<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Block-Wise Computing – BigDataStatMeth</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../assets/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-969ddfa49e00a70eb3423444dbc81f6c.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d0f1cdce0779274a5ec1152cd33adb41.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-d6747531eee53fd58085a197f3afc013.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-d0f1cdce0779274a5ec1152cd33adb41.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<meta name="mermaid-theme" content="default">
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/css/custom.css">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../assets/images/logo.png" alt="" class="navbar-logo light-content">
    <img src="../assets/images/logo.png" alt="" class="navbar-logo dark-content">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">BigDataStatMeth</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-fundamentals" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Fundamentals</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-fundamentals">    
        <li>
    <a class="dropdown-item" href="../fundamentals/big-data-problem.html">
 <span class="dropdown-text">The Big Data Problem</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../fundamentals/understanding-hdf5.html">
 <span class="dropdown-text">Understanding HDF5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../fundamentals/blockwise-computing.html">
 <span class="dropdown-text">Block-Wise Computing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../fundamentals/linear-algebra.html">
 <span class="dropdown-text">Linear Algebra Essentials</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-tutorials">    
        <li>
    <a class="dropdown-item" href="../tutorials/getting-started.html">
 <span class="dropdown-text">Getting Started</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorials/working-hdf5-matrices.html">
 <span class="dropdown-text">Working with HDF5 Matrices</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../tutorials/first-analysis.html">
 <span class="dropdown-text">Your First Analysis</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-workflows" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Workflows</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-workflows">    
        <li>
    <a class="dropdown-item" href="../workflows/implementing-pca.html">
 <span class="dropdown-text">Implementing PCA</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../workflows/implementing-cca.html">
 <span class="dropdown-text">Implementing CCA</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../workflows/cross-platform.html">
 <span class="dropdown-text">Cross-Platform Workflows</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-developing-methods" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Developing Methods</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-developing-methods">    
        <li>
    <a class="dropdown-item" href="../developing-methods/cca-r-implementation.html">
 <span class="dropdown-text">CCA in R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../developing-methods/cca-cpp-implementation.html">
 <span class="dropdown-text">CCA in C++</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-api-reference" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">API Reference</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-api-reference">    
        <li>
    <a class="dropdown-item" href="../api-reference/r/index.html">
 <span class="dropdown-text">R Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../api-reference/cpp/index.html">
 <span class="dropdown-text">C++ API</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../technical/performance.html"> 
<span class="menu-text">Technical</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/isglobal-brge/BigDataStatMeth"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://cran.r-project.org/package=BigDataStatMeth"> 
<span class="menu-text">CRAN</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../fundamentals/big-data-problem.html">Core Concepts</a></li><li class="breadcrumb-item"><a href="../fundamentals/blockwise-computing.html">Block-Wise Computing</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Core Concepts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/big-data-problem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Big Data Problem in Genomics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/understanding-hdf5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Understanding HDF5 Storage</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/blockwise-computing.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Block-Wise Computing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../fundamentals/linear-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Algebra for Statistical Methods</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-youll-learn" id="toc-what-youll-learn" class="nav-link active" data-scroll-target="#what-youll-learn"><span class="header-section-number">0.1</span> What You’ll Learn</a></li>
  <li><a href="#from-in-memory-to-block-wise-a-paradigm-shift" id="toc-from-in-memory-to-block-wise-a-paradigm-shift" class="nav-link" data-scroll-target="#from-in-memory-to-block-wise-a-paradigm-shift"><span class="header-section-number">1</span> From In-Memory to Block-Wise: A Paradigm Shift</a></li>
  <li><a href="#the-core-concept-divide-process-combine" id="toc-the-core-concept-divide-process-combine" class="nav-link" data-scroll-target="#the-core-concept-divide-process-combine"><span class="header-section-number">2</span> The Core Concept: Divide, Process, Combine</a></li>
  <li><a href="#example-1-computing-means-and-standard-deviations" id="toc-example-1-computing-means-and-standard-deviations" class="nav-link" data-scroll-target="#example-1-computing-means-and-standard-deviations"><span class="header-section-number">3</span> Example 1: Computing Means and Standard Deviations</a>
  <ul class="collapse">
  <li><a href="#the-in-memory-approach" id="toc-the-in-memory-approach" class="nav-link" data-scroll-target="#the-in-memory-approach"><span class="header-section-number">3.1</span> The In-Memory Approach</a></li>
  <li><a href="#the-block-wise-approach" id="toc-the-block-wise-approach" class="nav-link" data-scroll-target="#the-block-wise-approach"><span class="header-section-number">3.2</span> The Block-Wise Approach</a></li>
  <li><a href="#why-standard-deviation-is-slightly-more-complex" id="toc-why-standard-deviation-is-slightly-more-complex" class="nav-link" data-scroll-target="#why-standard-deviation-is-slightly-more-complex"><span class="header-section-number">3.3</span> Why Standard Deviation Is Slightly More Complex</a></li>
  </ul></li>
  <li><a href="#example-2-matrix-multiplication-by-blocks" id="toc-example-2-matrix-multiplication-by-blocks" class="nav-link" data-scroll-target="#example-2-matrix-multiplication-by-blocks"><span class="header-section-number">4</span> Example 2: Matrix Multiplication by Blocks</a>
  <ul class="collapse">
  <li><a href="#the-mathematical-foundation" id="toc-the-mathematical-foundation" class="nav-link" data-scroll-target="#the-mathematical-foundation"><span class="header-section-number">4.1</span> The Mathematical Foundation</a></li>
  <li><a href="#block-wise-strategy" id="toc-block-wise-strategy" class="nav-link" data-scroll-target="#block-wise-strategy"><span class="header-section-number">4.2</span> Block-Wise Strategy</a></li>
  <li><a href="#practical-implementation" id="toc-practical-implementation" class="nav-link" data-scroll-target="#practical-implementation"><span class="header-section-number">4.3</span> Practical Implementation</a></li>
  </ul></li>
  <li><a href="#example-3-the-qr-decomposition-challenge" id="toc-example-3-the-qr-decomposition-challenge" class="nav-link" data-scroll-target="#example-3-the-qr-decomposition-challenge"><span class="header-section-number">5</span> Example 3: The QR Decomposition Challenge</a>
  <ul class="collapse">
  <li><a href="#why-qr-matters" id="toc-why-qr-matters" class="nav-link" data-scroll-target="#why-qr-matters"><span class="header-section-number">5.1</span> Why QR Matters</a></li>
  <li><a href="#the-block-wise-strategy-hierarchical-qr" id="toc-the-block-wise-strategy-hierarchical-qr" class="nav-link" data-scroll-target="#the-block-wise-strategy-hierarchical-qr"><span class="header-section-number">5.2</span> The Block-Wise Strategy: Hierarchical QR</a></li>
  </ul></li>
  <li><a href="#example-4-block-wise-svd-for-principal-component-analysis" id="toc-example-4-block-wise-svd-for-principal-component-analysis" class="nav-link" data-scroll-target="#example-4-block-wise-svd-for-principal-component-analysis"><span class="header-section-number">6</span> Example 4: Block-Wise SVD for Principal Component Analysis</a>
  <ul class="collapse">
  <li><a href="#the-mathematical-goal" id="toc-the-mathematical-goal" class="nav-link" data-scroll-target="#the-mathematical-goal"><span class="header-section-number">6.1</span> The Mathematical Goal</a></li>
  <li><a href="#the-block-wise-strategy-hierarchical-decomposition" id="toc-the-block-wise-strategy-hierarchical-decomposition" class="nav-link" data-scroll-target="#the-block-wise-strategy-hierarchical-decomposition"><span class="header-section-number">6.2</span> The Block-Wise Strategy: Hierarchical Decomposition</a></li>
  </ul></li>
  <li><a href="#the-pattern-recognizing-block-wise-opportunities" id="toc-the-pattern-recognizing-block-wise-opportunities" class="nav-link" data-scroll-target="#the-pattern-recognizing-block-wise-opportunities"><span class="header-section-number">7</span> The Pattern: Recognizing Block-Wise Opportunities</a>
  <ul class="collapse">
  <li><a href="#operations-with-additive-decomposition" id="toc-operations-with-additive-decomposition" class="nav-link" data-scroll-target="#operations-with-additive-decomposition"><span class="header-section-number">7.1</span> 1. Operations with Additive Decomposition</a></li>
  <li><a href="#operations-with-hierarchical-decomposition" id="toc-operations-with-hierarchical-decomposition" class="nav-link" data-scroll-target="#operations-with-hierarchical-decomposition"><span class="header-section-number">7.2</span> 2. Operations with Hierarchical Decomposition</a></li>
  <li><a href="#operations-requiring-global-information" id="toc-operations-requiring-global-information" class="nav-link" data-scroll-target="#operations-requiring-global-information"><span class="header-section-number">7.3</span> 3. Operations Requiring Global Information</a></li>
  <li><a href="#operations-that-dont-decompose-well" id="toc-operations-that-dont-decompose-well" class="nav-link" data-scroll-target="#operations-that-dont-decompose-well"><span class="header-section-number">7.4</span> 4. Operations That Don’t Decompose Well</a></li>
  </ul></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations"><span class="header-section-number">8</span> Practical Considerations</a>
  <ul class="collapse">
  <li><a href="#block-size-selection" id="toc-block-size-selection" class="nav-link" data-scroll-target="#block-size-selection"><span class="header-section-number">8.1</span> Block Size Selection</a></li>
  <li><a href="#numerical-stability" id="toc-numerical-stability" class="nav-link" data-scroll-target="#numerical-stability"><span class="header-section-number">8.2</span> Numerical Stability</a></li>
  <li><a href="#parallelization" id="toc-parallelization" class="nav-link" data-scroll-target="#parallelization"><span class="header-section-number">8.3</span> Parallelization</a></li>
  </ul></li>
  <li><a href="#implementing-your-own-block-wise-methods" id="toc-implementing-your-own-block-wise-methods" class="nav-link" data-scroll-target="#implementing-your-own-block-wise-methods"><span class="header-section-number">9</span> Implementing Your Own Block-Wise Methods</a>
  <ul class="collapse">
  <li><a href="#architecture-overview" id="toc-architecture-overview" class="nav-link" data-scroll-target="#architecture-overview"><span class="header-section-number">9.1</span> Architecture Overview</a></li>
  <li><a href="#developing-new-methods" id="toc-developing-new-methods" class="nav-link" data-scroll-target="#developing-new-methods"><span class="header-section-number">9.2</span> Developing New Methods</a></li>
  <li><a href="#learning-from-examples" id="toc-learning-from-examples" class="nav-link" data-scroll-target="#learning-from-examples"><span class="header-section-number">9.3</span> Learning from Examples</a></li>
  </ul></li>
  <li><a href="#interactive-exercise" id="toc-interactive-exercise" class="nav-link" data-scroll-target="#interactive-exercise"><span class="header-section-number">10</span> Interactive Exercise</a>
  <ul class="collapse">
  <li><a href="#practice-analyzing-block-wise-efficiency" id="toc-practice-analyzing-block-wise-efficiency" class="nav-link" data-scroll-target="#practice-analyzing-block-wise-efficiency"><span class="header-section-number">10.1</span> Practice: Analyzing Block-Wise Efficiency</a></li>
  </ul></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways"><span class="header-section-number">11</span> Key Takeaways</a>
  <ul class="collapse">
  <li><a href="#essential-concepts" id="toc-essential-concepts" class="nav-link" data-scroll-target="#essential-concepts"><span class="header-section-number">11.1</span> Essential Concepts</a></li>
  <li><a href="#when-block-wise-processing-works-well" id="toc-when-block-wise-processing-works-well" class="nav-link" data-scroll-target="#when-block-wise-processing-works-well"><span class="header-section-number">11.2</span> When Block-Wise Processing Works Well</a></li>
  </ul></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps"><span class="header-section-number">12</span> Next Steps</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/isglobal-brge/BigDataStatMeth/edit/main/fundamentals/blockwise-computing.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/isglobal-brge/BigDataStatMeth/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../fundamentals/big-data-problem.html">Core Concepts</a></li><li class="breadcrumb-item"><a href="../fundamentals/blockwise-computing.html">Block-Wise Computing</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Block-Wise Computing</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Adapting Statistical Algorithms for Disk-Based Data</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="what-youll-learn" class="level3 learning-objectives" data-number="0.1">
<h3 data-number="0.1" class="anchored" data-anchor-id="what-youll-learn"><span class="header-section-number">0.1</span> What You’ll Learn</h3>
<p>By the end of this section, you will:</p>
<ul>
<li>Understand the divide-process-combine paradigm of block-wise algorithms</li>
<li>Know which operations decompose naturally to block-wise processing</li>
<li>Recognize which algorithms are challenging to adapt for blocks</li>
<li>Understand memory-computation trade-offs with block size</li>
<li>See concrete examples of block-wise matrix operations</li>
<li>Know how to compose new methods from existing BigDataStatMeth functions</li>
</ul>
</section>
<section id="from-in-memory-to-block-wise-a-paradigm-shift" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="from-in-memory-to-block-wise-a-paradigm-shift"><span class="header-section-number">1</span> From In-Memory to Block-Wise: A Paradigm Shift</h2>
<p>You now understand why large datasets don’t fit in RAM and how HDF5 enables efficient access to disk-stored data. But knowing you <em>can</em> read arbitrary portions of a matrix from disk doesn’t automatically tell you <em>how</em> to perform statistical analyses on that data. The challenge is algorithmic: how do you adapt methods designed for in-memory matrices to work with data that must be processed in pieces?</p>
<p>This is not merely an implementation detail - it requires rethinking how algorithms work. A standard PCA implementation might call <code>svd(X)</code> where <code>X</code> is a complete matrix in memory. That single function call encapsulates a sophisticated numerical algorithm, but it fundamentally assumes it can access any element of <code>X</code> at any time. When X lives on disk, this assumption breaks. You must decompose the algorithm into steps that process manageable blocks of data, with intermediate results that fit in memory.</p>
<p>The mathematical operations remain the same - we’re still computing eigenvalues, performing matrix multiplications, or fitting regression models. But the <em>computational strategy</em> changes fundamentally. This section explains how standard statistical methods are adapted for block-wise processing, using examples from BigDataStatMeth’s implementation.</p>
</section>
<section id="the-core-concept-divide-process-combine" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="the-core-concept-divide-process-combine"><span class="header-section-number">2</span> The Core Concept: Divide, Process, Combine</h2>
<p>Block-wise computing follows a conceptual pattern that applies across different statistical methods:</p>
<ol type="1">
<li><strong>Divide:</strong> Partition the data matrix into blocks that fit comfortably in memory</li>
<li><strong>Process:</strong> Perform computations on each block independently (when possible)</li>
<li><strong>Combine:</strong> Merge the block-level results to obtain the final answer</li>
</ol>
<p>The art lies in step 2 and 3 - figuring out what computations can be done on blocks independently, what information must be passed between blocks, and how to combine results validly. Not all algorithms decompose equally well, and some require sophisticated mathematical reformulations to work in a block-wise framework.</p>
<p>Let’s start with simple examples and build toward more complex methods.</p>
</section>
<section id="example-1-computing-means-and-standard-deviations" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="example-1-computing-means-and-standard-deviations"><span class="header-section-number">3</span> Example 1: Computing Means and Standard Deviations</h2>
<p>Computing column means illustrates the simplest case of block-wise processing. Suppose you have a matrix with 100,000 rows and 50,000 columns that’s too large for memory, but you can comfortably work with blocks of 10,000 rows at a time.</p>
<section id="the-in-memory-approach" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="the-in-memory-approach"><span class="header-section-number">3.1</span> The In-Memory Approach</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Traditional approach - assumes X fits in memory</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>column_means <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(X)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This single line hides significant computation: for each column, R reads all 100,000 values, sums them, and divides by 100,000.</p>
</section>
<section id="the-block-wise-approach" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="the-block-wise-approach"><span class="header-section-number">3.2</span> The Block-Wise Approach</h3>
<p>For block-wise computation, we leverage a mathematical property: the mean of a set of values equals the weighted average of the means of subsets, where weights are the subset sizes.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="">Visual Diagram</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">Step-by-Step Explanation</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false" href="">Pseudocode</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Matrix on Disk&lt;br/&gt;100,000 × 50,000] --&gt; B[Initialize&lt;br/&gt;column_sums = 0]
    B --&gt; C{More blocks?}
    C --&gt;|Yes| D[Read Block i&lt;br/&gt;10,000 rows]
    D --&gt; E[Compute&lt;br/&gt;colSums for block]
    E --&gt; F[Accumulate:&lt;br/&gt;column_sums += block_sums]
    F --&gt; C
    C --&gt;|No| G[Finalize:&lt;br/&gt;means = column_sums / n_rows]
    
    style A fill:#f0f8ff
    style G fill:#e8f6e8
    style D fill:#fff8e1
    style E fill:#fff8e1
    style F fill:#fff8e1
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p><strong>Step 1: Initialize accumulators</strong></p>
<p>We start by creating a vector to accumulate the sum of each column across all blocks. We also query the HDF5 file metadata to know how many rows exist in total and calculate how many blocks we’ll need to process.</p>
<p><strong>Step 2: Process blocks sequentially</strong></p>
<p>For each block:</p>
<ol type="1">
<li><p><strong>Calculate boundaries:</strong> Determine which rows belong to this block. Most blocks have <code>block_size</code> rows, but the last block might be smaller.</p></li>
<li><p><strong>Read from disk:</strong> Load only this block’s rows into RAM. This is the key to memory efficiency - we never hold the entire matrix.</p></li>
<li><p><strong>Compute contribution:</strong> Sum the values in each column of this block. This gives us a vector of length <code>n_cols</code>.</p></li>
<li><p><strong>Accumulate:</strong> Add this block’s column sums to our running total. This works because addition is associative and commutative.</p></li>
<li><p><strong>Free memory:</strong> Explicitly release the block’s memory before reading the next one. This ensures peak memory usage is just one block, not all blocks.</p></li>
</ol>
<p><strong>Step 3: Calculate final means</strong></p>
<p>After processing all blocks, we have the total sum for each column. Divide by the total number of rows to get the mean.</p>
<p><strong>Why this works mathematically:</strong></p>
<p><span class="math display">\text{mean}(X) = \frac{\sum_{i=1}^{n} x_i}{n} = \frac{\sum_{j=1}^{k} \sum_{i \in \text{block}_j} x_i}{n}</span></p>
<p>The inner sums are what we compute for each block, and we accumulate them in the outer sum.</p>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: BlockwiseMeans</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: HDF5 dataset with n_rows × n_cols, block_size</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: column_means vector of length n_cols</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Initialize</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>column_sums <span class="ot">&lt;-</span> vector of <span class="fu">zeros</span> (length n_cols)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>n_rows_total <span class="ot">&lt;-</span> <span class="fu">get_total_rows_from_hdf5</span>()</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(n_rows_total <span class="sc">/</span> block_size)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Process each block</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Define block boundaries</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  start_row <span class="ot">&lt;-</span> (i<span class="dv">-1</span>) <span class="sc">*</span> block_size <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  end_row <span class="ot">&lt;-</span> <span class="fu">min</span>(i <span class="sc">*</span> block_size, n_rows_total)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from disk</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(start_row, end_row)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute block contribution</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  block_sums <span class="ot">&lt;-</span> <span class="fu">compute_column_sums</span>(block)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Accumulate results</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  column_sums <span class="ot">&lt;-</span> column_sums <span class="sc">+</span> block_sums</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Free memory</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(block)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Finalize computation</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>column_means <span class="ot">&lt;-</span> column_sums <span class="sc">/</span> n_rows_total</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Return result</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(column_means)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Memory Efficiency
</div>
</div>
<div class="callout-body-container callout-body">
<p>Peak memory is one block (10,000 × 50,000 = ~40 MB for doubles) plus the accumulator vector (50,000 values = ~0.4 MB).</p>
<p><strong>Total: ~40 MB instead of 40 GB for the full matrix</strong> - a 1000× reduction!</p>
</div>
</div>
<p><strong>Key insight:</strong> For operations that can be expressed as combining independent contributions from blocks (sums, counts), block-wise processing is straightforward. The mathematical property that makes this work is <strong>additive decomposition</strong>: the sum over all data equals the sum of sums over blocks.</p>
<p><strong>BigDataStatMeth implementation:</strong> This is handled internally by C++ functions like <code>get_HDF5_mean_sd_by_column()</code> (or <code>by_row</code> variant) which manage block reading, computation, and accumulation efficiently using OpenMP parallelization when multiple cores are available.</p>
</section>
<section id="why-standard-deviation-is-slightly-more-complex" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="why-standard-deviation-is-slightly-more-complex"><span class="header-section-number">3.3</span> Why Standard Deviation Is Slightly More Complex</h3>
<p>Standard deviation requires both means and squared deviations from means. You might think you could compute it in one pass through blocks, but there’s a subtle issue: you need the <em>overall</em> mean to compute deviations, but you won’t know the overall mean until you’ve seen all blocks.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Two-Pass Algorithm Required
</div>
</div>
<div class="callout-body-container callout-body">
<p>Computing standard deviation requires <strong>two complete passes</strong> through the data:</p>
<ol type="1">
<li><strong>Pass 1:</strong> Compute overall means<br>
</li>
<li><strong>Pass 2:</strong> Compute squared deviations using those means</li>
</ol>
<p>This doubles I/O but keeps memory constant.</p>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">Visual Workflow</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">Detailed Explanation</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false" href="">Pseudocode</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>Two passes through the data:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Dataset on Disk] --&gt; B[Pass 1:&lt;br/&gt;Compute Means]
    B --&gt; C[Store means&lt;br/&gt;in memory]
    C --&gt; D[Pass 2:&lt;br/&gt;Start over]
    D --&gt; E[Read Block i]
    E --&gt; F[Center:&lt;br/&gt;block - means]
    F --&gt; G[Square:&lt;br/&gt;centered²]
    G --&gt; H[Accumulate&lt;br/&gt;squared_devs]
    H --&gt; I{More blocks?}
    I --&gt;|Yes| E
    I --&gt;|No| J[Finalize:&lt;br/&gt;sqrt of sum over n-1]
    
    style A fill:#f0f8ff
    style B fill:#fff8e1
    style C fill:#ffe8e8
    style J fill:#e8f6e8
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p><strong>Why two passes are necessary:</strong></p>
<p>To compute standard deviation, we need: <span class="math inline">\text{SD} = \sqrt{\frac{\sum (x_i - \bar{x})^2}{n-1}}</span></p>
<p>The problem: we need <span class="math inline">\bar{x}</span> (the mean) to compute each <span class="math inline">(x_i - \bar{x})^2</span> term. But we can’t know the overall mean until we’ve processed all blocks.</p>
<p><strong>Pass 1: Compute means (same as before)</strong></p>
<p>Use the block-wise mean algorithm to get the global mean for each column.</p>
<p><strong>Pass 2: Compute squared deviations</strong></p>
<p>Now that we know the means, we:</p>
<ol type="1">
<li><p><strong>Read each block again:</strong> Yes, this means reading the entire dataset twice. For very large datasets on slow storage, this I/O cost matters.</p></li>
<li><p><strong>Center the block:</strong> Subtract the global mean from each column. This “centering” operation broadcasts the mean vector across all rows of the block.</p></li>
<li><p><strong>Square element-wise:</strong> Each centered value is squared: <span class="math inline">(x - \bar{x})^2</span></p></li>
<li><p><strong>Accumulate squared deviations:</strong> Sum these squared values, column by column, across all blocks.</p></li>
<li><p><strong>Finalize:</strong> After processing all blocks, divide by <span class="math inline">n-1</span> (Bessel’s correction for sample variance) and take the square root.</p></li>
</ol>
<p><strong>Alternative: One-pass algorithm</strong></p>
<p>There exist numerically stable one-pass algorithms (e.g., Welford’s algorithm) that compute mean and variance simultaneously. However, they’re slightly more complex to implement and can be less numerically stable for data with large means and small variances. BigDataStatMeth opts for the two-pass approach for clarity and numerical reliability in typical statistical applications.</p>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: BlockwiseStandardDeviation</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: HDF5 dataset with n_rows × n_cols, block_size</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: column_sds vector of length n_cols</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass 1: Compute means</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>column_means <span class="ot">&lt;-</span> <span class="fu">BlockwiseMeans</span>(dataset, block_size)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass 2: Compute squared deviations</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>squared_devs <span class="ot">&lt;-</span> vector of <span class="fu">zeros</span> (length n_cols)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(n_rows_total <span class="sc">/</span> block_size)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from disk</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(start_row, end_row)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Center the block (subtract column means)</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  centered_block <span class="ot">&lt;-</span> block <span class="sc">-</span> column_means  <span class="co"># Broadcast subtraction</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Square element-wise</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  squared_block <span class="ot">&lt;-</span> centered_block<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sum squared deviations for this block</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  block_sq_devs <span class="ot">&lt;-</span> <span class="fu">compute_column_sums</span>(squared_block)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Accumulate</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  squared_devs <span class="ot">&lt;-</span> squared_devs <span class="sc">+</span> block_sq_devs</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Free memory</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(block)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Finalize: compute standard deviation</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>column_sds <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(squared_devs <span class="sc">/</span> (n_rows_total <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(column_sds)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p><strong>I/O cost:</strong> This two-pass approach doubles the I/O (reading data twice), but keeps memory requirements constant regardless of data size.</p>
<p><strong>BigDataStatMeth implementation:</strong> The package provides two ways to compute these statistics:</p>
<ol type="1">
<li><p><strong><code>bdNormalize_hdf5()</code></strong> - Performs centering and/or scaling in-place, automatically handling the multi-pass computation. Results are written back to the HDF5 file.</p></li>
<li><p><strong><code>bdgetSDandMean_hdf5()</code></strong> - Computes means and standard deviations and returns them either in memory (<code>onmemory = TRUE</code>) or stores them in the HDF5 file (<code>onmemory = FALSE</code>) for later use. This is useful when you need the statistics themselves, not just normalized data.</p></li>
</ol>
<p>Both functions use the C++ internal implementation <code>get_HDF5_mean_sd_by_column()</code> which handles block iteration, parallel computation with OpenMP, and numerically stable accumulation.</p>
</section>
</section>
<section id="example-2-matrix-multiplication-by-blocks" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="example-2-matrix-multiplication-by-blocks"><span class="header-section-number">4</span> Example 2: Matrix Multiplication by Blocks</h2>
<p>Matrix multiplication is fundamental to many statistical methods - it appears in linear regression, principal component analysis, and countless other algorithms. It also illustrates a more complex block-wise pattern because the result depends on interactions between different parts of both input matrices.</p>
<section id="the-mathematical-foundation" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="the-mathematical-foundation"><span class="header-section-number">4.1</span> The Mathematical Foundation</h3>
<p>Recall that matrix multiplication <span class="math inline">C = A \times B</span> where <span class="math inline">A</span> is <span class="math inline">m \times k</span> and <span class="math inline">B</span> is <span class="math inline">k \times n</span>, produces:</p>
<p><span class="math display">C_{ij} = \sum_{p=1}^{k} A_{ip} \times B_{pj}</span></p>
<p>Each element of <span class="math inline">C</span> is a dot product of a row from <span class="math inline">A</span> and a column from <span class="math inline">B</span>. The key insight for block-wise processing is that this operation can be decomposed spatially - we can compute different regions of <span class="math inline">C</span> independently.</p>
</section>
<section id="block-wise-strategy" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="block-wise-strategy"><span class="header-section-number">4.2</span> Block-Wise Strategy</h3>
<p>If we partition <span class="math inline">A</span> into row blocks and <span class="math inline">B</span> into column blocks:</p>
<p><span class="math display">
A = \begin{bmatrix} A_1 \\ A_2 \\ \vdots \\ A_m \end{bmatrix}, \quad
B = \begin{bmatrix} B_1 &amp; B_2 &amp; \cdots &amp; B_n \end{bmatrix}
</span></p>
<p>Then each block of the result <span class="math inline">C_{ij} = A_i \times B_j</span> can be computed independently. More usefully, if we partition along the shared dimension (the <span class="math inline">k</span> dimension):</p>
<p><span class="math display">
A = \begin{bmatrix} A_1 &amp; A_2 &amp; \cdots &amp; A_p \end{bmatrix}, \quad
B = \begin{bmatrix} B_1 \\ B_2 \\ \vdots \\ B_p \end{bmatrix}
</span></p>
<p>Then: <span class="math inline">C = \sum_{i=1}^{p} A_i \times B_i</span></p>
<p>This decomposition means we can: 1. Read one block pair <span class="math inline">(A_i, B_i)</span> at a time from disk 2. Compute their contribution to <span class="math inline">C</span> 3. Accumulate the result 4. Never hold more than two blocks and the accumulator in memory</p>
</section>
<section id="practical-implementation" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="practical-implementation"><span class="header-section-number">4.3</span> Practical Implementation</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">Visual Strategy</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false" href="">Algorithm Explanation</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false" href="">Pseudocode</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A["Matrix A m × k&lt;br/&gt;on disk"] --&gt; B["Partition along&lt;br/&gt;k dimension"]
    C["Matrix B k × n&lt;br/&gt;on disk"] --&gt; B
    B --&gt; D["Block pairs:&lt;br/&gt;A₁ B₁, A₂ B₂, ..."]
    D --&gt; E{More blocks?}
    E --&gt;|Yes| F["Read block pair&lt;br/&gt;Aᵢ Bᵢ"]
    F --&gt; G["Compute&lt;br/&gt;Aᵢ × Bᵢ"]
    G --&gt; H["Accumulate:&lt;br/&gt;C += Aᵢ × Bᵢ"]
    H --&gt; E
    E --&gt;|No| I["Result matrix&lt;br/&gt;C m × n"]
    
    style A fill:#f0f8ff
    style C fill:#f0f8ff
    style I fill:#e8f6e8
    style F fill:#fff8e1
    style G fill:#fff8e1
    style H fill:#fff8e1
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p><strong>Key insight:</strong> Matrix multiplication can be decomposed along the shared dimension (the <span class="math inline">k</span> in <span class="math inline">A_{m \times k} \times B_{k \times n}</span>).</p>
<p><strong>Step 1: Initialize</strong></p>
<p>Create a zero matrix <span class="math inline">C</span> of dimensions <span class="math inline">m \times n</span> to accumulate results. Calculate how many blocks we’ll need along the <span class="math inline">k</span> dimension.</p>
<p><strong>Step 2: Process each block pair</strong></p>
<p>For each block <span class="math inline">i</span>:</p>
<ol type="1">
<li><p><strong>Read from A:</strong> Extract columns <code>start:end</code> of matrix <span class="math inline">A</span>. This gives us a “tall thin” matrix: <span class="math inline">m</span> rows (all of them) by <code>block_width</code> columns (just this block’s slice).</p></li>
<li><p><strong>Read from B:</strong> Extract rows <code>start:end</code> of matrix <span class="math inline">B</span>. This gives us a “short wide” matrix: <code>block_width</code> rows (matching A’s columns) by <span class="math inline">n</span> columns (all of them).</p></li>
<li><p><strong>Multiply:</strong> Compute the standard matrix product of these two small pieces. The result is <span class="math inline">m \times n</span> - the same size as our final answer.</p></li>
<li><p><strong>Accumulate:</strong> Add this contribution to <span class="math inline">C</span>. This works because: <span class="math display">C = A \times B = \sum_{i=1}^{blocks} A_i \times B_i</span> where <span class="math inline">A_i</span> and <span class="math inline">B_i</span> are the block slices.</p></li>
</ol>
<p><strong>Step 3: Handle result</strong></p>
<p>If <span class="math inline">C</span> fits in memory, return it directly. If not (which can happen when <span class="math inline">m</span> and <span class="math inline">n</span> are both large), write it to HDF5 incrementally and return a reference.</p>
<p><strong>Memory analysis:</strong></p>
<p>Peak memory = <span class="math inline">A_{block}</span> + <span class="math inline">B_{block}</span> + <span class="math inline">C</span> = <span class="math inline">(m \times b) + (b \times n) + (m \times n)</span> values</p>
<p>For large <span class="math inline">k</span> but moderate <span class="math inline">m</span> and <span class="math inline">n</span>, this is much less than holding full <span class="math inline">A</span> and <span class="math inline">B</span> which would require <span class="math inline">(m \times k) + (k \times n)</span> values.</p>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: BlockwiseMatrixMultiplication</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: Matrix A m × k in HDF5, Matrix B k × n in HDF5, block_size</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: Matrix C = A × B m × n</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize result matrix</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> zero matrix m × n</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(k <span class="sc">/</span> block_size)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Process blocks along shared dimension</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Determine block range along k dimension</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  start_idx <span class="ot">&lt;-</span> (i<span class="dv">-1</span>) <span class="sc">*</span> block_size <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  end_idx <span class="ot">&lt;-</span> <span class="fu">min</span>(i <span class="sc">*</span> block_size, k)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  block_width <span class="ot">&lt;-</span> end_idx <span class="sc">-</span> start_idx <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from A (columns start_idx:end_idx)</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  A_block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_columns</span>(A, start_idx<span class="sc">:</span>end_idx)  <span class="co"># m × block_width</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read corresponding block from B (rows start_idx:end_idx)</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>  B_block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(B, start_idx<span class="sc">:</span>end_idx)     <span class="co"># block_width × n</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute this block's contribution to C</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>  C_contribution <span class="ot">&lt;-</span> A_block <span class="sc">%*%</span> B_block  <span class="co"># Standard matrix mult</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Accumulate into result</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  C <span class="ot">&lt;-</span> C <span class="sc">+</span> C_contribution</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Free memory</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(A_block, B_block)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Write result (if too large for memory, write directly to HDF5)</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (C fits <span class="cf">in</span> memory) {</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(C)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_to_hdf5</span>(C)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(HDF5_reference)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Spatial Decomposition
</div>
</div>
<div class="callout-body-container callout-body">
<p>Matrix multiplication is decomposed <strong>spatially</strong> along the shared dimension <span class="math inline">k</span>. Each block pair contributes independently to the final result - this is different from the <strong>temporal decomposition</strong> used for means where blocks contribute sequentially.</p>
</div>
</div>
<p><strong>BigDataStatMeth implementation:</strong> The <code>bdblockmult_hdf5()</code> function implements this strategy with additional optimizations:</p>
<ul>
<li>Automatic block size selection based on available memory</li>
<li>Writing results directly to HDF5 to handle cases where even the result matrix is too large</li>
<li>Parallel processing of independent block multiplications using OpenMP when multiple cores are available</li>
<li>Careful memory management to avoid unnecessary copies</li>
<li>All computation done in C++ for maximum efficiency</li>
</ul>
</section>
</section>
<section id="example-3-the-qr-decomposition-challenge" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="example-3-the-qr-decomposition-challenge"><span class="header-section-number">5</span> Example 3: The QR Decomposition Challenge</h2>
<p>The QR decomposition is more challenging because it requires maintaining orthogonality across all columns, which creates dependencies between blocks. This illustrates how not all algorithms decompose trivially.</p>
<section id="why-qr-matters" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="why-qr-matters"><span class="header-section-number">5.1</span> Why QR Matters</h3>
<p>The QR decomposition factors a matrix <span class="math inline">A</span> (dimensions <span class="math inline">m \times n</span>) into: <span class="math display">A = Q \times R</span></p>
<p>where <span class="math inline">Q</span> is orthogonal (<span class="math inline">m \times n</span>, with <span class="math inline">Q^T Q = I</span>) and <span class="math inline">R</span> is upper triangular (<span class="math inline">n \times n</span>). This decomposition is fundamental to:</p>
<ul>
<li>Solving least squares problems (linear regression)</li>
<li>Computing principal components</li>
<li>Many iterative algorithms that need orthonormal bases</li>
</ul>
</section>
<section id="the-block-wise-strategy-hierarchical-qr" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="the-block-wise-strategy-hierarchical-qr"><span class="header-section-number">5.2</span> The Block-Wise Strategy: Hierarchical QR</h3>
<p>The key insight is that QR decomposition can be computed hierarchically through a series of smaller QR decompositions.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true" href="">Visual Workflow</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false" href="">Step-by-Step Process</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false" href="">Pseudocode</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A["Matrix A&lt;br/&gt;m × n&lt;br/&gt;Too large for RAM"] --&gt; B["Partition into&lt;br/&gt;k row blocks"]
    B --&gt; C1["Block A₁&lt;br/&gt;m₁ × n"]
    B --&gt; C2["Block A₂&lt;br/&gt;m₂ × n"]
    B --&gt; C3["Block Aₖ&lt;br/&gt;mₖ × n"]
    
    C1 --&gt; D1["Local QR:&lt;br/&gt;A₁ = Q₁R₁"]
    C2 --&gt; D2["Local QR:&lt;br/&gt;A₂ = Q₂R₂"]
    C3 --&gt; D3["Local QR:&lt;br/&gt;Aₖ = QₖRₖ"]
    
    D1 --&gt; E["Stack R matrices:&lt;br/&gt;[R₁; R₂; ...; Rₖ]&lt;br/&gt;kn × n&lt;br/&gt;Fits in RAM!"]
    D2 --&gt; E
    D3 --&gt; E
    
    E --&gt; F["Final QR:&lt;br/&gt;Rstack = QR × Rfinal"]
    
    F --&gt; G["Reconstruct Q:&lt;br/&gt;Multiply Q_i by QR blocks"]
    
    G --&gt; H["Result:&lt;br/&gt;A = Q × Rfinal"]
    
    style A fill:#ffe8e8
    style E fill:#fff8e1
    style H fill:#e8f6e8
    style D1 fill:#f0f8ff
    style D2 fill:#f0f8ff
    style D3 fill:#f0f8ff
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p><strong>Step 1: Partition</strong></p>
<p>Divide the matrix <span class="math inline">A</span> into blocks along rows: <span class="math inline">A = [A_1; A_2; ...; A_k]</span></p>
<p><strong>Step 2: Local QR</strong></p>
<p>Compute QR for each block independently: <span class="math display">A_i = Q_i R_i</span></p>
<p>Each block’s QR decomposition can be computed separately because they operate on independent rows.</p>
<p><strong>Step 3: Collect R matrices</strong></p>
<p>Stack all the upper triangular <span class="math inline">R_i</span> matrices vertically: <span class="math display">R_{stack} = [R_1; R_2; ...; R_k]</span></p>
<p><strong>Critical insight:</strong> <span class="math inline">R_{stack}</span> is much smaller than <span class="math inline">A</span>. It’s <span class="math inline">kn \times n</span> instead of <span class="math inline">m \times n</span>, and typically <span class="math inline">kn \ll m</span>, so this stacked matrix <strong>fits in memory</strong> even when <span class="math inline">A</span> doesn’t!</p>
<p><strong>Step 4: Final QR</strong></p>
<p>Compute QR of the stacked R matrices (this fits in RAM): <span class="math display">R_{stack} = Q_R \times R_{final}</span></p>
<p><strong>Step 5: Reconstruct Q</strong></p>
<p>The overall <span class="math inline">Q</span> is obtained by multiplying each local <span class="math inline">Q_i</span> by the corresponding block of <span class="math inline">Q_R</span>. This reconstruction can be done block by block, again staying within memory constraints.</p>
<p><strong>Why this works mathematically:</strong></p>
<p><span class="math display">A = \begin{bmatrix} Q_1 R_1 \\ Q_2 R_2 \\ \vdots \\ Q_k R_k \end{bmatrix} =
\begin{bmatrix} Q_1 \\ Q_2 \\ \vdots \\ Q_k \end{bmatrix}
\begin{bmatrix} R_1 \\ R_2 \\ \vdots \\ R_k \end{bmatrix}</span></p>
<p>Since the <span class="math inline">Q_i</span> are orthogonal, applying another QR to the stacked <span class="math inline">R</span> matrices gives us the final factorization.</p>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: HierarchicalQR</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: Matrix A m × n in HDF5, block_size</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: Q matrix m × n, R matrix n × n</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Partition and compute local QRs</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(m <span class="sc">/</span> block_size)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>R_list <span class="ot">&lt;-</span> <span class="fu">list</span>()  <span class="co"># Store R matrices</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from HDF5</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  A_block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(start_row, end_row)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute local QR</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  qr_result <span class="ot">&lt;-</span> <span class="fu">qr_decomposition</span>(A_block)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  Q_local <span class="ot">&lt;-</span> qr_result<span class="sc">$</span>Q</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  R_local <span class="ot">&lt;-</span> qr_result<span class="sc">$</span>R</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store Q to HDF5 for later</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_hdf5</span>(Q_local, <span class="at">group =</span> <span class="st">"local_Q"</span>, <span class="at">dataset =</span> <span class="fu">paste0</span>(<span class="st">"Q_"</span>, i))</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Keep R in memory (small)</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>  R_list[[i]] <span class="ot">&lt;-</span> R_local</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(A_block, Q_local)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Stack R matrices (fits in RAM)</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>R_stacked <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(R_list)  <span class="co"># (k*n × n)</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Final QR on stacked Rs</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>qr_final <span class="ot">&lt;-</span> <span class="fu">qr_decomposition</span>(R_stacked)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>Q_R <span class="ot">&lt;-</span> qr_final<span class="sc">$</span>Q</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>R_final <span class="ot">&lt;-</span> qr_final<span class="sc">$</span>R</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Reconstruct global Q (block by block)</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read local Q_i</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>  Q_local <span class="ot">&lt;-</span> <span class="fu">read_hdf5</span>(<span class="at">group =</span> <span class="st">"local_Q"</span>, <span class="at">dataset =</span> <span class="fu">paste0</span>(<span class="st">"Q_"</span>, i))</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Multiply by corresponding Q_R block</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>  start_idx <span class="ot">&lt;-</span> (i<span class="dv">-1</span>) <span class="sc">*</span> n <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>  end_idx <span class="ot">&lt;-</span> i <span class="sc">*</span> n</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>  Q_R_block <span class="ot">&lt;-</span> Q_R[start_idx<span class="sc">:</span>end_idx, ]</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>  Q_global_block <span class="ot">&lt;-</span> Q_local <span class="sc">%*%</span> Q_R_block</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Write back to HDF5</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_hdf5</span>(Q_global_block, <span class="at">group =</span> <span class="st">"final_Q"</span>, <span class="at">dataset =</span> <span class="fu">paste0</span>(<span class="st">"Q_"</span>, i))</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(<span class="fu">list</span>(<span class="at">Q =</span> <span class="st">"final_Q"</span>, <span class="at">R =</span> R_final))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>The Magic of Hierarchical QR
</div>
</div>
<div class="callout-body-container callout-body">
<p>The stacked <span class="math inline">R</span> matrices are only <span class="math inline">(k \times n) \times n</span> in size. Even with 10 blocks, if <span class="math inline">n=1000</span>, that’s just a <span class="math inline">10{,}000 \times 1000</span> matrix - about 80 MB. This fits comfortably in RAM even when the original matrix is hundreds of GB!</p>
</div>
</div>
<p><strong>BigDataStatMeth implementation:</strong> The package implements hierarchical QR in <code>bdQR_hdf5()</code>, handling the block partitioning, intermediate storage, and final assembly automatically. This enables methods like PCA on out-of-memory data.</p>
</section>
</section>
<section id="example-4-block-wise-svd-for-principal-component-analysis" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="example-4-block-wise-svd-for-principal-component-analysis"><span class="header-section-number">6</span> Example 4: Block-Wise SVD for Principal Component Analysis</h2>
<p>Singular Value Decomposition (SVD) underlies principal component analysis and is one of the most important matrix decompositions in statistics. Computing SVD on matrices too large for memory is a significant challenge that demonstrates the full power of block-wise thinking.</p>
<section id="the-mathematical-goal" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="the-mathematical-goal"><span class="header-section-number">6.1</span> The Mathematical Goal</h3>
<p>For a matrix <span class="math inline">X</span> (dimensions <span class="math inline">n \times p</span>), we want: <span class="math display">X = U \Sigma V^T</span></p>
<p>where: - <span class="math inline">U</span> is <span class="math inline">n \times r</span> with orthonormal columns (left singular vectors) - <span class="math inline">\Sigma</span> is <span class="math inline">r \times r</span> diagonal (singular values)<br>
- <span class="math inline">V</span> is <span class="math inline">p \times r</span> with orthonormal columns (right singular vectors) - <span class="math inline">r = \min(n, p)</span> or smaller if we want only the leading components</p>
<p>For PCA, we typically want only the first <span class="math inline">k</span> components where <span class="math inline">k \ll r</span>, which simplifies the problem significantly.</p>
</section>
<section id="the-block-wise-strategy-hierarchical-decomposition" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="the-block-wise-strategy-hierarchical-decomposition"><span class="header-section-number">6.2</span> The Block-Wise Strategy: Hierarchical Decomposition</h3>
<p>BigDataStatMeth implements a hierarchical SVD algorithm (Iwen &amp; Ong, 2017) that works in levels.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true" href="">Visual Workflow</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false" href="">Two-Level Process</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-3" role="tab" aria-controls="tabset-5-3" aria-selected="false" href="">Memory Analysis</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A["Matrix X n × p&lt;br/&gt;Too large for RAM"] --&gt; B["Level 1:&lt;br/&gt;Partition into m blocks"]
    
    B --&gt; C1["Block X₁"]
    B --&gt; C2["Block X₂"]  
    B --&gt; C3["Block Xₘ"]
    
    C1 --&gt; D1["Local SVD:&lt;br/&gt;X₁ = U₁Σ₁V₁ᵀ&lt;br/&gt;Keep k components"]
    C2 --&gt; D2["Local SVD:&lt;br/&gt;X₂ = U₂Σ₂V₂ᵀ&lt;br/&gt;Keep k components"]
    C3 --&gt; D3["Local SVD:&lt;br/&gt;Xₘ = UₘΣₘVₘᵀ&lt;br/&gt;Keep k components"]
    
    D1 --&gt; E1["Form Z₁ = V₁Σ₁&lt;br/&gt;p × k"]
    D2 --&gt; E2["Form Z₂ = V₂Σ₂&lt;br/&gt;p × k"]
    D3 --&gt; E3["Form Zₘ = VₘΣₘ&lt;br/&gt;p × k"]
    
    E1 --&gt; F["Level 2:&lt;br/&gt;Stack Z matrices&lt;br/&gt;Z = [Z₁; Z₂; ...; Zₘ]&lt;br/&gt;mk × k&lt;br/&gt;Fits in RAM!"]
    E2 --&gt; F
    E3 --&gt; F
    
    F --&gt; G["Global SVD:&lt;br/&gt;Z = UzΣzVzᵀ"]
    
    G --&gt; H["Extract Results:&lt;br/&gt;Singular values = Σz&lt;br/&gt;Right vectors = Vz&lt;br/&gt;Left vectors from U₁...Uₘ"]
    
    H --&gt; I["Final SVD:&lt;br/&gt;X ≈ UΣVᵀ"]
    
    style A fill:#ffe8e8
    style F fill:#fff8e1
    style I fill:#e8f6e8
    style D1 fill:#f0f8ff
    style D2 fill:#f0f8ff
    style D3 fill:#f0f8ff
    style G fill:#e8f6e8
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<p><strong>Level 1: Partition and Local SVD</strong></p>
<ol type="1">
<li><p><strong>Partition</strong> <span class="math inline">X</span> into blocks along rows: <span class="math display">X = \begin{bmatrix} X_1 \\ X_2 \\ \vdots \\ X_m \end{bmatrix}</span></p></li>
<li><p><strong>Compute truncated SVD</strong> for each block, keeping only <span class="math inline">k</span> components: <span class="math display">X_i = U_i \Sigma_i V_i^T</span></p>
<p>where <span class="math inline">U_i</span> is <span class="math inline">n_i \times k</span>, <span class="math inline">\Sigma_i</span> is <span class="math inline">k \times k</span>, and <span class="math inline">V_i</span> is <span class="math inline">p \times k</span>.</p></li>
<li><p><strong>Form weighted matrices</strong> from the right singular vectors: <span class="math display">Z_i = V_i \Sigma_i</span></p>
<p>Each <span class="math inline">Z_i</span> is <span class="math inline">p \times k</span> - much smaller than the original <span class="math inline">X_i</span> which was <span class="math inline">n_i \times p</span>!</p></li>
</ol>
<p><strong>Level 2: Merge and Global SVD</strong></p>
<ol start="4" type="1">
<li><p><strong>Stack</strong> the <span class="math inline">Z_i</span> matrices: <span class="math display">Z = \begin{bmatrix} Z_1 \\ Z_2 \\ \vdots \\ Z_m \end{bmatrix}</span></p>
<p>This <span class="math inline">Z</span> matrix is <span class="math inline">mk \times k</span>. Since <span class="math inline">m</span> (blocks) and <span class="math inline">k</span> (components) are both small, <strong><span class="math inline">Z</span> fits in memory</strong>.</p></li>
<li><p><strong>Compute global SVD</strong> of <span class="math inline">Z</span>: <span class="math display">Z = U_Z \Sigma_Z V_Z^T</span></p></li>
<li><p><strong>Extract results:</strong></p>
<ul>
<li>Global singular values = <span class="math inline">\Sigma_Z</span></li>
<li>Global right singular vectors = <span class="math inline">V_Z</span></li>
<li>Global left singular vectors: multiply back through blocks</li>
</ul></li>
</ol>
<p><strong>Why this works:</strong> The row space of <span class="math inline">X</span> (spanned by right singular vectors) is well-approximated by combining the row spaces of blocks. Block SVDs capture main variation within each block; global SVD captures overall variation.</p>
<p><strong>Approximation quality:</strong> Not exact, but excellent for large <span class="math inline">n</span> relative to <span class="math inline">p</span> with sufficient <span class="math inline">k</span>. Error decreases as <span class="math inline">k</span> increases.</p>
</div>
<div id="tabset-5-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-3-tab">
<p><strong>Concrete example:</strong> <span class="math inline">X</span> is 100,000 × 20,000 (16 GB)</p>
<ul>
<li>Partition into <span class="math inline">m = 10</span> blocks of 10,000 rows</li>
<li>Keep <span class="math inline">k = 50</span> components</li>
</ul>
<p><strong>Memory per block during local SVD:</strong> - Block <span class="math inline">X_i</span>: 10,000 × 20,000 = 1.6 GB - <span class="math inline">U_i</span>: 10,000 × 50 = 4 MB<br>
- <span class="math inline">\Sigma_i</span>: 50 × 50 = 20 KB - <span class="math inline">V_i</span>: 20,000 × 50 = 8 MB - <strong>Peak: ~1.6 GB</strong> (dominated by the block)</p>
<p><strong>Memory for global SVD:</strong> - <span class="math inline">Z</span>: (10 × 50) × 20,000 = 8 MB - <strong>This easily fits in memory!</strong></p>
<p><strong>Result:</strong> 16 GB problem → 1.6 GB peak memory (10× reduction) while computing accurate approximation.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Hierarchical Decomposition Power
</div>
</div>
<div class="callout-body-container callout-body">
<p>The stacked <span class="math inline">Z</span> matrix is tiny: <span class="math inline">(m \times k) \times p</span> instead of <span class="math inline">n \times p</span>. With 10 blocks and 50 components, even for <span class="math inline">p=20{,}000</span>, that’s just 8 MB - fitting comfortably in RAM even when the original is 16 GB!</p>
</div>
</div>
<p>We’ve reduced a 16 GB problem to one requiring ~1.6 GB peak memory - a 10× reduction - while computing an accurate approximation to the full SVD.</p>
<p><strong>BigDataStatMeth implementation:</strong> The <code>bdSVD_hdf5()</code> function implements this hierarchical strategy with additional optimizations:</p>
<ul>
<li>Automatic selection of block size and hierarchy depth based on data dimensions and available memory</li>
<li>Parallel processing of independent blocks</li>
<li>Optional centering and scaling before SVD</li>
<li>Multiple hierarchy levels for very large datasets (you can set <code>q</code> levels with <code>k</code> blocks per level)</li>
</ul>
</section>
</section>
<section id="the-pattern-recognizing-block-wise-opportunities" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="the-pattern-recognizing-block-wise-opportunities"><span class="header-section-number">7</span> The Pattern: Recognizing Block-Wise Opportunities</h2>
<p>Looking across these examples, several patterns emerge for when and how algorithms can be adapted for block-wise processing:</p>
<section id="operations-with-additive-decomposition" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="operations-with-additive-decomposition"><span class="header-section-number">7.1</span> 1. Operations with Additive Decomposition</h3>
<p>If an operation can be expressed as summing contributions from different data portions, it’s straightforward to implement block-wise:</p>
<ul>
<li><strong>Examples:</strong> Means, sums, counts, sufficient statistics for simple models</li>
<li><strong>Strategy:</strong> Process each block, accumulate results, finalize</li>
<li><strong>Memory:</strong> One block plus small accumulator</li>
<li><strong>I/O:</strong> Single pass through data</li>
</ul>
</section>
<section id="operations-with-hierarchical-decomposition" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="operations-with-hierarchical-decomposition"><span class="header-section-number">7.2</span> 2. Operations with Hierarchical Decomposition</h3>
<p>If an operation can be computed hierarchically (computing on blocks, then combining block results), block-wise processing is feasible:</p>
<ul>
<li><strong>Examples:</strong> QR decomposition, SVD, certain optimization algorithms</li>
<li><strong>Strategy:</strong> Local computation on blocks, merge results, possibly iterate</li>
<li><strong>Memory:</strong> One block plus moderately-sized merge structure</li>
<li><strong>I/O:</strong> Multiple passes, but still practical</li>
</ul>
</section>
<section id="operations-requiring-global-information" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="operations-requiring-global-information"><span class="header-section-number">7.3</span> 3. Operations Requiring Global Information</h3>
<p>Some operations need information about the entire dataset to process any part of it:</p>
<ul>
<li><strong>Examples:</strong> Sorting, ranking, quantiles, certain graph algorithms</li>
<li><strong>Challenge:</strong> May require multiple passes or sophisticated algorithms</li>
<li><strong>Strategy:</strong> Often use approximation or sampling strategies</li>
</ul>
</section>
<section id="operations-that-dont-decompose-well" class="level3" data-number="7.4">
<h3 data-number="7.4" class="anchored" data-anchor-id="operations-that-dont-decompose-well"><span class="header-section-number">7.4</span> 4. Operations That Don’t Decompose Well</h3>
<p>A few operations are fundamentally difficult to decompose:</p>
<ul>
<li><strong>Examples:</strong> Some machine learning algorithms with complex dependencies, certain nonlinear optimizations</li>
<li><strong>Options:</strong> Use approximations, reformulate the problem, or accept that in-memory computation is necessary</li>
</ul>
<p>BigDataStatMeth focuses on category 1 and 2 operations, which cover most standard statistical analyses. For category 3, the package often provides approximate but practical solutions.</p>
</section>
</section>
<section id="practical-considerations" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="practical-considerations"><span class="header-section-number">8</span> Practical Considerations</h2>
<section id="block-size-selection" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="block-size-selection"><span class="header-section-number">8.1</span> Block Size Selection</h3>
<p>Choosing appropriate block sizes involves trade-offs:</p>
<p><strong>Too small blocks:</strong> - More overhead from reading many blocks - More function calls and loop iterations - Potentially less cache-friendly computations</p>
<p><strong>Too large blocks:</strong> - Risk of memory exhaustion - Less opportunity for parallelization - Longer time to first result</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Finding the Sweet Spot
</div>
</div>
<div class="callout-body-container callout-body">
<p>BigDataStatMeth uses smart heuristics based on available RAM, data dimensions, and operation type. Users can override defaults when they have specific system knowledge, but the automatic selection works well for most cases.</p>
<p><strong>Rule of thumb:</strong> Blocks should use ~10-20% of available RAM, leaving room for intermediate results and OS operations.</p>
</div>
</div>
<p>BigDataStatMeth uses heuristics based on: - Available RAM (conservative estimates) - Data dimensions (balanced partitioning) - Operation type (some need larger blocks for efficiency) - Computational complexity (CPU-bound vs.&nbsp;I/O-bound)</p>
<p>Users can override defaults when they have specific knowledge about their system.</p>
</section>
<section id="numerical-stability" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="numerical-stability"><span class="header-section-number">8.2</span> Numerical Stability</h3>
<p>Block-wise algorithms can affect numerical properties, though the impact varies by operation:</p>
<p><strong>Potential issues:</strong> - Accumulation of rounding errors across many blocks - Loss of precision in hierarchical methods (e.g., hierarchical SVD is approximate) - Order-dependent results for some operations - Cancellation errors when subtracting nearly equal numbers</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>What BigDataStatMeth Guarantees
</div>
</div>
<div class="callout-body-container callout-body">
<p>The package prioritizes <strong>practical numerical reliability</strong> over theoretical guarantees:</p>
<ul>
<li>✅ <strong>Tested algorithms:</strong> Extensively verified against in-memory methods</li>
<li>✅ <strong>Established methods:</strong> Uses well-known algorithms from numerical linear algebra literature</li>
<li>✅ <strong>Double precision:</strong> All computations use 64-bit floating point</li>
<li>✅ <strong>Documented approximations:</strong> When algorithms are approximate (hierarchical SVD), this is clearly stated</li>
</ul>
<p><strong>What is NOT guaranteed:</strong> - ❌ Bit-exact reproducibility across different hardware - ❌ Formal error bounds for all operations - ❌ Specific compensated algorithms (e.g., Kahan summation)</p>
</div>
</div>
<p><strong>Practical implications:</strong></p>
<p>For most statistical applications, the numerical precision is more than adequate: - PCA/SVD components match in-memory results to many decimal places - Regression coefficients are statistically indistinguishable - Hypothesis test results are identical</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>When to Worry About Numerical Precision
</div>
</div>
<div class="callout-body-container callout-body">
<p>If your application requires <strong>provable numerical bounds</strong> or <strong>arbitrary precision</strong>, BigDataStatMeth may not be suitable.</p>
<p>The package optimizes for the common case where <strong>statistical noise far exceeds numerical error</strong> - which describes most genomic and large-scale data analyses.</p>
</div>
</div>
<p><strong>User control:</strong></p>
<p>Some functions provide parameters to control accuracy: - SVD/PCA: <code>k</code> parameter controls how many components to compute (more = better approximation to full decomposition) - Iterative methods: tolerance parameters control convergence criteria</p>
<p>Check function documentation for available accuracy controls.</p>
</section>
<section id="parallelization" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="parallelization"><span class="header-section-number">8.3</span> Parallelization</h3>
<p>Many block-wise operations are embarrassingly parallel - blocks can be processed independently. BigDataStatMeth leverages this through <strong>OpenMP parallelization</strong> at the C++ level.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true" href="">Visual Workflow</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false" href="">How It Works</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-3" role="tab" aria-controls="tabset-6-3" aria-selected="false" href="">Pseudocode</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Matrix in HDF5&lt;br/&gt;divided into blocks] --&gt; B[OpenMP Scheduler&lt;br/&gt;threads=4]
    
    B --&gt; C1[Thread 1:&lt;br/&gt;Block 1]
    B --&gt; C2[Thread 2:&lt;br/&gt;Block 2]
    B --&gt; C3[Thread 3:&lt;br/&gt;Block 3]
    B --&gt; C4[Thread 4:&lt;br/&gt;Block 4]
    
    C1 --&gt; D1[Process&lt;br/&gt;independently]
    C2 --&gt; D2[Process&lt;br/&gt;independently]
    C3 --&gt; D3[Process&lt;br/&gt;independently]
    C4 --&gt; D4[Process&lt;br/&gt;independently]
    
    D1 --&gt; E[Combine results&lt;br/&gt;sequentially]
    D2 --&gt; E
    D3 --&gt; E
    D4 --&gt; E
    
    E --&gt; F[Final result]
    
    style A fill:#f0f8ff
    style B fill:#fff8e1
    style C1 fill:#e8f6e8
    style C2 fill:#e8f6e8
    style C3 fill:#e8f6e8
    style C4 fill:#e8f6e8
    style F fill:#e8f6e8
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<p><strong>OpenMP (Open Multi-Processing)</strong> is a parallel programming API for C++ that BigDataStatMeth uses internally. When you specify <code>threads = 4</code> in a function like <code>bdSVD_hdf5()</code>, the C++ code distributes independent block operations across 4 CPU cores.</p>
<p><strong>Key characteristics:</strong></p>
<ul>
<li><strong>Shared memory:</strong> All threads access the same HDF5 file, but read different blocks</li>
<li><strong>Thread-safe I/O:</strong> BigDataStatMeth ensures HDF5 reads don’t conflict between threads<br>
</li>
<li><strong>Load balancing:</strong> OpenMP automatically distributes blocks to available threads</li>
<li><strong>Overhead vs.&nbsp;benefit:</strong> Parallelism only helps when block processing time exceeds coordination overhead</li>
</ul>
<p><strong>When parallelization helps:</strong></p>
<ul>
<li>Large blocks that take seconds to process each</li>
<li>CPU-intensive operations (matrix multiplication, decompositions)</li>
<li>Many blocks to process (good load distribution)</li>
</ul>
<p><strong>When it doesn’t help:</strong></p>
<ul>
<li>Very small blocks (overhead dominates)</li>
<li>I/O-bound operations (disk is the bottleneck, not CPU)</li>
<li>Few blocks (can’t keep all cores busy)</li>
</ul>
<p>BigDataStatMeth automatically uses parallelization where beneficial. Users control thread count via the <code>threads</code> parameter.</p>
</div>
<div id="tabset-6-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-3-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Algorithm: ParallelBlockProcessing</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">// Input: HDF5 dataset, n_blocks, n_threads</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">// Output: Combined results from all blocks</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">// 1. Initialize</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">&lt;-</span> array to store each block<span class="ch">'s</span><span class="er"> output</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">// 2. Parallel processing (OpenMP)</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp parallel for num_threads(n_threads)</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> n_blocks<span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Each thread processes its assigned blocks</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> thread_id <span class="op">=</span> omp_get_thread_num<span class="op">();</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Thread-safe read</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  block_i <span class="op">=</span> read_hdf5_block<span class="op">(</span>i<span class="op">);</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Independent computation</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  result_i <span class="op">=</span> process_block<span class="op">(</span>block_i<span class="op">);</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Store result</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>  results<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> result_i<span class="op">;</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Free memory</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>  free<span class="op">(</span>block_i<span class="op">);</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">// 3. Combine results (sequential)</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>final_result <span class="op">=</span> combine_function<span class="op">(</span>results<span class="op">);</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="co">// 4. Return</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> final_result<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Thread Configuration
</div>
</div>
<div class="callout-body-container callout-body">
<p>Match <code>threads</code> to your CPU cores but leave 1-2 cores free for the system. For a 12-core machine, <code>threads = 10</code> is often optimal. Use <code>threads = 1</code> for debugging to simplify error tracking.</p>
</div>
</div>
</section>
</section>
<section id="implementing-your-own-block-wise-methods" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="implementing-your-own-block-wise-methods"><span class="header-section-number">9</span> Implementing Your Own Block-Wise Methods</h2>
<p>One of BigDataStatMeth’s design goals is enabling users to implement new statistical methods using block-wise processing. The package provides different levels of abstraction:</p>
<section id="architecture-overview" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="architecture-overview"><span class="header-section-number">9.1</span> Architecture Overview</h3>
<p>BigDataStatMeth uses a <strong>three-layer architecture</strong>:</p>
<p><strong>1. Internal C++ Layer (Accessible from C++, not from R):</strong></p>
<p>The lowest level consists of efficient C++ classes and functions that handle direct HDF5 file operations:</p>
<ul>
<li><code>hdf5Dataset</code> class - Wraps HDF5 C API for file access, provides block reading/writing</li>
<li>Efficient memory management and buffer handling</li>
<li>Direct HDF5 C API access for maximum performance</li>
<li>OpenMP-parallelized block iteration</li>
</ul>
<p><strong>Important:</strong> These internal components are <strong>NOT directly exposed to R users</strong> - you can’t call them from an R script. However, they <strong>ARE fully accessible if you’re developing new methods in C++</strong> using BigDataStatMeth as a header-only library. If you’re implementing a new statistical method in C++, you have full access to these low-level building blocks.</p>
<p>Each high-level algorithm (PCA, regression, etc.) uses these internal functions and manages its own block iteration strategy for optimal performance. The block-reading logic is algorithm-specific rather than exposed as general-purpose functions because different algorithms benefit from different iteration patterns.</p>
<p><strong>2. Mid-Level Functions (C++ with R bindings):</strong></p>
<p>Block-wise operations implemented in C++ but accessible from both R and C++:</p>
<ul>
<li><code>bdCrossprod_hdf5()</code> / <code>bdtCrossprod_hdf5()</code> - Crossproduct operations</li>
<li><code>bdblockmult_hdf5()</code> - Matrix multiplication</li>
<li><code>bdNormalize_hdf5()</code> - Centering and scaling</li>
<li><code>bdApply_hdf5()</code> - Apply functions to blocks</li>
</ul>
<p>These functions handle the complexity of block iteration, parallel processing, and result accumulation internally. From R, you simply call them with appropriate parameters.</p>
<p><strong>3. High-Level Statistical Methods (C++ with R bindings):</strong></p>
<p>Complete statistical analyses implemented using the mid-level functions:</p>
<ul>
<li><code>bdSVD_hdf5()</code> - Singular Value Decomposition</li>
<li><code>bdPCA_hdf5()</code> - Principal Component Analysis<br>
</li>
<li><code>bdQR_hdf5()</code> - QR Decomposition</li>
<li>Regression methods, association tests, etc.</li>
</ul>
</section>
<section id="developing-new-methods" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="developing-new-methods"><span class="header-section-number">9.2</span> Developing New Methods</h3>
<p><strong>Approach 1: Compose from existing functions (Recommended for R users)</strong></p>
<p>Use existing mid-level and high-level functions as building blocks. Example: implementing Canonical Correlation Analysis (CCA) in R:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CCA implementation using BigDataStatMeth functions</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>bdCCA_hdf5 <span class="ot">&lt;-</span> <span class="cf">function</span>(filename, X_dataset, Y_dataset, <span class="at">k =</span> <span class="dv">10</span>) {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1: Normalize both datasets</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bdNormalize_hdf5</span>(filename, X_dataset, <span class="at">bcenter =</span> <span class="cn">TRUE</span>, <span class="at">bscale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bdNormalize_hdf5</span>(filename, Y_dataset, <span class="at">bcenter =</span> <span class="cn">TRUE</span>, <span class="at">bscale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 2: Compute QR decomposition for each</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  qr_x <span class="ot">&lt;-</span> <span class="fu">bdQR_hdf5</span>(filename, X_dataset)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  qr_y <span class="ot">&lt;-</span> <span class="fu">bdQR_hdf5</span>(filename, Y_dataset)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 3: Compute cross-product of Q matrices</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  cross <span class="ot">&lt;-</span> <span class="fu">bdCrossprod_hdf5</span>(</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    filename, </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">A =</span> qr_x<span class="sc">$</span>Q_dataset,</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">B =</span> qr_y<span class="sc">$</span>Q_dataset</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 4: SVD of cross-product</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>  svd_result <span class="ot">&lt;-</span> <span class="fu">bdSVD_hdf5</span>(filename, cross<span class="sc">$</span>dataset, <span class="at">k =</span> k)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 5: Back-transform to get canonical variates</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># ... (using bdblockmult_hdf5 to multiply through)</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">correlations =</span> svd_result<span class="sc">$</span>d, ...))</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This approach leverages existing optimized functions without writing C++ code.</p>
<p><strong>Approach 2: Implement in C++ (For developers)</strong></p>
<p>For maximum performance or novel algorithms, implement directly in C++. You’ll work with:</p>
<ul>
<li><code>hdf5Dataset</code> class for file access</li>
<li>Eigen library for linear algebra</li>
<li>OpenMP for parallelization</li>
</ul>
<p>See the CCA implementation examples in the package source (<code>Example_bdCCA.cpp</code>, <code>Example_bdCCA.h</code>) which show both R-based and C++-based approaches to the same algorithm.</p>
<p><strong>Key consideration:</strong> The C++ approach requires understanding: - Memory management in C++ - HDF5 C API through <code>hdf5Dataset</code> wrapper<br>
- Eigen matrix operations - Thread safety for parallel operations</p>
<p>Most users will find composing from existing functions sufficient. The C++ API is there for those developing new core algorithms or requiring maximum performance.</p>
</section>
<section id="learning-from-examples" class="level3" data-number="9.3">
<h3 data-number="9.3" class="anchored" data-anchor-id="learning-from-examples"><span class="header-section-number">9.3</span> Learning from Examples</h3>
<p>The package includes several complete examples showing different implementation strategies:</p>
<ul>
<li><strong><code>Example_bdCCA_hdf5_R.R</code></strong> - CCA implemented purely in R using BigDataStatMeth functions</li>
<li><strong><code>Example_bdCCA.cpp/.h</code></strong> - CCA implemented in C++ for comparison</li>
<li><strong><code>Example_getQRbyBlocks.R</code></strong> - Hierarchical QR showing block partitioning strategies</li>
</ul>
<p>These examples demonstrate how to think through: 1. What can be computed block-by-block? 2. What intermediate results need to be merged? 3. What’s the memory footprint at each step? 4. When to write intermediate results to HDF5 vs.&nbsp;keep in memory?</p>
</section>
</section>
<section id="interactive-exercise" class="level2 exercise" data-number="10">
<h2 class="exercise anchored" data-number="10" data-anchor-id="interactive-exercise"><span class="header-section-number">10</span> Interactive Exercise</h2>
<section id="practice-analyzing-block-wise-efficiency" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="practice-analyzing-block-wise-efficiency"><span class="header-section-number">10.1</span> Practice: Analyzing Block-Wise Efficiency</h3>
<p>Understanding which operations work well with block-wise processing and which present challenges helps you design efficient analysis pipelines. This exercise develops that intuition.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Consider this analysis workflow</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>analyze_workflow <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 1: Compute column means</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  means <span class="ot">&lt;-</span> <span class="fu">bdColMeans_hdf5</span>(file, dataset)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 2: Center the data  </span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  centered <span class="ot">&lt;-</span> <span class="fu">bdNormalize_hdf5</span>(file, dataset, <span class="at">bcenter =</span> <span class="cn">TRUE</span>, <span class="at">bscale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 3: Compute t(X) %*% X</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  crossprod <span class="ot">&lt;-</span> <span class="fu">bdCrossprod_hdf5</span>(file, centered)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 4: Eigen-decomposition for PCA</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  pca <span class="ot">&lt;-</span> <span class="fu">bdSVD_hdf5</span>(file, crossprod)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Question: Which operations are most/least block-amenable?</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Reflection Questions
</div>
</div>
<div class="callout-body-container callout-body">
<p>Think through these scenarios - understanding the principles matters more than having “correct” answers:</p>
<p><strong>1. Operation Efficiency Analysis:</strong> - Which operation above is most naturally block-wise? Why? - Which operation requires the most inter-block coordination? - If you had to do this with limited memory, which step would be the bottleneck?</p>
<p><strong>2. Block Size Decisions:</strong> - For a 100,000 × 50,000 matrix with 32 GB RAM available, what block size would you choose? - What if you had 128 GB RAM? Would you still use blocks? - How would block size affect the accuracy of the results?</p>
<p><strong>3. Algorithm Adaptation:</strong> - Consider k-means clustering. Can you decompose it block-wise? - What about hierarchical clustering? - Which machine learning algorithms would be easy vs.&nbsp;hard to adapt?</p>
<p><strong>4. Designing Your Pipeline:</strong> - Your analysis needs: QC filtering, normalization, PCA, then regression - Which steps can process data block-by-block independently? - Which steps need access to summary statistics from all data? - Where would you store intermediate results?</p>
<p><strong>5. Trade-offs:</strong> - Smaller blocks = less memory but more disk I/O - Larger blocks = more memory but fewer I/O operations<br>
- For your system, where’s the sweet spot?</p>
<p>Try sketching out a block-wise version of your actual analysis pipeline. Which parts translate easily? Which require creative rethinking? This mental exercise builds intuition for designing efficient big data workflows.</p>
</div>
</div>
</section>
</section>
<section id="key-takeaways" class="level2 key-concept" data-number="11">
<h2 class="key-concept anchored" data-number="11" data-anchor-id="key-takeaways"><span class="header-section-number">11</span> Key Takeaways</h2>
<p>Let’s consolidate what you’ve learned about adapting algorithms for block-wise processing with disk-based data.</p>
<section id="essential-concepts" class="level3" data-number="11.1">
<h3 data-number="11.1" class="anchored" data-anchor-id="essential-concepts"><span class="header-section-number">11.1</span> Essential Concepts</h3>
<p><strong>The divide-process-combine paradigm</strong> underlies all block-wise computing. You partition data into manageable pieces, process each piece (often independently), then combine results to get the final answer. This simple pattern adapts to operations from simple means to complex matrix factorizations. The challenge lies in figuring out <em>what</em> to process and <em>how</em> to combine results validly.</p>
<p><strong>Block-amenable operations</strong> share common mathematical properties that make them decompose naturally. Operations that can be expressed as sums, products, or aggregations across independent portions of data work well. Computing means, sums, element-wise operations, and many matrix products fall into this category. The mathematical structure of these operations allows valid decomposition.</p>
<p><strong>Block-resistant operations</strong> require information flow between all parts of the data or produce outputs that scale problematically. Anything requiring global sorting, finding specific quantiles, or creating O(n²) outputs challenges block-wise approaches. These operations don’t decompose cleanly - they need special algorithmic tricks or fundamentally different approaches.</p>
<p><strong>Block size creates a memory-accuracy-speed trade-off</strong> with no universally optimal choice. Smaller blocks use less memory but require more disk I/O and potentially more approximation error in hierarchical algorithms. Larger blocks use more memory but require fewer I/O operations and may be more accurate. The optimal choice depends on your available RAM, disk speed, and accuracy requirements.</p>
<p><strong>Hierarchical processing</strong> enables algorithms that don’t naturally decompose to single-pass block operations. By creating multiple levels of computation - process blocks, merge results into smaller intermediate blocks, repeat until small enough - you can handle very large matrices while controlling memory usage at each level. This is how BigDataStatMeth implements complex operations like SVD/PCA.</p>
<p><strong>Composability is power.</strong> You can build complex analyses by composing simple block-wise operations. Rather than implementing every possible analysis from scratch in C++, combine existing functions: normalize, compute crossproduct, perform SVD, multiply back through. This compositional approach lets you implement new methods at the R level, leveraging optimized core operations.</p>
</section>
<section id="when-block-wise-processing-works-well" class="level3" data-number="11.2">
<h3 data-number="11.2" class="anchored" data-anchor-id="when-block-wise-processing-works-well"><span class="header-section-number">11.2</span> When Block-Wise Processing Works Well</h3>
<p>Understanding which problems benefit from block-wise approaches helps you make good architectural decisions for your analyses.</p>
<p>✅ <strong>Highly effective for:</strong></p>
<ul>
<li><p><strong>Matrix multiplication and products</strong> - These decompose naturally into block-block operations. BigDataStatMeth’s implementations are highly optimized and scale well.</p></li>
<li><p><strong>Element-wise operations</strong> - Operations like adding, subtracting, multiplying by scalars process each element independently. Perfect for block-wise processing with no communication overhead.</p></li>
<li><p><strong>Row or column operations</strong> - Computing means, sums, normalizations by rows or columns work naturally with blocks containing complete rows or columns.</p></li>
<li><p><strong>Many factorizations</strong> - SVD, QR, and Cholesky decompositions have hierarchical block-wise algorithms that maintain numerical accuracy while limiting memory usage.</p></li>
</ul>
<p>❌ <strong>Challenging for:</strong></p>
<ul>
<li><p><strong>Global operations</strong> - Finding the median, computing percentiles, or operations that require knowing the full data distribution don’t decompose easily.</p></li>
<li><p><strong>Fine-grained dependencies</strong> - Algorithms where each element depends on many others (like some iterative optimization methods) resist block decomposition.</p></li>
<li><p><strong>Operations creating large outputs</strong> - Computing all pairwise distances or correlations creates O(n²) results. Even block-wise approaches struggle when output size explodes.</p></li>
<li><p><strong>Highly iterative methods</strong> - Algorithms requiring many passes through data with convergence checks add overhead when each pass means disk I/O.</p></li>
</ul>
<p>For most statistical analyses in genomics and similar fields - PCA, regression, association tests, basic machine learning - block-wise approaches work very well. The operations these methods need decompose naturally. More specialized algorithms may require case-by-case evaluation of whether block-wise processing provides benefits.</p>
</section>
</section>
<section id="next-steps" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="next-steps"><span class="header-section-number">12</span> Next Steps</h2>
<p>You now understand how standard statistical algorithms adapt for disk-based data processing. This conceptual foundation prepares you to:</p>
<ul>
<li><a href="../fundamentals/linear-algebra.html"><strong>Understand Linear Algebra Foundations →</strong></a> Review the mathematical operations BigDataStatMeth implements</li>
<li><a href="../tutorials/getting-started.html"><strong>Getting Started Tutorial →</strong></a> Apply these concepts to your own data</li>
<li><a href="../workflows/canonical-correlation.qmd"><strong>CCA Implementation Example →</strong></a> See a complete complex method implemented block-wise</li>
</ul>
<hr>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Want to Learn More?
</div>
</div>
<div class="callout-body-container callout-body">
<p>The BigDataStatMeth paper provides mathematical details and proofs for the hierarchical algorithms. The <a href="../api-reference/cpp-api.html">C++ API documentation</a> shows lower-level implementation details if you want to understand exactly how operations are executed.</p>
</div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/isglobal-brge\.github\.io\/BigDataStatMeth\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Block-Wise Computing"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Adapting Statistical Algorithms for Disk-Based Data"</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>::: {.learning-objectives}</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="fu">### What You'll Learn</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>By the end of this section, you will:</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand the divide-process-combine paradigm of block-wise algorithms</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Know which operations decompose naturally to block-wise processing</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Recognize which algorithms are challenging to adapt for blocks</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand memory-computation trade-offs with block size</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>See concrete examples of block-wise matrix operations</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Know how to compose new methods from existing BigDataStatMeth functions</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="fu">## From In-Memory to Block-Wise: A Paradigm Shift</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>You now understand why large datasets don't fit in RAM and how HDF5 enables efficient access to disk-stored data. But knowing you *can* read arbitrary portions of a matrix from disk doesn't automatically tell you *how* to perform statistical analyses on that data. The challenge is algorithmic: how do you adapt methods designed for in-memory matrices to work with data that must be processed in pieces?</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>This is not merely an implementation detail - it requires rethinking how algorithms work. A standard PCA implementation might call <span class="in">`svd(X)`</span> where <span class="in">`X`</span> is a complete matrix in memory. That single function call encapsulates a sophisticated numerical algorithm, but it fundamentally assumes it can access any element of <span class="in">`X`</span> at any time. When X lives on disk, this assumption breaks. You must decompose the algorithm into steps that process manageable blocks of data, with intermediate results that fit in memory.</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>The mathematical operations remain the same - we're still computing eigenvalues, performing matrix multiplications, or fitting regression models. But the *computational strategy* changes fundamentally. This section explains how standard statistical methods are adapted for block-wise processing, using examples from BigDataStatMeth's implementation.</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Core Concept: Divide, Process, Combine</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>Block-wise computing follows a conceptual pattern that applies across different statistical methods:</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Divide:** Partition the data matrix into blocks that fit comfortably in memory</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Process:** Perform computations on each block independently (when possible)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Combine:** Merge the block-level results to obtain the final answer</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>The art lies in step 2 and 3 - figuring out what computations can be done on blocks independently, what information must be passed between blocks, and how to combine results validly. Not all algorithms decompose equally well, and some require sophisticated mathematical reformulations to work in a block-wise framework.</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>Let's start with simple examples and build toward more complex methods.</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example 1: Computing Means and Standard Deviations</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>Computing column means illustrates the simplest case of block-wise processing. Suppose you have a matrix with 100,000 rows and 50,000 columns that's too large for memory, but you can comfortably work with blocks of 10,000 rows at a time.</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="fu">### The In-Memory Approach</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Traditional approach - assumes X fits in memory</span></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>column_means <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(X)</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>This single line hides significant computation: for each column, R reads all 100,000 values, sums them, and divides by 100,000.</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Block-Wise Approach</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>For block-wise computation, we leverage a mathematical property: the mean of a set of values equals the weighted average of the means of subsets, where weights are the subset sizes.</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>::: {.panel-tabset}</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visual Diagram</span></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    A[Matrix on Disk&lt;br/&gt;<span class="dv">100</span>,<span class="dv">000</span> × <span class="dv">50</span>,<span class="dv">000</span>] --&gt; B[Initialize&lt;br/&gt;column_sums = <span class="dv">0</span>]</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    B --&gt; C{More blocks?}</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>    C --&gt;|Yes| D[Read Block i&lt;br/&gt;<span class="dv">10</span>,<span class="dv">000</span> rows]</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>    D --&gt; E[Compute&lt;br/&gt;colSums <span class="kw">for</span> block]</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>    E --&gt; F[Accumulate:&lt;br/&gt;column_sums += block_sums]</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    F --&gt; C</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>    C --&gt;|No| G[Finalize:&lt;br/&gt;means = column_sums / n_rows]</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>    style A fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>    style G fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>    style D fill:<span class="co">#fff8e1</span></span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>    style E fill:<span class="co">#fff8e1</span></span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>    style F fill:<span class="co">#fff8e1</span></span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step-by-Step Explanation</span></span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>**Step 1: Initialize accumulators**</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>We start by creating a vector to accumulate the sum of each column across all blocks. We also query the HDF5 file metadata to know how many rows exist in total and calculate how many blocks we'll need to process.</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>**Step 2: Process blocks sequentially**</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>For each block:</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Calculate boundaries:** Determine which rows belong to this block. Most blocks have <span class="in">`block_size`</span> rows, but the last block might be smaller.</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Read from disk:** Load only this block's rows into RAM. This is the key to memory efficiency - we never hold the entire matrix.</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Compute contribution:** Sum the values in each column of this block. This gives us a vector of length <span class="in">`n_cols`</span>.</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Accumulate:** Add this block's column sums to our running total. This works because addition is associative and commutative.</span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Free memory:** Explicitly release the block's memory before reading the next one. This ensures peak memory usage is just one block, not all blocks.</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>**Step 3: Calculate final means**</span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>After processing all blocks, we have the total sum for each column. Divide by the total number of rows to get the mean.</span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>**Why this works mathematically:**</span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>$$\text{mean}(X) = \frac{\sum_{i=1}^{n} x_i}{n} = \frac{\sum_{j=1}^{k} \sum_{i \in \text{block}_j} x_i}{n}$$</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>The inner sums are what we compute for each block, and we accumulate them in the outer sum.</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pseudocode</span></span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: BlockwiseMeans</span></span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: HDF5 dataset with n_rows × n_cols, block_size</span></span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: column_means vector of length n_cols</span></span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Initialize</span></span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>column_sums <span class="ot">&lt;-</span> vector of <span class="fu">zeros</span> (length n_cols)</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>n_rows_total <span class="ot">&lt;-</span> <span class="fu">get_total_rows_from_hdf5</span>()</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(n_rows_total <span class="sc">/</span> block_size)</span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Process each block</span></span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Define block boundaries</span></span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a>  start_row <span class="ot">&lt;-</span> (i<span class="dv">-1</span>) <span class="sc">*</span> block_size <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a>  end_row <span class="ot">&lt;-</span> <span class="fu">min</span>(i <span class="sc">*</span> block_size, n_rows_total)</span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from disk</span></span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a>  block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(start_row, end_row)</span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute block contribution</span></span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a>  block_sums <span class="ot">&lt;-</span> <span class="fu">compute_column_sums</span>(block)</span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Accumulate results</span></span>
<span id="cb9-131"><a href="#cb9-131" aria-hidden="true" tabindex="-1"></a>  column_sums <span class="ot">&lt;-</span> column_sums <span class="sc">+</span> block_sums</span>
<span id="cb9-132"><a href="#cb9-132" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Free memory</span></span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(block)</span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Finalize computation</span></span>
<span id="cb9-138"><a href="#cb9-138" aria-hidden="true" tabindex="-1"></a>column_means <span class="ot">&lt;-</span> column_sums <span class="sc">/</span> n_rows_total</span>
<span id="cb9-139"><a href="#cb9-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Return result</span></span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(column_means)</span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a><span class="fu">## Memory Efficiency</span></span>
<span id="cb9-148"><a href="#cb9-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-149"><a href="#cb9-149" aria-hidden="true" tabindex="-1"></a>Peak memory is one block (10,000 × 50,000 = ~40 MB for doubles) plus the accumulator vector (50,000 values = ~0.4 MB).</span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a>**Total: ~40 MB instead of 40 GB for the full matrix** - a 1000× reduction!</span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-154"><a href="#cb9-154" aria-hidden="true" tabindex="-1"></a>**Key insight:** For operations that can be expressed as combining independent contributions from blocks (sums, counts), block-wise processing is straightforward. The mathematical property that makes this work is **additive decomposition**: the sum over all data equals the sum of sums over blocks.</span>
<span id="cb9-155"><a href="#cb9-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a>**BigDataStatMeth implementation:** This is handled internally by C++ functions like <span class="in">`get_HDF5_mean_sd_by_column()`</span> (or <span class="in">`by_row`</span> variant) which manage block reading, computation, and accumulation efficiently using OpenMP parallelization when multiple cores are available.</span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why Standard Deviation Is Slightly More Complex</span></span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a>Standard deviation requires both means and squared deviations from means. You might think you could compute it in one pass through blocks, but there's a subtle issue: you need the *overall* mean to compute deviations, but you won't know the overall mean until you've seen all blocks.</span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb9-163"><a href="#cb9-163" aria-hidden="true" tabindex="-1"></a><span class="fu">## Two-Pass Algorithm Required</span></span>
<span id="cb9-164"><a href="#cb9-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-165"><a href="#cb9-165" aria-hidden="true" tabindex="-1"></a>Computing standard deviation requires **two complete passes** through the data:</span>
<span id="cb9-166"><a href="#cb9-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-167"><a href="#cb9-167" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Pass 1:** Compute overall means  </span>
<span id="cb9-168"><a href="#cb9-168" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Pass 2:** Compute squared deviations using those means</span>
<span id="cb9-169"><a href="#cb9-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-170"><a href="#cb9-170" aria-hidden="true" tabindex="-1"></a>This doubles I/O but keeps memory constant.</span>
<span id="cb9-171"><a href="#cb9-171" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-172"><a href="#cb9-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-173"><a href="#cb9-173" aria-hidden="true" tabindex="-1"></a>::: {.panel-tabset}</span>
<span id="cb9-174"><a href="#cb9-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-175"><a href="#cb9-175" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visual Workflow</span></span>
<span id="cb9-176"><a href="#cb9-176" aria-hidden="true" tabindex="-1"></a>Two passes through the data:</span>
<span id="cb9-177"><a href="#cb9-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-180"><a href="#cb9-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb9-181"><a href="#cb9-181" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb9-182"><a href="#cb9-182" aria-hidden="true" tabindex="-1"></a>    A[Dataset on Disk] --&gt; B[Pass <span class="dv">1</span>:&lt;br/&gt;Compute Means]</span>
<span id="cb9-183"><a href="#cb9-183" aria-hidden="true" tabindex="-1"></a>    B --&gt; C[Store means&lt;br/&gt;in memory]</span>
<span id="cb9-184"><a href="#cb9-184" aria-hidden="true" tabindex="-1"></a>    C --&gt; D[Pass <span class="dv">2</span>:&lt;br/&gt;Start over]</span>
<span id="cb9-185"><a href="#cb9-185" aria-hidden="true" tabindex="-1"></a>    D --&gt; E[Read Block i]</span>
<span id="cb9-186"><a href="#cb9-186" aria-hidden="true" tabindex="-1"></a>    E --&gt; F[Center:&lt;br/&gt;block - means]</span>
<span id="cb9-187"><a href="#cb9-187" aria-hidden="true" tabindex="-1"></a>    F --&gt; G[Square:&lt;br/&gt;centered²]</span>
<span id="cb9-188"><a href="#cb9-188" aria-hidden="true" tabindex="-1"></a>    G --&gt; H[Accumulate&lt;br/&gt;squared_devs]</span>
<span id="cb9-189"><a href="#cb9-189" aria-hidden="true" tabindex="-1"></a>    H --&gt; I{More blocks?}</span>
<span id="cb9-190"><a href="#cb9-190" aria-hidden="true" tabindex="-1"></a>    I --&gt;|Yes| E</span>
<span id="cb9-191"><a href="#cb9-191" aria-hidden="true" tabindex="-1"></a>    I --&gt;|No| J[Finalize:&lt;br/&gt;<span class="fu">sqrt</span> of sum over n<span class="dv">-1</span>]</span>
<span id="cb9-192"><a href="#cb9-192" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-193"><a href="#cb9-193" aria-hidden="true" tabindex="-1"></a>    style A fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-194"><a href="#cb9-194" aria-hidden="true" tabindex="-1"></a>    style B fill:<span class="co">#fff8e1</span></span>
<span id="cb9-195"><a href="#cb9-195" aria-hidden="true" tabindex="-1"></a>    style C fill:<span class="co">#ffe8e8</span></span>
<span id="cb9-196"><a href="#cb9-196" aria-hidden="true" tabindex="-1"></a>    style J fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-197"><a href="#cb9-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-198"><a href="#cb9-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-199"><a href="#cb9-199" aria-hidden="true" tabindex="-1"></a><span class="fu">### Detailed Explanation</span></span>
<span id="cb9-200"><a href="#cb9-200" aria-hidden="true" tabindex="-1"></a>**Why two passes are necessary:**</span>
<span id="cb9-201"><a href="#cb9-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-202"><a href="#cb9-202" aria-hidden="true" tabindex="-1"></a>To compute standard deviation, we need: $\text{SD} = \sqrt{\frac{\sum (x_i - \bar{x})^2}{n-1}}$</span>
<span id="cb9-203"><a href="#cb9-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-204"><a href="#cb9-204" aria-hidden="true" tabindex="-1"></a>The problem: we need $\bar{x}$ (the mean) to compute each $(x_i - \bar{x})^2$ term. But we can't know the overall mean until we've processed all blocks.</span>
<span id="cb9-205"><a href="#cb9-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-206"><a href="#cb9-206" aria-hidden="true" tabindex="-1"></a>**Pass 1: Compute means (same as before)**</span>
<span id="cb9-207"><a href="#cb9-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-208"><a href="#cb9-208" aria-hidden="true" tabindex="-1"></a>Use the block-wise mean algorithm to get the global mean for each column.</span>
<span id="cb9-209"><a href="#cb9-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-210"><a href="#cb9-210" aria-hidden="true" tabindex="-1"></a>**Pass 2: Compute squared deviations**</span>
<span id="cb9-211"><a href="#cb9-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-212"><a href="#cb9-212" aria-hidden="true" tabindex="-1"></a>Now that we know the means, we:</span>
<span id="cb9-213"><a href="#cb9-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-214"><a href="#cb9-214" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Read each block again:** Yes, this means reading the entire dataset twice. For very large datasets on slow storage, this I/O cost matters.</span>
<span id="cb9-215"><a href="#cb9-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-216"><a href="#cb9-216" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Center the block:** Subtract the global mean from each column. This "centering" operation broadcasts the mean vector across all rows of the block.</span>
<span id="cb9-217"><a href="#cb9-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-218"><a href="#cb9-218" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Square element-wise:** Each centered value is squared: $(x - \bar{x})^2$</span>
<span id="cb9-219"><a href="#cb9-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-220"><a href="#cb9-220" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Accumulate squared deviations:** Sum these squared values, column by column, across all blocks.</span>
<span id="cb9-221"><a href="#cb9-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-222"><a href="#cb9-222" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Finalize:** After processing all blocks, divide by $n-1$ (Bessel's correction for sample variance) and take the square root.</span>
<span id="cb9-223"><a href="#cb9-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-224"><a href="#cb9-224" aria-hidden="true" tabindex="-1"></a>**Alternative: One-pass algorithm**</span>
<span id="cb9-225"><a href="#cb9-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-226"><a href="#cb9-226" aria-hidden="true" tabindex="-1"></a>There exist numerically stable one-pass algorithms (e.g., Welford's algorithm) that compute mean and variance simultaneously. However, they're slightly more complex to implement and can be less numerically stable for data with large means and small variances. BigDataStatMeth opts for the two-pass approach for clarity and numerical reliability in typical statistical applications.</span>
<span id="cb9-227"><a href="#cb9-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-228"><a href="#cb9-228" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pseudocode</span></span>
<span id="cb9-229"><a href="#cb9-229" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb9-230"><a href="#cb9-230" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: BlockwiseStandardDeviation</span></span>
<span id="cb9-231"><a href="#cb9-231" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: HDF5 dataset with n_rows × n_cols, block_size</span></span>
<span id="cb9-232"><a href="#cb9-232" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: column_sds vector of length n_cols</span></span>
<span id="cb9-233"><a href="#cb9-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-234"><a href="#cb9-234" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass 1: Compute means</span></span>
<span id="cb9-235"><a href="#cb9-235" aria-hidden="true" tabindex="-1"></a>column_means <span class="ot">&lt;-</span> <span class="fu">BlockwiseMeans</span>(dataset, block_size)</span>
<span id="cb9-236"><a href="#cb9-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-237"><a href="#cb9-237" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass 2: Compute squared deviations</span></span>
<span id="cb9-238"><a href="#cb9-238" aria-hidden="true" tabindex="-1"></a>squared_devs <span class="ot">&lt;-</span> vector of <span class="fu">zeros</span> (length n_cols)</span>
<span id="cb9-239"><a href="#cb9-239" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(n_rows_total <span class="sc">/</span> block_size)</span>
<span id="cb9-240"><a href="#cb9-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-241"><a href="#cb9-241" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb9-242"><a href="#cb9-242" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from disk</span></span>
<span id="cb9-243"><a href="#cb9-243" aria-hidden="true" tabindex="-1"></a>  block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(start_row, end_row)</span>
<span id="cb9-244"><a href="#cb9-244" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-245"><a href="#cb9-245" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Center the block (subtract column means)</span></span>
<span id="cb9-246"><a href="#cb9-246" aria-hidden="true" tabindex="-1"></a>  centered_block <span class="ot">&lt;-</span> block <span class="sc">-</span> column_means  <span class="co"># Broadcast subtraction</span></span>
<span id="cb9-247"><a href="#cb9-247" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-248"><a href="#cb9-248" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Square element-wise</span></span>
<span id="cb9-249"><a href="#cb9-249" aria-hidden="true" tabindex="-1"></a>  squared_block <span class="ot">&lt;-</span> centered_block<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb9-250"><a href="#cb9-250" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-251"><a href="#cb9-251" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sum squared deviations for this block</span></span>
<span id="cb9-252"><a href="#cb9-252" aria-hidden="true" tabindex="-1"></a>  block_sq_devs <span class="ot">&lt;-</span> <span class="fu">compute_column_sums</span>(squared_block)</span>
<span id="cb9-253"><a href="#cb9-253" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-254"><a href="#cb9-254" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Accumulate</span></span>
<span id="cb9-255"><a href="#cb9-255" aria-hidden="true" tabindex="-1"></a>  squared_devs <span class="ot">&lt;-</span> squared_devs <span class="sc">+</span> block_sq_devs</span>
<span id="cb9-256"><a href="#cb9-256" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-257"><a href="#cb9-257" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Free memory</span></span>
<span id="cb9-258"><a href="#cb9-258" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(block)</span>
<span id="cb9-259"><a href="#cb9-259" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-260"><a href="#cb9-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-261"><a href="#cb9-261" aria-hidden="true" tabindex="-1"></a><span class="co"># Finalize: compute standard deviation</span></span>
<span id="cb9-262"><a href="#cb9-262" aria-hidden="true" tabindex="-1"></a>column_sds <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(squared_devs <span class="sc">/</span> (n_rows_total <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb9-263"><a href="#cb9-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-264"><a href="#cb9-264" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(column_sds)</span>
<span id="cb9-265"><a href="#cb9-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-266"><a href="#cb9-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-267"><a href="#cb9-267" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-268"><a href="#cb9-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-269"><a href="#cb9-269" aria-hidden="true" tabindex="-1"></a>**I/O cost:** This two-pass approach doubles the I/O (reading data twice), but keeps memory requirements constant regardless of data size.</span>
<span id="cb9-270"><a href="#cb9-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-271"><a href="#cb9-271" aria-hidden="true" tabindex="-1"></a>**BigDataStatMeth implementation:** The package provides two ways to compute these statistics:</span>
<span id="cb9-272"><a href="#cb9-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-273"><a href="#cb9-273" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**`bdNormalize_hdf5()`** - Performs centering and/or scaling in-place, automatically handling the multi-pass computation. Results are written back to the HDF5 file.</span>
<span id="cb9-274"><a href="#cb9-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-275"><a href="#cb9-275" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**`bdgetSDandMean_hdf5()`** - Computes means and standard deviations and returns them either in memory (<span class="in">`onmemory = TRUE`</span>) or stores them in the HDF5 file (<span class="in">`onmemory = FALSE`</span>) for later use. This is useful when you need the statistics themselves, not just normalized data.</span>
<span id="cb9-276"><a href="#cb9-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-277"><a href="#cb9-277" aria-hidden="true" tabindex="-1"></a>Both functions use the C++ internal implementation <span class="in">`get_HDF5_mean_sd_by_column()`</span> which handles block iteration, parallel computation with OpenMP, and numerically stable accumulation.</span>
<span id="cb9-278"><a href="#cb9-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-279"><a href="#cb9-279" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example 2: Matrix Multiplication by Blocks</span></span>
<span id="cb9-280"><a href="#cb9-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-281"><a href="#cb9-281" aria-hidden="true" tabindex="-1"></a>Matrix multiplication is fundamental to many statistical methods - it appears in linear regression, principal component analysis, and countless other algorithms. It also illustrates a more complex block-wise pattern because the result depends on interactions between different parts of both input matrices.</span>
<span id="cb9-282"><a href="#cb9-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-283"><a href="#cb9-283" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Mathematical Foundation</span></span>
<span id="cb9-284"><a href="#cb9-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-285"><a href="#cb9-285" aria-hidden="true" tabindex="-1"></a>Recall that matrix multiplication $C = A \times B$ where $A$ is $m \times k$ and $B$ is $k \times n$, produces:</span>
<span id="cb9-286"><a href="#cb9-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-287"><a href="#cb9-287" aria-hidden="true" tabindex="-1"></a>$$C_{ij} = \sum_{p=1}^{k} A_{ip} \times B_{pj}$$</span>
<span id="cb9-288"><a href="#cb9-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-289"><a href="#cb9-289" aria-hidden="true" tabindex="-1"></a>Each element of $C$ is a dot product of a row from $A$ and a column from $B$. The key insight for block-wise processing is that this operation can be decomposed spatially - we can compute different regions of $C$ independently.</span>
<span id="cb9-290"><a href="#cb9-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-291"><a href="#cb9-291" aria-hidden="true" tabindex="-1"></a><span class="fu">### Block-Wise Strategy</span></span>
<span id="cb9-292"><a href="#cb9-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-293"><a href="#cb9-293" aria-hidden="true" tabindex="-1"></a>If we partition $A$ into row blocks and $B$ into column blocks:</span>
<span id="cb9-294"><a href="#cb9-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-295"><a href="#cb9-295" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-296"><a href="#cb9-296" aria-hidden="true" tabindex="-1"></a>A = \begin{bmatrix} A_1 <span class="sc">\\</span> A_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> A_m \end{bmatrix}, \quad</span>
<span id="cb9-297"><a href="#cb9-297" aria-hidden="true" tabindex="-1"></a>B = \begin{bmatrix} B_1 &amp; B_2 &amp; \cdots &amp; B_n \end{bmatrix}</span>
<span id="cb9-298"><a href="#cb9-298" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-299"><a href="#cb9-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-300"><a href="#cb9-300" aria-hidden="true" tabindex="-1"></a>Then each block of the result $C_{ij} = A_i \times B_j$ can be computed independently. More usefully, if we partition along the shared dimension (the $k$ dimension):</span>
<span id="cb9-301"><a href="#cb9-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-302"><a href="#cb9-302" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-303"><a href="#cb9-303" aria-hidden="true" tabindex="-1"></a>A = \begin{bmatrix} A_1 &amp; A_2 &amp; \cdots &amp; A_p \end{bmatrix}, \quad</span>
<span id="cb9-304"><a href="#cb9-304" aria-hidden="true" tabindex="-1"></a>B = \begin{bmatrix} B_1 <span class="sc">\\</span> B_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> B_p \end{bmatrix}</span>
<span id="cb9-305"><a href="#cb9-305" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-306"><a href="#cb9-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-307"><a href="#cb9-307" aria-hidden="true" tabindex="-1"></a>Then: $C = \sum_{i=1}^{p} A_i \times B_i$</span>
<span id="cb9-308"><a href="#cb9-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-309"><a href="#cb9-309" aria-hidden="true" tabindex="-1"></a>This decomposition means we can:</span>
<span id="cb9-310"><a href="#cb9-310" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Read one block pair $(A_i, B_i)$ at a time from disk</span>
<span id="cb9-311"><a href="#cb9-311" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Compute their contribution to $C$</span>
<span id="cb9-312"><a href="#cb9-312" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Accumulate the result</span>
<span id="cb9-313"><a href="#cb9-313" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Never hold more than two blocks and the accumulator in memory</span>
<span id="cb9-314"><a href="#cb9-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-315"><a href="#cb9-315" aria-hidden="true" tabindex="-1"></a><span class="fu">### Practical Implementation</span></span>
<span id="cb9-316"><a href="#cb9-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-317"><a href="#cb9-317" aria-hidden="true" tabindex="-1"></a>::: {.panel-tabset}</span>
<span id="cb9-318"><a href="#cb9-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-319"><a href="#cb9-319" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visual Strategy</span></span>
<span id="cb9-322"><a href="#cb9-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb9-323"><a href="#cb9-323" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb9-324"><a href="#cb9-324" aria-hidden="true" tabindex="-1"></a>    A[<span class="ot">"</span><span class="st">Matrix A m × k&lt;br/&gt;on disk</span><span class="ot">"</span>] --&gt; B[<span class="ot">"</span><span class="st">Partition along&lt;br/&gt;k dimension</span><span class="ot">"</span>]</span>
<span id="cb9-325"><a href="#cb9-325" aria-hidden="true" tabindex="-1"></a>    C[<span class="ot">"</span><span class="st">Matrix B k × n&lt;br/&gt;on disk</span><span class="ot">"</span>] --&gt; B</span>
<span id="cb9-326"><a href="#cb9-326" aria-hidden="true" tabindex="-1"></a>    B --&gt; D[<span class="ot">"</span><span class="st">Block pairs:&lt;br/&gt;A₁ B₁, A₂ B₂, ...</span><span class="ot">"</span>]</span>
<span id="cb9-327"><a href="#cb9-327" aria-hidden="true" tabindex="-1"></a>    D --&gt; E{More blocks?}</span>
<span id="cb9-328"><a href="#cb9-328" aria-hidden="true" tabindex="-1"></a>    E --&gt;|Yes| F[<span class="ot">"</span><span class="st">Read block pair&lt;br/&gt;Aᵢ Bᵢ</span><span class="ot">"</span>]</span>
<span id="cb9-329"><a href="#cb9-329" aria-hidden="true" tabindex="-1"></a>    F --&gt; G[<span class="ot">"</span><span class="st">Compute&lt;br/&gt;Aᵢ × Bᵢ</span><span class="ot">"</span>]</span>
<span id="cb9-330"><a href="#cb9-330" aria-hidden="true" tabindex="-1"></a>    G --&gt; H[<span class="ot">"</span><span class="st">Accumulate:&lt;br/&gt;C += Aᵢ × Bᵢ</span><span class="ot">"</span>]</span>
<span id="cb9-331"><a href="#cb9-331" aria-hidden="true" tabindex="-1"></a>    H --&gt; E</span>
<span id="cb9-332"><a href="#cb9-332" aria-hidden="true" tabindex="-1"></a>    E --&gt;|No| I[<span class="ot">"</span><span class="st">Result matrix&lt;br/&gt;C m × n</span><span class="ot">"</span>]</span>
<span id="cb9-333"><a href="#cb9-333" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-334"><a href="#cb9-334" aria-hidden="true" tabindex="-1"></a>    style A fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-335"><a href="#cb9-335" aria-hidden="true" tabindex="-1"></a>    style C fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-336"><a href="#cb9-336" aria-hidden="true" tabindex="-1"></a>    style I fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-337"><a href="#cb9-337" aria-hidden="true" tabindex="-1"></a>    style F fill:<span class="co">#fff8e1</span></span>
<span id="cb9-338"><a href="#cb9-338" aria-hidden="true" tabindex="-1"></a>    style G fill:<span class="co">#fff8e1</span></span>
<span id="cb9-339"><a href="#cb9-339" aria-hidden="true" tabindex="-1"></a>    style H fill:<span class="co">#fff8e1</span></span>
<span id="cb9-340"><a href="#cb9-340" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-341"><a href="#cb9-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-342"><a href="#cb9-342" aria-hidden="true" tabindex="-1"></a><span class="fu">### Algorithm Explanation</span></span>
<span id="cb9-343"><a href="#cb9-343" aria-hidden="true" tabindex="-1"></a>**Key insight:** Matrix multiplication can be decomposed along the shared dimension (the $k$ in $A_{m \times k} \times B_{k \times n}$).</span>
<span id="cb9-344"><a href="#cb9-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-345"><a href="#cb9-345" aria-hidden="true" tabindex="-1"></a>**Step 1: Initialize**</span>
<span id="cb9-346"><a href="#cb9-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-347"><a href="#cb9-347" aria-hidden="true" tabindex="-1"></a>Create a zero matrix $C$ of dimensions $m \times n$ to accumulate results. Calculate how many blocks we'll need along the $k$ dimension.</span>
<span id="cb9-348"><a href="#cb9-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-349"><a href="#cb9-349" aria-hidden="true" tabindex="-1"></a>**Step 2: Process each block pair**</span>
<span id="cb9-350"><a href="#cb9-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-351"><a href="#cb9-351" aria-hidden="true" tabindex="-1"></a>For each block $i$:</span>
<span id="cb9-352"><a href="#cb9-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-353"><a href="#cb9-353" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Read from A:** Extract columns <span class="in">`start:end`</span> of matrix $A$. This gives us a "tall thin" matrix: $m$ rows (all of them) by <span class="in">`block_width`</span> columns (just this block's slice).</span>
<span id="cb9-354"><a href="#cb9-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-355"><a href="#cb9-355" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Read from B:** Extract rows <span class="in">`start:end`</span> of matrix $B$. This gives us a "short wide" matrix: <span class="in">`block_width`</span> rows (matching A's columns) by $n$ columns (all of them).</span>
<span id="cb9-356"><a href="#cb9-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-357"><a href="#cb9-357" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Multiply:** Compute the standard matrix product of these two small pieces. The result is $m \times n$ - the same size as our final answer.</span>
<span id="cb9-358"><a href="#cb9-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-359"><a href="#cb9-359" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Accumulate:** Add this contribution to $C$. This works because:</span>
<span id="cb9-360"><a href="#cb9-360" aria-hidden="true" tabindex="-1"></a>   $$C = A \times B = \sum_{i=1}^{blocks} A_i \times B_i$$</span>
<span id="cb9-361"><a href="#cb9-361" aria-hidden="true" tabindex="-1"></a>   where $A_i$ and $B_i$ are the block slices.</span>
<span id="cb9-362"><a href="#cb9-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-363"><a href="#cb9-363" aria-hidden="true" tabindex="-1"></a>**Step 3: Handle result**</span>
<span id="cb9-364"><a href="#cb9-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-365"><a href="#cb9-365" aria-hidden="true" tabindex="-1"></a>If $C$ fits in memory, return it directly. If not (which can happen when $m$ and $n$ are both large), write it to HDF5 incrementally and return a reference.</span>
<span id="cb9-366"><a href="#cb9-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-367"><a href="#cb9-367" aria-hidden="true" tabindex="-1"></a>**Memory analysis:**</span>
<span id="cb9-368"><a href="#cb9-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-369"><a href="#cb9-369" aria-hidden="true" tabindex="-1"></a>Peak memory = $A_{block}$ + $B_{block}$ + $C$</span>
<span id="cb9-370"><a href="#cb9-370" aria-hidden="true" tabindex="-1"></a>= $(m \times b) + (b \times n) + (m \times n)$ values</span>
<span id="cb9-371"><a href="#cb9-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-372"><a href="#cb9-372" aria-hidden="true" tabindex="-1"></a>For large $k$ but moderate $m$ and $n$, this is much less than holding full $A$ and $B$ which would require $(m \times k) + (k \times n)$ values.</span>
<span id="cb9-373"><a href="#cb9-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-374"><a href="#cb9-374" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pseudocode</span></span>
<span id="cb9-375"><a href="#cb9-375" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb9-376"><a href="#cb9-376" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: BlockwiseMatrixMultiplication</span></span>
<span id="cb9-377"><a href="#cb9-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: Matrix A m × k in HDF5, Matrix B k × n in HDF5, block_size</span></span>
<span id="cb9-378"><a href="#cb9-378" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: Matrix C = A × B m × n</span></span>
<span id="cb9-379"><a href="#cb9-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-380"><a href="#cb9-380" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize result matrix</span></span>
<span id="cb9-381"><a href="#cb9-381" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> zero matrix m × n</span>
<span id="cb9-382"><a href="#cb9-382" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(k <span class="sc">/</span> block_size)</span>
<span id="cb9-383"><a href="#cb9-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-384"><a href="#cb9-384" aria-hidden="true" tabindex="-1"></a><span class="co"># Process blocks along shared dimension</span></span>
<span id="cb9-385"><a href="#cb9-385" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb9-386"><a href="#cb9-386" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Determine block range along k dimension</span></span>
<span id="cb9-387"><a href="#cb9-387" aria-hidden="true" tabindex="-1"></a>  start_idx <span class="ot">&lt;-</span> (i<span class="dv">-1</span>) <span class="sc">*</span> block_size <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb9-388"><a href="#cb9-388" aria-hidden="true" tabindex="-1"></a>  end_idx <span class="ot">&lt;-</span> <span class="fu">min</span>(i <span class="sc">*</span> block_size, k)</span>
<span id="cb9-389"><a href="#cb9-389" aria-hidden="true" tabindex="-1"></a>  block_width <span class="ot">&lt;-</span> end_idx <span class="sc">-</span> start_idx <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb9-390"><a href="#cb9-390" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-391"><a href="#cb9-391" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from A (columns start_idx:end_idx)</span></span>
<span id="cb9-392"><a href="#cb9-392" aria-hidden="true" tabindex="-1"></a>  A_block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_columns</span>(A, start_idx<span class="sc">:</span>end_idx)  <span class="co"># m × block_width</span></span>
<span id="cb9-393"><a href="#cb9-393" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-394"><a href="#cb9-394" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read corresponding block from B (rows start_idx:end_idx)</span></span>
<span id="cb9-395"><a href="#cb9-395" aria-hidden="true" tabindex="-1"></a>  B_block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(B, start_idx<span class="sc">:</span>end_idx)     <span class="co"># block_width × n</span></span>
<span id="cb9-396"><a href="#cb9-396" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-397"><a href="#cb9-397" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute this block's contribution to C</span></span>
<span id="cb9-398"><a href="#cb9-398" aria-hidden="true" tabindex="-1"></a>  C_contribution <span class="ot">&lt;-</span> A_block <span class="sc">%*%</span> B_block  <span class="co"># Standard matrix mult</span></span>
<span id="cb9-399"><a href="#cb9-399" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-400"><a href="#cb9-400" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Accumulate into result</span></span>
<span id="cb9-401"><a href="#cb9-401" aria-hidden="true" tabindex="-1"></a>  C <span class="ot">&lt;-</span> C <span class="sc">+</span> C_contribution</span>
<span id="cb9-402"><a href="#cb9-402" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-403"><a href="#cb9-403" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Free memory</span></span>
<span id="cb9-404"><a href="#cb9-404" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(A_block, B_block)</span>
<span id="cb9-405"><a href="#cb9-405" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-406"><a href="#cb9-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-407"><a href="#cb9-407" aria-hidden="true" tabindex="-1"></a><span class="co"># Write result (if too large for memory, write directly to HDF5)</span></span>
<span id="cb9-408"><a href="#cb9-408" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (C fits <span class="cf">in</span> memory) {</span>
<span id="cb9-409"><a href="#cb9-409" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(C)</span>
<span id="cb9-410"><a href="#cb9-410" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb9-411"><a href="#cb9-411" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_to_hdf5</span>(C)</span>
<span id="cb9-412"><a href="#cb9-412" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(HDF5_reference)</span>
<span id="cb9-413"><a href="#cb9-413" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-414"><a href="#cb9-414" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-415"><a href="#cb9-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-416"><a href="#cb9-416" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-417"><a href="#cb9-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-418"><a href="#cb9-418" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb9-419"><a href="#cb9-419" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spatial Decomposition</span></span>
<span id="cb9-420"><a href="#cb9-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-421"><a href="#cb9-421" aria-hidden="true" tabindex="-1"></a>Matrix multiplication is decomposed **spatially** along the shared dimension $k$. Each block pair contributes independently to the final result - this is different from the **temporal decomposition** used for means where blocks contribute sequentially.</span>
<span id="cb9-422"><a href="#cb9-422" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-423"><a href="#cb9-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-424"><a href="#cb9-424" aria-hidden="true" tabindex="-1"></a>**BigDataStatMeth implementation:** The <span class="in">`bdblockmult_hdf5()`</span> function implements this strategy with additional optimizations:</span>
<span id="cb9-425"><a href="#cb9-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-426"><a href="#cb9-426" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Automatic block size selection based on available memory</span>
<span id="cb9-427"><a href="#cb9-427" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Writing results directly to HDF5 to handle cases where even the result matrix is too large</span>
<span id="cb9-428"><a href="#cb9-428" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Parallel processing of independent block multiplications using OpenMP when multiple cores are available</span>
<span id="cb9-429"><a href="#cb9-429" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Careful memory management to avoid unnecessary copies</span>
<span id="cb9-430"><a href="#cb9-430" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>All computation done in C++ for maximum efficiency</span>
<span id="cb9-431"><a href="#cb9-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-432"><a href="#cb9-432" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example 3: The QR Decomposition Challenge</span></span>
<span id="cb9-433"><a href="#cb9-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-434"><a href="#cb9-434" aria-hidden="true" tabindex="-1"></a>The QR decomposition is more challenging because it requires maintaining orthogonality across all columns, which creates dependencies between blocks. This illustrates how not all algorithms decompose trivially.</span>
<span id="cb9-435"><a href="#cb9-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-436"><a href="#cb9-436" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why QR Matters</span></span>
<span id="cb9-437"><a href="#cb9-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-438"><a href="#cb9-438" aria-hidden="true" tabindex="-1"></a>The QR decomposition factors a matrix $A$ (dimensions $m \times n$) into:</span>
<span id="cb9-439"><a href="#cb9-439" aria-hidden="true" tabindex="-1"></a>$$A = Q \times R$$</span>
<span id="cb9-440"><a href="#cb9-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-441"><a href="#cb9-441" aria-hidden="true" tabindex="-1"></a>where $Q$ is orthogonal ($m \times n$, with $Q^T Q = I$) and $R$ is upper triangular ($n \times n$). This decomposition is fundamental to:</span>
<span id="cb9-442"><a href="#cb9-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-443"><a href="#cb9-443" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Solving least squares problems (linear regression)</span>
<span id="cb9-444"><a href="#cb9-444" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Computing principal components</span>
<span id="cb9-445"><a href="#cb9-445" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Many iterative algorithms that need orthonormal bases</span>
<span id="cb9-446"><a href="#cb9-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-447"><a href="#cb9-447" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Block-Wise Strategy: Hierarchical QR</span></span>
<span id="cb9-448"><a href="#cb9-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-449"><a href="#cb9-449" aria-hidden="true" tabindex="-1"></a>The key insight is that QR decomposition can be computed hierarchically through a series of smaller QR decompositions.</span>
<span id="cb9-450"><a href="#cb9-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-451"><a href="#cb9-451" aria-hidden="true" tabindex="-1"></a>::: {.panel-tabset}</span>
<span id="cb9-452"><a href="#cb9-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-453"><a href="#cb9-453" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visual Workflow</span></span>
<span id="cb9-454"><a href="#cb9-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-457"><a href="#cb9-457" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb9-458"><a href="#cb9-458" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb9-459"><a href="#cb9-459" aria-hidden="true" tabindex="-1"></a>    A[<span class="ot">"</span><span class="st">Matrix A&lt;br/&gt;m × n&lt;br/&gt;Too large for RAM</span><span class="ot">"</span>] --&gt; B[<span class="ot">"</span><span class="st">Partition into&lt;br/&gt;k row blocks</span><span class="ot">"</span>]</span>
<span id="cb9-460"><a href="#cb9-460" aria-hidden="true" tabindex="-1"></a>    B --&gt; C1[<span class="ot">"</span><span class="st">Block A₁&lt;br/&gt;m₁ × n</span><span class="ot">"</span>]</span>
<span id="cb9-461"><a href="#cb9-461" aria-hidden="true" tabindex="-1"></a>    B --&gt; C2[<span class="ot">"</span><span class="st">Block A₂&lt;br/&gt;m₂ × n</span><span class="ot">"</span>]</span>
<span id="cb9-462"><a href="#cb9-462" aria-hidden="true" tabindex="-1"></a>    B --&gt; C3[<span class="ot">"</span><span class="st">Block Aₖ&lt;br/&gt;mₖ × n</span><span class="ot">"</span>]</span>
<span id="cb9-463"><a href="#cb9-463" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-464"><a href="#cb9-464" aria-hidden="true" tabindex="-1"></a>    C1 --&gt; D1[<span class="ot">"</span><span class="st">Local QR:&lt;br/&gt;A₁ = Q₁R₁</span><span class="ot">"</span>]</span>
<span id="cb9-465"><a href="#cb9-465" aria-hidden="true" tabindex="-1"></a>    C2 --&gt; D2[<span class="ot">"</span><span class="st">Local QR:&lt;br/&gt;A₂ = Q₂R₂</span><span class="ot">"</span>]</span>
<span id="cb9-466"><a href="#cb9-466" aria-hidden="true" tabindex="-1"></a>    C3 --&gt; D3[<span class="ot">"</span><span class="st">Local QR:&lt;br/&gt;Aₖ = QₖRₖ</span><span class="ot">"</span>]</span>
<span id="cb9-467"><a href="#cb9-467" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-468"><a href="#cb9-468" aria-hidden="true" tabindex="-1"></a>    D1 --&gt; E[<span class="ot">"</span><span class="st">Stack R matrices:&lt;br/&gt;[R₁; R₂; ...; Rₖ]&lt;br/&gt;kn × n&lt;br/&gt;Fits in RAM!</span><span class="ot">"</span>]</span>
<span id="cb9-469"><a href="#cb9-469" aria-hidden="true" tabindex="-1"></a>    D2 --&gt; E</span>
<span id="cb9-470"><a href="#cb9-470" aria-hidden="true" tabindex="-1"></a>    D3 --&gt; E</span>
<span id="cb9-471"><a href="#cb9-471" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-472"><a href="#cb9-472" aria-hidden="true" tabindex="-1"></a>    E --&gt; F[<span class="ot">"</span><span class="st">Final QR:&lt;br/&gt;Rstack = QR × Rfinal</span><span class="ot">"</span>]</span>
<span id="cb9-473"><a href="#cb9-473" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-474"><a href="#cb9-474" aria-hidden="true" tabindex="-1"></a>    F --&gt; G[<span class="ot">"</span><span class="st">Reconstruct Q:&lt;br/&gt;Multiply Q_i by QR blocks</span><span class="ot">"</span>]</span>
<span id="cb9-475"><a href="#cb9-475" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-476"><a href="#cb9-476" aria-hidden="true" tabindex="-1"></a>    G --&gt; H[<span class="ot">"</span><span class="st">Result:&lt;br/&gt;A = Q × Rfinal</span><span class="ot">"</span>]</span>
<span id="cb9-477"><a href="#cb9-477" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-478"><a href="#cb9-478" aria-hidden="true" tabindex="-1"></a>    style A fill:<span class="co">#ffe8e8</span></span>
<span id="cb9-479"><a href="#cb9-479" aria-hidden="true" tabindex="-1"></a>    style E fill:<span class="co">#fff8e1</span></span>
<span id="cb9-480"><a href="#cb9-480" aria-hidden="true" tabindex="-1"></a>    style H fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-481"><a href="#cb9-481" aria-hidden="true" tabindex="-1"></a>    style D1 fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-482"><a href="#cb9-482" aria-hidden="true" tabindex="-1"></a>    style D2 fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-483"><a href="#cb9-483" aria-hidden="true" tabindex="-1"></a>    style D3 fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-484"><a href="#cb9-484" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-485"><a href="#cb9-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-486"><a href="#cb9-486" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step-by-Step Process</span></span>
<span id="cb9-487"><a href="#cb9-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-488"><a href="#cb9-488" aria-hidden="true" tabindex="-1"></a>**Step 1: Partition**</span>
<span id="cb9-489"><a href="#cb9-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-490"><a href="#cb9-490" aria-hidden="true" tabindex="-1"></a>Divide the matrix $A$ into blocks along rows: $A = <span class="co">[</span><span class="ot">A_1; A_2; ...; A_k</span><span class="co">]</span>$</span>
<span id="cb9-491"><a href="#cb9-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-492"><a href="#cb9-492" aria-hidden="true" tabindex="-1"></a>**Step 2: Local QR**</span>
<span id="cb9-493"><a href="#cb9-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-494"><a href="#cb9-494" aria-hidden="true" tabindex="-1"></a>Compute QR for each block independently:</span>
<span id="cb9-495"><a href="#cb9-495" aria-hidden="true" tabindex="-1"></a>$$A_i = Q_i R_i$$</span>
<span id="cb9-496"><a href="#cb9-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-497"><a href="#cb9-497" aria-hidden="true" tabindex="-1"></a>Each block's QR decomposition can be computed separately because they operate on independent rows.</span>
<span id="cb9-498"><a href="#cb9-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-499"><a href="#cb9-499" aria-hidden="true" tabindex="-1"></a>**Step 3: Collect R matrices**</span>
<span id="cb9-500"><a href="#cb9-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-501"><a href="#cb9-501" aria-hidden="true" tabindex="-1"></a>Stack all the upper triangular $R_i$ matrices vertically:</span>
<span id="cb9-502"><a href="#cb9-502" aria-hidden="true" tabindex="-1"></a>$$R_{stack} = <span class="co">[</span><span class="ot">R_1; R_2; ...; R_k</span><span class="co">]</span>$$</span>
<span id="cb9-503"><a href="#cb9-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-504"><a href="#cb9-504" aria-hidden="true" tabindex="-1"></a>**Critical insight:** $R_{stack}$ is much smaller than $A$. It's $kn \times n$ instead of $m \times n$, and typically $kn \ll m$, so this stacked matrix **fits in memory** even when $A$ doesn't!</span>
<span id="cb9-505"><a href="#cb9-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-506"><a href="#cb9-506" aria-hidden="true" tabindex="-1"></a>**Step 4: Final QR**</span>
<span id="cb9-507"><a href="#cb9-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-508"><a href="#cb9-508" aria-hidden="true" tabindex="-1"></a>Compute QR of the stacked R matrices (this fits in RAM):</span>
<span id="cb9-509"><a href="#cb9-509" aria-hidden="true" tabindex="-1"></a>$$R_{stack} = Q_R \times R_{final}$$</span>
<span id="cb9-510"><a href="#cb9-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-511"><a href="#cb9-511" aria-hidden="true" tabindex="-1"></a>**Step 5: Reconstruct Q**</span>
<span id="cb9-512"><a href="#cb9-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-513"><a href="#cb9-513" aria-hidden="true" tabindex="-1"></a>The overall $Q$ is obtained by multiplying each local $Q_i$ by the corresponding block of $Q_R$. This reconstruction can be done block by block, again staying within memory constraints.</span>
<span id="cb9-514"><a href="#cb9-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-515"><a href="#cb9-515" aria-hidden="true" tabindex="-1"></a>**Why this works mathematically:**</span>
<span id="cb9-516"><a href="#cb9-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-517"><a href="#cb9-517" aria-hidden="true" tabindex="-1"></a>$$A = \begin{bmatrix} Q_1 R_1 <span class="sc">\\</span> Q_2 R_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> Q_k R_k \end{bmatrix} = </span>
<span id="cb9-518"><a href="#cb9-518" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix} Q_1 <span class="sc">\\</span> Q_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> Q_k \end{bmatrix} </span>
<span id="cb9-519"><a href="#cb9-519" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix} R_1 <span class="sc">\\</span> R_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> R_k \end{bmatrix}$$</span>
<span id="cb9-520"><a href="#cb9-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-521"><a href="#cb9-521" aria-hidden="true" tabindex="-1"></a>Since the $Q_i$ are orthogonal, applying another QR to the stacked $R$ matrices gives us the final factorization.</span>
<span id="cb9-522"><a href="#cb9-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-523"><a href="#cb9-523" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pseudocode</span></span>
<span id="cb9-524"><a href="#cb9-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-525"><a href="#cb9-525" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb9-526"><a href="#cb9-526" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm: HierarchicalQR</span></span>
<span id="cb9-527"><a href="#cb9-527" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: Matrix A m × n in HDF5, block_size</span></span>
<span id="cb9-528"><a href="#cb9-528" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: Q matrix m × n, R matrix n × n</span></span>
<span id="cb9-529"><a href="#cb9-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-530"><a href="#cb9-530" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Partition and compute local QRs</span></span>
<span id="cb9-531"><a href="#cb9-531" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(m <span class="sc">/</span> block_size)</span>
<span id="cb9-532"><a href="#cb9-532" aria-hidden="true" tabindex="-1"></a>R_list <span class="ot">&lt;-</span> <span class="fu">list</span>()  <span class="co"># Store R matrices</span></span>
<span id="cb9-533"><a href="#cb9-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-534"><a href="#cb9-534" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb9-535"><a href="#cb9-535" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read block from HDF5</span></span>
<span id="cb9-536"><a href="#cb9-536" aria-hidden="true" tabindex="-1"></a>  A_block <span class="ot">&lt;-</span> <span class="fu">read_hdf5_rows</span>(start_row, end_row)</span>
<span id="cb9-537"><a href="#cb9-537" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-538"><a href="#cb9-538" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute local QR</span></span>
<span id="cb9-539"><a href="#cb9-539" aria-hidden="true" tabindex="-1"></a>  qr_result <span class="ot">&lt;-</span> <span class="fu">qr_decomposition</span>(A_block)</span>
<span id="cb9-540"><a href="#cb9-540" aria-hidden="true" tabindex="-1"></a>  Q_local <span class="ot">&lt;-</span> qr_result<span class="sc">$</span>Q</span>
<span id="cb9-541"><a href="#cb9-541" aria-hidden="true" tabindex="-1"></a>  R_local <span class="ot">&lt;-</span> qr_result<span class="sc">$</span>R</span>
<span id="cb9-542"><a href="#cb9-542" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-543"><a href="#cb9-543" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store Q to HDF5 for later</span></span>
<span id="cb9-544"><a href="#cb9-544" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_hdf5</span>(Q_local, <span class="at">group =</span> <span class="st">"local_Q"</span>, <span class="at">dataset =</span> <span class="fu">paste0</span>(<span class="st">"Q_"</span>, i))</span>
<span id="cb9-545"><a href="#cb9-545" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-546"><a href="#cb9-546" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Keep R in memory (small)</span></span>
<span id="cb9-547"><a href="#cb9-547" aria-hidden="true" tabindex="-1"></a>  R_list[[i]] <span class="ot">&lt;-</span> R_local</span>
<span id="cb9-548"><a href="#cb9-548" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-549"><a href="#cb9-549" aria-hidden="true" tabindex="-1"></a>  <span class="fu">free</span>(A_block, Q_local)</span>
<span id="cb9-550"><a href="#cb9-550" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-551"><a href="#cb9-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-552"><a href="#cb9-552" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Stack R matrices (fits in RAM)</span></span>
<span id="cb9-553"><a href="#cb9-553" aria-hidden="true" tabindex="-1"></a>R_stacked <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(R_list)  <span class="co"># (k*n × n)</span></span>
<span id="cb9-554"><a href="#cb9-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-555"><a href="#cb9-555" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Final QR on stacked Rs</span></span>
<span id="cb9-556"><a href="#cb9-556" aria-hidden="true" tabindex="-1"></a>qr_final <span class="ot">&lt;-</span> <span class="fu">qr_decomposition</span>(R_stacked)</span>
<span id="cb9-557"><a href="#cb9-557" aria-hidden="true" tabindex="-1"></a>Q_R <span class="ot">&lt;-</span> qr_final<span class="sc">$</span>Q</span>
<span id="cb9-558"><a href="#cb9-558" aria-hidden="true" tabindex="-1"></a>R_final <span class="ot">&lt;-</span> qr_final<span class="sc">$</span>R</span>
<span id="cb9-559"><a href="#cb9-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-560"><a href="#cb9-560" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Reconstruct global Q (block by block)</span></span>
<span id="cb9-561"><a href="#cb9-561" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_blocks) {</span>
<span id="cb9-562"><a href="#cb9-562" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read local Q_i</span></span>
<span id="cb9-563"><a href="#cb9-563" aria-hidden="true" tabindex="-1"></a>  Q_local <span class="ot">&lt;-</span> <span class="fu">read_hdf5</span>(<span class="at">group =</span> <span class="st">"local_Q"</span>, <span class="at">dataset =</span> <span class="fu">paste0</span>(<span class="st">"Q_"</span>, i))</span>
<span id="cb9-564"><a href="#cb9-564" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-565"><a href="#cb9-565" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Multiply by corresponding Q_R block</span></span>
<span id="cb9-566"><a href="#cb9-566" aria-hidden="true" tabindex="-1"></a>  start_idx <span class="ot">&lt;-</span> (i<span class="dv">-1</span>) <span class="sc">*</span> n <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb9-567"><a href="#cb9-567" aria-hidden="true" tabindex="-1"></a>  end_idx <span class="ot">&lt;-</span> i <span class="sc">*</span> n</span>
<span id="cb9-568"><a href="#cb9-568" aria-hidden="true" tabindex="-1"></a>  Q_R_block <span class="ot">&lt;-</span> Q_R[start_idx<span class="sc">:</span>end_idx, ]</span>
<span id="cb9-569"><a href="#cb9-569" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-570"><a href="#cb9-570" aria-hidden="true" tabindex="-1"></a>  Q_global_block <span class="ot">&lt;-</span> Q_local <span class="sc">%*%</span> Q_R_block</span>
<span id="cb9-571"><a href="#cb9-571" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-572"><a href="#cb9-572" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Write back to HDF5</span></span>
<span id="cb9-573"><a href="#cb9-573" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_hdf5</span>(Q_global_block, <span class="at">group =</span> <span class="st">"final_Q"</span>, <span class="at">dataset =</span> <span class="fu">paste0</span>(<span class="st">"Q_"</span>, i))</span>
<span id="cb9-574"><a href="#cb9-574" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-575"><a href="#cb9-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-576"><a href="#cb9-576" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(<span class="fu">list</span>(<span class="at">Q =</span> <span class="st">"final_Q"</span>, <span class="at">R =</span> R_final))</span>
<span id="cb9-577"><a href="#cb9-577" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-578"><a href="#cb9-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-579"><a href="#cb9-579" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-580"><a href="#cb9-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-581"><a href="#cb9-581" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb9-582"><a href="#cb9-582" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Magic of Hierarchical QR</span></span>
<span id="cb9-583"><a href="#cb9-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-584"><a href="#cb9-584" aria-hidden="true" tabindex="-1"></a>The stacked $R$ matrices are only $(k \times n) \times n$ in size. Even with 10 blocks, if $n=1000$, that's just a $10{,}000 \times 1000$ matrix - about 80 MB. This fits comfortably in RAM even when the original matrix is hundreds of GB!</span>
<span id="cb9-585"><a href="#cb9-585" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-586"><a href="#cb9-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-587"><a href="#cb9-587" aria-hidden="true" tabindex="-1"></a>**BigDataStatMeth implementation:** The package implements hierarchical QR in <span class="in">`bdQR_hdf5()`</span>, handling the block partitioning, intermediate storage, and final assembly automatically. This enables methods like PCA on out-of-memory data.</span>
<span id="cb9-588"><a href="#cb9-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-589"><a href="#cb9-589" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example 4: Block-Wise SVD for Principal Component Analysis</span></span>
<span id="cb9-590"><a href="#cb9-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-591"><a href="#cb9-591" aria-hidden="true" tabindex="-1"></a>Singular Value Decomposition (SVD) underlies principal component analysis and is one of the most important matrix decompositions in statistics. Computing SVD on matrices too large for memory is a significant challenge that demonstrates the full power of block-wise thinking.</span>
<span id="cb9-592"><a href="#cb9-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-593"><a href="#cb9-593" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Mathematical Goal</span></span>
<span id="cb9-594"><a href="#cb9-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-595"><a href="#cb9-595" aria-hidden="true" tabindex="-1"></a>For a matrix $X$ (dimensions $n \times p$), we want:</span>
<span id="cb9-596"><a href="#cb9-596" aria-hidden="true" tabindex="-1"></a>$$X = U \Sigma V^T$$</span>
<span id="cb9-597"><a href="#cb9-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-598"><a href="#cb9-598" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb9-599"><a href="#cb9-599" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$U$ is $n \times r$ with orthonormal columns (left singular vectors)</span>
<span id="cb9-600"><a href="#cb9-600" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\Sigma$ is $r \times r$ diagonal (singular values)  </span>
<span id="cb9-601"><a href="#cb9-601" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$V$ is $p \times r$ with orthonormal columns (right singular vectors)</span>
<span id="cb9-602"><a href="#cb9-602" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$r = \min(n, p)$ or smaller if we want only the leading components</span>
<span id="cb9-603"><a href="#cb9-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-604"><a href="#cb9-604" aria-hidden="true" tabindex="-1"></a>For PCA, we typically want only the first $k$ components where $k \ll r$, which simplifies the problem significantly.</span>
<span id="cb9-605"><a href="#cb9-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-606"><a href="#cb9-606" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Block-Wise Strategy: Hierarchical Decomposition</span></span>
<span id="cb9-607"><a href="#cb9-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-608"><a href="#cb9-608" aria-hidden="true" tabindex="-1"></a>BigDataStatMeth implements a hierarchical SVD algorithm (Iwen &amp; Ong, 2017) that works in levels.</span>
<span id="cb9-609"><a href="#cb9-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-610"><a href="#cb9-610" aria-hidden="true" tabindex="-1"></a>::: {.panel-tabset}</span>
<span id="cb9-611"><a href="#cb9-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-612"><a href="#cb9-612" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visual Workflow</span></span>
<span id="cb9-615"><a href="#cb9-615" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb9-616"><a href="#cb9-616" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb9-617"><a href="#cb9-617" aria-hidden="true" tabindex="-1"></a>    A[<span class="ot">"</span><span class="st">Matrix X n × p&lt;br/&gt;Too large for RAM</span><span class="ot">"</span>] --&gt; B[<span class="ot">"</span><span class="st">Level 1:&lt;br/&gt;Partition into m blocks</span><span class="ot">"</span>]</span>
<span id="cb9-618"><a href="#cb9-618" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-619"><a href="#cb9-619" aria-hidden="true" tabindex="-1"></a>    B --&gt; C1[<span class="ot">"</span><span class="st">Block X₁</span><span class="ot">"</span>]</span>
<span id="cb9-620"><a href="#cb9-620" aria-hidden="true" tabindex="-1"></a>    B --&gt; C2[<span class="ot">"</span><span class="st">Block X₂</span><span class="ot">"</span>]  </span>
<span id="cb9-621"><a href="#cb9-621" aria-hidden="true" tabindex="-1"></a>    B --&gt; C3[<span class="ot">"</span><span class="st">Block Xₘ</span><span class="ot">"</span>]</span>
<span id="cb9-622"><a href="#cb9-622" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-623"><a href="#cb9-623" aria-hidden="true" tabindex="-1"></a>    C1 --&gt; D1[<span class="ot">"</span><span class="st">Local SVD:&lt;br/&gt;X₁ = U₁Σ₁V₁ᵀ&lt;br/&gt;Keep k components</span><span class="ot">"</span>]</span>
<span id="cb9-624"><a href="#cb9-624" aria-hidden="true" tabindex="-1"></a>    C2 --&gt; D2[<span class="ot">"</span><span class="st">Local SVD:&lt;br/&gt;X₂ = U₂Σ₂V₂ᵀ&lt;br/&gt;Keep k components</span><span class="ot">"</span>]</span>
<span id="cb9-625"><a href="#cb9-625" aria-hidden="true" tabindex="-1"></a>    C3 --&gt; D3[<span class="ot">"</span><span class="st">Local SVD:&lt;br/&gt;Xₘ = UₘΣₘVₘᵀ&lt;br/&gt;Keep k components</span><span class="ot">"</span>]</span>
<span id="cb9-626"><a href="#cb9-626" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-627"><a href="#cb9-627" aria-hidden="true" tabindex="-1"></a>    D1 --&gt; E1[<span class="ot">"</span><span class="st">Form Z₁ = V₁Σ₁&lt;br/&gt;p × k</span><span class="ot">"</span>]</span>
<span id="cb9-628"><a href="#cb9-628" aria-hidden="true" tabindex="-1"></a>    D2 --&gt; E2[<span class="ot">"</span><span class="st">Form Z₂ = V₂Σ₂&lt;br/&gt;p × k</span><span class="ot">"</span>]</span>
<span id="cb9-629"><a href="#cb9-629" aria-hidden="true" tabindex="-1"></a>    D3 --&gt; E3[<span class="ot">"</span><span class="st">Form Zₘ = VₘΣₘ&lt;br/&gt;p × k</span><span class="ot">"</span>]</span>
<span id="cb9-630"><a href="#cb9-630" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-631"><a href="#cb9-631" aria-hidden="true" tabindex="-1"></a>    E1 --&gt; F[<span class="ot">"</span><span class="st">Level 2:&lt;br/&gt;Stack Z matrices&lt;br/&gt;Z = [Z₁; Z₂; ...; Zₘ]&lt;br/&gt;mk × k&lt;br/&gt;Fits in RAM!</span><span class="ot">"</span>]</span>
<span id="cb9-632"><a href="#cb9-632" aria-hidden="true" tabindex="-1"></a>    E2 --&gt; F</span>
<span id="cb9-633"><a href="#cb9-633" aria-hidden="true" tabindex="-1"></a>    E3 --&gt; F</span>
<span id="cb9-634"><a href="#cb9-634" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-635"><a href="#cb9-635" aria-hidden="true" tabindex="-1"></a>    F --&gt; G[<span class="ot">"</span><span class="st">Global SVD:&lt;br/&gt;Z = UzΣzVzᵀ</span><span class="ot">"</span>]</span>
<span id="cb9-636"><a href="#cb9-636" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-637"><a href="#cb9-637" aria-hidden="true" tabindex="-1"></a>    G --&gt; H[<span class="ot">"</span><span class="st">Extract Results:&lt;br/&gt;Singular values = Σz&lt;br/&gt;Right vectors = Vz&lt;br/&gt;Left vectors from U₁...Uₘ</span><span class="ot">"</span>]</span>
<span id="cb9-638"><a href="#cb9-638" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-639"><a href="#cb9-639" aria-hidden="true" tabindex="-1"></a>    H --&gt; I[<span class="ot">"</span><span class="st">Final SVD:&lt;br/&gt;X ≈ UΣVᵀ</span><span class="ot">"</span>]</span>
<span id="cb9-640"><a href="#cb9-640" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-641"><a href="#cb9-641" aria-hidden="true" tabindex="-1"></a>    style A fill:<span class="co">#ffe8e8</span></span>
<span id="cb9-642"><a href="#cb9-642" aria-hidden="true" tabindex="-1"></a>    style F fill:<span class="co">#fff8e1</span></span>
<span id="cb9-643"><a href="#cb9-643" aria-hidden="true" tabindex="-1"></a>    style I fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-644"><a href="#cb9-644" aria-hidden="true" tabindex="-1"></a>    style D1 fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-645"><a href="#cb9-645" aria-hidden="true" tabindex="-1"></a>    style D2 fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-646"><a href="#cb9-646" aria-hidden="true" tabindex="-1"></a>    style D3 fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-647"><a href="#cb9-647" aria-hidden="true" tabindex="-1"></a>    style G fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-648"><a href="#cb9-648" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-649"><a href="#cb9-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-650"><a href="#cb9-650" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two-Level Process</span></span>
<span id="cb9-651"><a href="#cb9-651" aria-hidden="true" tabindex="-1"></a>**Level 1: Partition and Local SVD**</span>
<span id="cb9-652"><a href="#cb9-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-653"><a href="#cb9-653" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Partition** $X$ into blocks along rows:</span>
<span id="cb9-654"><a href="#cb9-654" aria-hidden="true" tabindex="-1"></a>   $$X = \begin{bmatrix} X_1 <span class="sc">\\</span> X_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> X_m \end{bmatrix}$$</span>
<span id="cb9-655"><a href="#cb9-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-656"><a href="#cb9-656" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Compute truncated SVD** for each block, keeping only $k$ components:</span>
<span id="cb9-657"><a href="#cb9-657" aria-hidden="true" tabindex="-1"></a>   $$X_i = U_i \Sigma_i V_i^T$$</span>
<span id="cb9-658"><a href="#cb9-658" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb9-659"><a href="#cb9-659" aria-hidden="true" tabindex="-1"></a>   where $U_i$ is $n_i \times k$, $\Sigma_i$ is $k \times k$, and $V_i$ is $p \times k$.</span>
<span id="cb9-660"><a href="#cb9-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-661"><a href="#cb9-661" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Form weighted matrices** from the right singular vectors:</span>
<span id="cb9-662"><a href="#cb9-662" aria-hidden="true" tabindex="-1"></a>   $$Z_i = V_i \Sigma_i$$</span>
<span id="cb9-663"><a href="#cb9-663" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb9-664"><a href="#cb9-664" aria-hidden="true" tabindex="-1"></a>   Each $Z_i$ is $p \times k$ - much smaller than the original $X_i$ which was $n_i \times p$!</span>
<span id="cb9-665"><a href="#cb9-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-666"><a href="#cb9-666" aria-hidden="true" tabindex="-1"></a>**Level 2: Merge and Global SVD**</span>
<span id="cb9-667"><a href="#cb9-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-668"><a href="#cb9-668" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Stack** the $Z_i$ matrices:</span>
<span id="cb9-669"><a href="#cb9-669" aria-hidden="true" tabindex="-1"></a>   $$Z = \begin{bmatrix} Z_1 <span class="sc">\\</span> Z_2 <span class="sc">\\</span> \vdots <span class="sc">\\</span> Z_m \end{bmatrix}$$</span>
<span id="cb9-670"><a href="#cb9-670" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb9-671"><a href="#cb9-671" aria-hidden="true" tabindex="-1"></a>   This $Z$ matrix is $mk \times k$. Since $m$ (blocks) and $k$ (components) are both small, **$Z$ fits in memory**.</span>
<span id="cb9-672"><a href="#cb9-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-673"><a href="#cb9-673" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Compute global SVD** of $Z$:</span>
<span id="cb9-674"><a href="#cb9-674" aria-hidden="true" tabindex="-1"></a>   $$Z = U_Z \Sigma_Z V_Z^T$$</span>
<span id="cb9-675"><a href="#cb9-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-676"><a href="#cb9-676" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Extract results:**</span>
<span id="cb9-677"><a href="#cb9-677" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Global singular values = $\Sigma_Z$</span>
<span id="cb9-678"><a href="#cb9-678" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Global right singular vectors = $V_Z$</span>
<span id="cb9-679"><a href="#cb9-679" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Global left singular vectors: multiply back through blocks</span>
<span id="cb9-680"><a href="#cb9-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-681"><a href="#cb9-681" aria-hidden="true" tabindex="-1"></a>**Why this works:** The row space of $X$ (spanned by right singular vectors) is well-approximated by combining the row spaces of blocks. Block SVDs capture main variation within each block; global SVD captures overall variation.</span>
<span id="cb9-682"><a href="#cb9-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-683"><a href="#cb9-683" aria-hidden="true" tabindex="-1"></a>**Approximation quality:** Not exact, but excellent for large $n$ relative to $p$ with sufficient $k$. Error decreases as $k$ increases.</span>
<span id="cb9-684"><a href="#cb9-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-685"><a href="#cb9-685" aria-hidden="true" tabindex="-1"></a><span class="fu">### Memory Analysis</span></span>
<span id="cb9-686"><a href="#cb9-686" aria-hidden="true" tabindex="-1"></a>**Concrete example:** $X$ is 100,000 × 20,000 (16 GB)</span>
<span id="cb9-687"><a href="#cb9-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-688"><a href="#cb9-688" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Partition into $m = 10$ blocks of 10,000 rows</span>
<span id="cb9-689"><a href="#cb9-689" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Keep $k = 50$ components</span>
<span id="cb9-690"><a href="#cb9-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-691"><a href="#cb9-691" aria-hidden="true" tabindex="-1"></a>**Memory per block during local SVD:**</span>
<span id="cb9-692"><a href="#cb9-692" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Block $X_i$: 10,000 × 20,000 = 1.6 GB</span>
<span id="cb9-693"><a href="#cb9-693" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$U_i$: 10,000 × 50 = 4 MB  </span>
<span id="cb9-694"><a href="#cb9-694" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\Sigma_i$: 50 × 50 = 20 KB</span>
<span id="cb9-695"><a href="#cb9-695" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$V_i$: 20,000 × 50 = 8 MB</span>
<span id="cb9-696"><a href="#cb9-696" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Peak: ~1.6 GB** (dominated by the block)</span>
<span id="cb9-697"><a href="#cb9-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-698"><a href="#cb9-698" aria-hidden="true" tabindex="-1"></a>**Memory for global SVD:**</span>
<span id="cb9-699"><a href="#cb9-699" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$Z$: (10 × 50) × 20,000 = 8 MB</span>
<span id="cb9-700"><a href="#cb9-700" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**This easily fits in memory!**</span>
<span id="cb9-701"><a href="#cb9-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-702"><a href="#cb9-702" aria-hidden="true" tabindex="-1"></a>**Result:** 16 GB problem → 1.6 GB peak memory (10× reduction) while computing accurate approximation.</span>
<span id="cb9-703"><a href="#cb9-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-704"><a href="#cb9-704" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-705"><a href="#cb9-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-706"><a href="#cb9-706" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb9-707"><a href="#cb9-707" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hierarchical Decomposition Power</span></span>
<span id="cb9-708"><a href="#cb9-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-709"><a href="#cb9-709" aria-hidden="true" tabindex="-1"></a>The stacked $Z$ matrix is tiny: $(m \times k) \times p$ instead of $n \times p$. With 10 blocks and 50 components, even for $p=20{,}000$, that's just 8 MB - fitting comfortably in RAM even when the original is 16 GB!</span>
<span id="cb9-710"><a href="#cb9-710" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-711"><a href="#cb9-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-712"><a href="#cb9-712" aria-hidden="true" tabindex="-1"></a>We've reduced a 16 GB problem to one requiring ~1.6 GB peak memory - a 10× reduction - while computing an accurate approximation to the full SVD.</span>
<span id="cb9-713"><a href="#cb9-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-714"><a href="#cb9-714" aria-hidden="true" tabindex="-1"></a>**BigDataStatMeth implementation:** The <span class="in">`bdSVD_hdf5()`</span> function implements this hierarchical strategy with additional optimizations:</span>
<span id="cb9-715"><a href="#cb9-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-716"><a href="#cb9-716" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Automatic selection of block size and hierarchy depth based on data dimensions and available memory</span>
<span id="cb9-717"><a href="#cb9-717" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Parallel processing of independent blocks</span>
<span id="cb9-718"><a href="#cb9-718" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Optional centering and scaling before SVD</span>
<span id="cb9-719"><a href="#cb9-719" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multiple hierarchy levels for very large datasets (you can set <span class="in">`q`</span> levels with <span class="in">`k`</span> blocks per level)</span>
<span id="cb9-720"><a href="#cb9-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-721"><a href="#cb9-721" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Pattern: Recognizing Block-Wise Opportunities</span></span>
<span id="cb9-722"><a href="#cb9-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-723"><a href="#cb9-723" aria-hidden="true" tabindex="-1"></a>Looking across these examples, several patterns emerge for when and how algorithms can be adapted for block-wise processing:</span>
<span id="cb9-724"><a href="#cb9-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-725"><a href="#cb9-725" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1. Operations with Additive Decomposition</span></span>
<span id="cb9-726"><a href="#cb9-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-727"><a href="#cb9-727" aria-hidden="true" tabindex="-1"></a>If an operation can be expressed as summing contributions from different data portions, it's straightforward to implement block-wise:</span>
<span id="cb9-728"><a href="#cb9-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-729"><a href="#cb9-729" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Examples:** Means, sums, counts, sufficient statistics for simple models</span>
<span id="cb9-730"><a href="#cb9-730" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Strategy:** Process each block, accumulate results, finalize</span>
<span id="cb9-731"><a href="#cb9-731" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Memory:** One block plus small accumulator</span>
<span id="cb9-732"><a href="#cb9-732" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**I/O:** Single pass through data</span>
<span id="cb9-733"><a href="#cb9-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-734"><a href="#cb9-734" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2. Operations with Hierarchical Decomposition</span></span>
<span id="cb9-735"><a href="#cb9-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-736"><a href="#cb9-736" aria-hidden="true" tabindex="-1"></a>If an operation can be computed hierarchically (computing on blocks, then combining block results), block-wise processing is feasible:</span>
<span id="cb9-737"><a href="#cb9-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-738"><a href="#cb9-738" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Examples:** QR decomposition, SVD, certain optimization algorithms</span>
<span id="cb9-739"><a href="#cb9-739" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Strategy:** Local computation on blocks, merge results, possibly iterate</span>
<span id="cb9-740"><a href="#cb9-740" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Memory:** One block plus moderately-sized merge structure</span>
<span id="cb9-741"><a href="#cb9-741" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**I/O:** Multiple passes, but still practical</span>
<span id="cb9-742"><a href="#cb9-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-743"><a href="#cb9-743" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3. Operations Requiring Global Information</span></span>
<span id="cb9-744"><a href="#cb9-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-745"><a href="#cb9-745" aria-hidden="true" tabindex="-1"></a>Some operations need information about the entire dataset to process any part of it:</span>
<span id="cb9-746"><a href="#cb9-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-747"><a href="#cb9-747" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Examples:** Sorting, ranking, quantiles, certain graph algorithms</span>
<span id="cb9-748"><a href="#cb9-748" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Challenge:** May require multiple passes or sophisticated algorithms</span>
<span id="cb9-749"><a href="#cb9-749" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Strategy:** Often use approximation or sampling strategies</span>
<span id="cb9-750"><a href="#cb9-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-751"><a href="#cb9-751" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4. Operations That Don't Decompose Well</span></span>
<span id="cb9-752"><a href="#cb9-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-753"><a href="#cb9-753" aria-hidden="true" tabindex="-1"></a>A few operations are fundamentally difficult to decompose:</span>
<span id="cb9-754"><a href="#cb9-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-755"><a href="#cb9-755" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Examples:** Some machine learning algorithms with complex dependencies, certain nonlinear optimizations</span>
<span id="cb9-756"><a href="#cb9-756" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Options:** Use approximations, reformulate the problem, or accept that in-memory computation is necessary</span>
<span id="cb9-757"><a href="#cb9-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-758"><a href="#cb9-758" aria-hidden="true" tabindex="-1"></a>BigDataStatMeth focuses on category 1 and 2 operations, which cover most standard statistical analyses. For category 3, the package often provides approximate but practical solutions.</span>
<span id="cb9-759"><a href="#cb9-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-760"><a href="#cb9-760" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practical Considerations</span></span>
<span id="cb9-761"><a href="#cb9-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-762"><a href="#cb9-762" aria-hidden="true" tabindex="-1"></a><span class="fu">### Block Size Selection</span></span>
<span id="cb9-763"><a href="#cb9-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-764"><a href="#cb9-764" aria-hidden="true" tabindex="-1"></a>Choosing appropriate block sizes involves trade-offs:</span>
<span id="cb9-765"><a href="#cb9-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-766"><a href="#cb9-766" aria-hidden="true" tabindex="-1"></a>**Too small blocks:**</span>
<span id="cb9-767"><a href="#cb9-767" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>More overhead from reading many blocks</span>
<span id="cb9-768"><a href="#cb9-768" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>More function calls and loop iterations</span>
<span id="cb9-769"><a href="#cb9-769" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Potentially less cache-friendly computations</span>
<span id="cb9-770"><a href="#cb9-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-771"><a href="#cb9-771" aria-hidden="true" tabindex="-1"></a>**Too large blocks:**</span>
<span id="cb9-772"><a href="#cb9-772" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Risk of memory exhaustion</span>
<span id="cb9-773"><a href="#cb9-773" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Less opportunity for parallelization</span>
<span id="cb9-774"><a href="#cb9-774" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Longer time to first result</span>
<span id="cb9-775"><a href="#cb9-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-776"><a href="#cb9-776" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb9-777"><a href="#cb9-777" aria-hidden="true" tabindex="-1"></a><span class="fu">## Finding the Sweet Spot</span></span>
<span id="cb9-778"><a href="#cb9-778" aria-hidden="true" tabindex="-1"></a>BigDataStatMeth uses smart heuristics based on available RAM, data dimensions, and operation type. Users can override defaults when they have specific system knowledge, but the automatic selection works well for most cases.</span>
<span id="cb9-779"><a href="#cb9-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-780"><a href="#cb9-780" aria-hidden="true" tabindex="-1"></a>**Rule of thumb:** Blocks should use ~10-20% of available RAM, leaving room for intermediate results and OS operations.</span>
<span id="cb9-781"><a href="#cb9-781" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-782"><a href="#cb9-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-783"><a href="#cb9-783" aria-hidden="true" tabindex="-1"></a>BigDataStatMeth uses heuristics based on:</span>
<span id="cb9-784"><a href="#cb9-784" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Available RAM (conservative estimates)</span>
<span id="cb9-785"><a href="#cb9-785" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data dimensions (balanced partitioning)</span>
<span id="cb9-786"><a href="#cb9-786" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Operation type (some need larger blocks for efficiency)</span>
<span id="cb9-787"><a href="#cb9-787" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Computational complexity (CPU-bound vs. I/O-bound)</span>
<span id="cb9-788"><a href="#cb9-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-789"><a href="#cb9-789" aria-hidden="true" tabindex="-1"></a>Users can override defaults when they have specific knowledge about their system.</span>
<span id="cb9-790"><a href="#cb9-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-791"><a href="#cb9-791" aria-hidden="true" tabindex="-1"></a><span class="fu">### Numerical Stability</span></span>
<span id="cb9-792"><a href="#cb9-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-793"><a href="#cb9-793" aria-hidden="true" tabindex="-1"></a>Block-wise algorithms can affect numerical properties, though the impact varies by operation:</span>
<span id="cb9-794"><a href="#cb9-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-795"><a href="#cb9-795" aria-hidden="true" tabindex="-1"></a>**Potential issues:**</span>
<span id="cb9-796"><a href="#cb9-796" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Accumulation of rounding errors across many blocks</span>
<span id="cb9-797"><a href="#cb9-797" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Loss of precision in hierarchical methods (e.g., hierarchical SVD is approximate)</span>
<span id="cb9-798"><a href="#cb9-798" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Order-dependent results for some operations</span>
<span id="cb9-799"><a href="#cb9-799" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Cancellation errors when subtracting nearly equal numbers</span>
<span id="cb9-800"><a href="#cb9-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-801"><a href="#cb9-801" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb9-802"><a href="#cb9-802" aria-hidden="true" tabindex="-1"></a><span class="fu">## What BigDataStatMeth Guarantees</span></span>
<span id="cb9-803"><a href="#cb9-803" aria-hidden="true" tabindex="-1"></a>The package prioritizes **practical numerical reliability** over theoretical guarantees:</span>
<span id="cb9-804"><a href="#cb9-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-805"><a href="#cb9-805" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✅ **Tested algorithms:** Extensively verified against in-memory methods</span>
<span id="cb9-806"><a href="#cb9-806" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✅ **Established methods:** Uses well-known algorithms from numerical linear algebra literature</span>
<span id="cb9-807"><a href="#cb9-807" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✅ **Double precision:** All computations use 64-bit floating point</span>
<span id="cb9-808"><a href="#cb9-808" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✅ **Documented approximations:** When algorithms are approximate (hierarchical SVD), this is clearly stated</span>
<span id="cb9-809"><a href="#cb9-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-810"><a href="#cb9-810" aria-hidden="true" tabindex="-1"></a>**What is NOT guaranteed:**</span>
<span id="cb9-811"><a href="#cb9-811" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>❌ Bit-exact reproducibility across different hardware</span>
<span id="cb9-812"><a href="#cb9-812" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>❌ Formal error bounds for all operations</span>
<span id="cb9-813"><a href="#cb9-813" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>❌ Specific compensated algorithms (e.g., Kahan summation)</span>
<span id="cb9-814"><a href="#cb9-814" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-815"><a href="#cb9-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-816"><a href="#cb9-816" aria-hidden="true" tabindex="-1"></a>**Practical implications:**</span>
<span id="cb9-817"><a href="#cb9-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-818"><a href="#cb9-818" aria-hidden="true" tabindex="-1"></a>For most statistical applications, the numerical precision is more than adequate:</span>
<span id="cb9-819"><a href="#cb9-819" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>PCA/SVD components match in-memory results to many decimal places</span>
<span id="cb9-820"><a href="#cb9-820" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Regression coefficients are statistically indistinguishable</span>
<span id="cb9-821"><a href="#cb9-821" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hypothesis test results are identical</span>
<span id="cb9-822"><a href="#cb9-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-823"><a href="#cb9-823" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb9-824"><a href="#cb9-824" aria-hidden="true" tabindex="-1"></a><span class="fu">## When to Worry About Numerical Precision</span></span>
<span id="cb9-825"><a href="#cb9-825" aria-hidden="true" tabindex="-1"></a>If your application requires **provable numerical bounds** or **arbitrary precision**, BigDataStatMeth may not be suitable. </span>
<span id="cb9-826"><a href="#cb9-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-827"><a href="#cb9-827" aria-hidden="true" tabindex="-1"></a>The package optimizes for the common case where **statistical noise far exceeds numerical error** - which describes most genomic and large-scale data analyses.</span>
<span id="cb9-828"><a href="#cb9-828" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-829"><a href="#cb9-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-830"><a href="#cb9-830" aria-hidden="true" tabindex="-1"></a>**User control:**</span>
<span id="cb9-831"><a href="#cb9-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-832"><a href="#cb9-832" aria-hidden="true" tabindex="-1"></a>Some functions provide parameters to control accuracy:</span>
<span id="cb9-833"><a href="#cb9-833" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>SVD/PCA: <span class="in">`k`</span> parameter controls how many components to compute (more = better approximation to full decomposition)</span>
<span id="cb9-834"><a href="#cb9-834" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Iterative methods: tolerance parameters control convergence criteria</span>
<span id="cb9-835"><a href="#cb9-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-836"><a href="#cb9-836" aria-hidden="true" tabindex="-1"></a>Check function documentation for available accuracy controls.</span>
<span id="cb9-837"><a href="#cb9-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-838"><a href="#cb9-838" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parallelization</span></span>
<span id="cb9-839"><a href="#cb9-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-840"><a href="#cb9-840" aria-hidden="true" tabindex="-1"></a>Many block-wise operations are embarrassingly parallel - blocks can be processed independently. BigDataStatMeth leverages this through **OpenMP parallelization** at the C++ level.</span>
<span id="cb9-841"><a href="#cb9-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-842"><a href="#cb9-842" aria-hidden="true" tabindex="-1"></a>::: {.panel-tabset}</span>
<span id="cb9-843"><a href="#cb9-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-844"><a href="#cb9-844" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visual Workflow</span></span>
<span id="cb9-847"><a href="#cb9-847" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb9-848"><a href="#cb9-848" aria-hidden="true" tabindex="-1"></a>flowchart TD</span>
<span id="cb9-849"><a href="#cb9-849" aria-hidden="true" tabindex="-1"></a>    A[Matrix in HDF5&lt;br/&gt;divided into blocks] --&gt; B[OpenMP Scheduler&lt;br/&gt;threads=<span class="dv">4</span>]</span>
<span id="cb9-850"><a href="#cb9-850" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-851"><a href="#cb9-851" aria-hidden="true" tabindex="-1"></a>    B --&gt; C1[Thread <span class="dv">1</span>:&lt;br/&gt;Block <span class="dv">1</span>]</span>
<span id="cb9-852"><a href="#cb9-852" aria-hidden="true" tabindex="-1"></a>    B --&gt; C2[Thread <span class="dv">2</span>:&lt;br/&gt;Block <span class="dv">2</span>]</span>
<span id="cb9-853"><a href="#cb9-853" aria-hidden="true" tabindex="-1"></a>    B --&gt; C3[Thread <span class="dv">3</span>:&lt;br/&gt;Block <span class="dv">3</span>]</span>
<span id="cb9-854"><a href="#cb9-854" aria-hidden="true" tabindex="-1"></a>    B --&gt; C4[Thread <span class="dv">4</span>:&lt;br/&gt;Block <span class="dv">4</span>]</span>
<span id="cb9-855"><a href="#cb9-855" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-856"><a href="#cb9-856" aria-hidden="true" tabindex="-1"></a>    C1 --&gt; D1[Process&lt;br/&gt;independently]</span>
<span id="cb9-857"><a href="#cb9-857" aria-hidden="true" tabindex="-1"></a>    C2 --&gt; D2[Process&lt;br/&gt;independently]</span>
<span id="cb9-858"><a href="#cb9-858" aria-hidden="true" tabindex="-1"></a>    C3 --&gt; D3[Process&lt;br/&gt;independently]</span>
<span id="cb9-859"><a href="#cb9-859" aria-hidden="true" tabindex="-1"></a>    C4 --&gt; D4[Process&lt;br/&gt;independently]</span>
<span id="cb9-860"><a href="#cb9-860" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-861"><a href="#cb9-861" aria-hidden="true" tabindex="-1"></a>    D1 --&gt; E[Combine results&lt;br/&gt;sequentially]</span>
<span id="cb9-862"><a href="#cb9-862" aria-hidden="true" tabindex="-1"></a>    D2 --&gt; E</span>
<span id="cb9-863"><a href="#cb9-863" aria-hidden="true" tabindex="-1"></a>    D3 --&gt; E</span>
<span id="cb9-864"><a href="#cb9-864" aria-hidden="true" tabindex="-1"></a>    D4 --&gt; E</span>
<span id="cb9-865"><a href="#cb9-865" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-866"><a href="#cb9-866" aria-hidden="true" tabindex="-1"></a>    E --&gt; F[Final result]</span>
<span id="cb9-867"><a href="#cb9-867" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-868"><a href="#cb9-868" aria-hidden="true" tabindex="-1"></a>    style A fill:<span class="co">#f0f8ff</span></span>
<span id="cb9-869"><a href="#cb9-869" aria-hidden="true" tabindex="-1"></a>    style B fill:<span class="co">#fff8e1</span></span>
<span id="cb9-870"><a href="#cb9-870" aria-hidden="true" tabindex="-1"></a>    style C1 fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-871"><a href="#cb9-871" aria-hidden="true" tabindex="-1"></a>    style C2 fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-872"><a href="#cb9-872" aria-hidden="true" tabindex="-1"></a>    style C3 fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-873"><a href="#cb9-873" aria-hidden="true" tabindex="-1"></a>    style C4 fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-874"><a href="#cb9-874" aria-hidden="true" tabindex="-1"></a>    style F fill:<span class="co">#e8f6e8</span></span>
<span id="cb9-875"><a href="#cb9-875" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-876"><a href="#cb9-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-877"><a href="#cb9-877" aria-hidden="true" tabindex="-1"></a><span class="fu">### How It Works</span></span>
<span id="cb9-878"><a href="#cb9-878" aria-hidden="true" tabindex="-1"></a>**OpenMP (Open Multi-Processing)** is a parallel programming API for C++ that BigDataStatMeth uses internally. When you specify <span class="in">`threads = 4`</span> in a function like <span class="in">`bdSVD_hdf5()`</span>, the C++ code distributes independent block operations across 4 CPU cores.</span>
<span id="cb9-879"><a href="#cb9-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-880"><a href="#cb9-880" aria-hidden="true" tabindex="-1"></a>**Key characteristics:**</span>
<span id="cb9-881"><a href="#cb9-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-882"><a href="#cb9-882" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Shared memory:** All threads access the same HDF5 file, but read different blocks</span>
<span id="cb9-883"><a href="#cb9-883" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Thread-safe I/O:** BigDataStatMeth ensures HDF5 reads don't conflict between threads  </span>
<span id="cb9-884"><a href="#cb9-884" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Load balancing:** OpenMP automatically distributes blocks to available threads</span>
<span id="cb9-885"><a href="#cb9-885" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Overhead vs. benefit:** Parallelism only helps when block processing time exceeds coordination overhead</span>
<span id="cb9-886"><a href="#cb9-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-887"><a href="#cb9-887" aria-hidden="true" tabindex="-1"></a>**When parallelization helps:**</span>
<span id="cb9-888"><a href="#cb9-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-889"><a href="#cb9-889" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Large blocks that take seconds to process each</span>
<span id="cb9-890"><a href="#cb9-890" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>CPU-intensive operations (matrix multiplication, decompositions)</span>
<span id="cb9-891"><a href="#cb9-891" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Many blocks to process (good load distribution)</span>
<span id="cb9-892"><a href="#cb9-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-893"><a href="#cb9-893" aria-hidden="true" tabindex="-1"></a>**When it doesn't help:**</span>
<span id="cb9-894"><a href="#cb9-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-895"><a href="#cb9-895" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Very small blocks (overhead dominates)</span>
<span id="cb9-896"><a href="#cb9-896" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>I/O-bound operations (disk is the bottleneck, not CPU)</span>
<span id="cb9-897"><a href="#cb9-897" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Few blocks (can't keep all cores busy)</span>
<span id="cb9-898"><a href="#cb9-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-899"><a href="#cb9-899" aria-hidden="true" tabindex="-1"></a>BigDataStatMeth automatically uses parallelization where beneficial. Users control thread count via the <span class="in">`threads`</span> parameter.</span>
<span id="cb9-900"><a href="#cb9-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-901"><a href="#cb9-901" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pseudocode</span></span>
<span id="cb9-902"><a href="#cb9-902" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-903"><a href="#cb9-903" aria-hidden="true" tabindex="-1"></a><span class="co">// Algorithm: ParallelBlockProcessing</span></span>
<span id="cb9-904"><a href="#cb9-904" aria-hidden="true" tabindex="-1"></a><span class="co">// Input: HDF5 dataset, n_blocks, n_threads</span></span>
<span id="cb9-905"><a href="#cb9-905" aria-hidden="true" tabindex="-1"></a><span class="co">// Output: Combined results from all blocks</span></span>
<span id="cb9-906"><a href="#cb9-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-907"><a href="#cb9-907" aria-hidden="true" tabindex="-1"></a><span class="co">// 1. Initialize</span></span>
<span id="cb9-908"><a href="#cb9-908" aria-hidden="true" tabindex="-1"></a>results <span class="op">&lt;-</span> array to store each block<span class="ch">'s</span><span class="er"> output</span></span>
<span id="cb9-909"><a href="#cb9-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-910"><a href="#cb9-910" aria-hidden="true" tabindex="-1"></a><span class="co">// 2. Parallel processing (OpenMP)</span></span>
<span id="cb9-911"><a href="#cb9-911" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma omp parallel for num_threads(n_threads)</span></span>
<span id="cb9-912"><a href="#cb9-912" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> n_blocks<span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb9-913"><a href="#cb9-913" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Each thread processes its assigned blocks</span></span>
<span id="cb9-914"><a href="#cb9-914" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> thread_id <span class="op">=</span> omp_get_thread_num<span class="op">();</span></span>
<span id="cb9-915"><a href="#cb9-915" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-916"><a href="#cb9-916" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Thread-safe read</span></span>
<span id="cb9-917"><a href="#cb9-917" aria-hidden="true" tabindex="-1"></a>  block_i <span class="op">=</span> read_hdf5_block<span class="op">(</span>i<span class="op">);</span></span>
<span id="cb9-918"><a href="#cb9-918" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-919"><a href="#cb9-919" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Independent computation</span></span>
<span id="cb9-920"><a href="#cb9-920" aria-hidden="true" tabindex="-1"></a>  result_i <span class="op">=</span> process_block<span class="op">(</span>block_i<span class="op">);</span></span>
<span id="cb9-921"><a href="#cb9-921" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-922"><a href="#cb9-922" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Store result</span></span>
<span id="cb9-923"><a href="#cb9-923" aria-hidden="true" tabindex="-1"></a>  results<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> result_i<span class="op">;</span></span>
<span id="cb9-924"><a href="#cb9-924" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-925"><a href="#cb9-925" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Free memory</span></span>
<span id="cb9-926"><a href="#cb9-926" aria-hidden="true" tabindex="-1"></a>  free<span class="op">(</span>block_i<span class="op">);</span></span>
<span id="cb9-927"><a href="#cb9-927" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb9-928"><a href="#cb9-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-929"><a href="#cb9-929" aria-hidden="true" tabindex="-1"></a><span class="co">// 3. Combine results (sequential)</span></span>
<span id="cb9-930"><a href="#cb9-930" aria-hidden="true" tabindex="-1"></a>final_result <span class="op">=</span> combine_function<span class="op">(</span>results<span class="op">);</span></span>
<span id="cb9-931"><a href="#cb9-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-932"><a href="#cb9-932" aria-hidden="true" tabindex="-1"></a><span class="co">// 4. Return</span></span>
<span id="cb9-933"><a href="#cb9-933" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> final_result<span class="op">;</span></span>
<span id="cb9-934"><a href="#cb9-934" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-935"><a href="#cb9-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-936"><a href="#cb9-936" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-937"><a href="#cb9-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-938"><a href="#cb9-938" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb9-939"><a href="#cb9-939" aria-hidden="true" tabindex="-1"></a><span class="fu">## Thread Configuration</span></span>
<span id="cb9-940"><a href="#cb9-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-941"><a href="#cb9-941" aria-hidden="true" tabindex="-1"></a>Match <span class="in">`threads`</span> to your CPU cores but leave 1-2 cores free for the system. For a 12-core machine, <span class="in">`threads = 10`</span> is often optimal. Use <span class="in">`threads = 1`</span> for debugging to simplify error tracking.</span>
<span id="cb9-942"><a href="#cb9-942" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-943"><a href="#cb9-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-944"><a href="#cb9-944" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implementing Your Own Block-Wise Methods</span></span>
<span id="cb9-945"><a href="#cb9-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-946"><a href="#cb9-946" aria-hidden="true" tabindex="-1"></a>One of BigDataStatMeth's design goals is enabling users to implement new statistical methods using block-wise processing. The package provides different levels of abstraction:</span>
<span id="cb9-947"><a href="#cb9-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-948"><a href="#cb9-948" aria-hidden="true" tabindex="-1"></a><span class="fu">### Architecture Overview</span></span>
<span id="cb9-949"><a href="#cb9-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-950"><a href="#cb9-950" aria-hidden="true" tabindex="-1"></a>BigDataStatMeth uses a **three-layer architecture**:</span>
<span id="cb9-951"><a href="#cb9-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-952"><a href="#cb9-952" aria-hidden="true" tabindex="-1"></a>**1. Internal C++ Layer (Accessible from C++, not from R):**</span>
<span id="cb9-953"><a href="#cb9-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-954"><a href="#cb9-954" aria-hidden="true" tabindex="-1"></a>The lowest level consists of efficient C++ classes and functions that handle direct HDF5 file operations:</span>
<span id="cb9-955"><a href="#cb9-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-956"><a href="#cb9-956" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`hdf5Dataset`</span> class - Wraps HDF5 C API for file access, provides block reading/writing</span>
<span id="cb9-957"><a href="#cb9-957" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Efficient memory management and buffer handling</span>
<span id="cb9-958"><a href="#cb9-958" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Direct HDF5 C API access for maximum performance</span>
<span id="cb9-959"><a href="#cb9-959" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>OpenMP-parallelized block iteration</span>
<span id="cb9-960"><a href="#cb9-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-961"><a href="#cb9-961" aria-hidden="true" tabindex="-1"></a>**Important:** These internal components are **NOT directly exposed to R users** - you can't call them from an R script. However, they **ARE fully accessible if you're developing new methods in C++** using BigDataStatMeth as a header-only library. If you're implementing a new statistical method in C++, you have full access to these low-level building blocks.</span>
<span id="cb9-962"><a href="#cb9-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-963"><a href="#cb9-963" aria-hidden="true" tabindex="-1"></a>Each high-level algorithm (PCA, regression, etc.) uses these internal functions and manages its own block iteration strategy for optimal performance. The block-reading logic is algorithm-specific rather than exposed as general-purpose functions because different algorithms benefit from different iteration patterns.</span>
<span id="cb9-964"><a href="#cb9-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-965"><a href="#cb9-965" aria-hidden="true" tabindex="-1"></a>**2. Mid-Level Functions (C++ with R bindings):**</span>
<span id="cb9-966"><a href="#cb9-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-967"><a href="#cb9-967" aria-hidden="true" tabindex="-1"></a>Block-wise operations implemented in C++ but accessible from both R and C++:</span>
<span id="cb9-968"><a href="#cb9-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-969"><a href="#cb9-969" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`bdCrossprod_hdf5()`</span> / <span class="in">`bdtCrossprod_hdf5()`</span> - Crossproduct operations</span>
<span id="cb9-970"><a href="#cb9-970" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`bdblockmult_hdf5()`</span> - Matrix multiplication</span>
<span id="cb9-971"><a href="#cb9-971" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`bdNormalize_hdf5()`</span> - Centering and scaling</span>
<span id="cb9-972"><a href="#cb9-972" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`bdApply_hdf5()`</span> - Apply functions to blocks</span>
<span id="cb9-973"><a href="#cb9-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-974"><a href="#cb9-974" aria-hidden="true" tabindex="-1"></a>These functions handle the complexity of block iteration, parallel processing, and result accumulation internally. From R, you simply call them with appropriate parameters.</span>
<span id="cb9-975"><a href="#cb9-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-976"><a href="#cb9-976" aria-hidden="true" tabindex="-1"></a>**3. High-Level Statistical Methods (C++ with R bindings):**</span>
<span id="cb9-977"><a href="#cb9-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-978"><a href="#cb9-978" aria-hidden="true" tabindex="-1"></a>Complete statistical analyses implemented using the mid-level functions:</span>
<span id="cb9-979"><a href="#cb9-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-980"><a href="#cb9-980" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`bdSVD_hdf5()`</span> - Singular Value Decomposition</span>
<span id="cb9-981"><a href="#cb9-981" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`bdPCA_hdf5()`</span> - Principal Component Analysis  </span>
<span id="cb9-982"><a href="#cb9-982" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`bdQR_hdf5()`</span> - QR Decomposition</span>
<span id="cb9-983"><a href="#cb9-983" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Regression methods, association tests, etc.</span>
<span id="cb9-984"><a href="#cb9-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-985"><a href="#cb9-985" aria-hidden="true" tabindex="-1"></a><span class="fu">### Developing New Methods</span></span>
<span id="cb9-986"><a href="#cb9-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-987"><a href="#cb9-987" aria-hidden="true" tabindex="-1"></a>**Approach 1: Compose from existing functions (Recommended for R users)**</span>
<span id="cb9-988"><a href="#cb9-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-989"><a href="#cb9-989" aria-hidden="true" tabindex="-1"></a>Use existing mid-level and high-level functions as building blocks. Example: implementing Canonical Correlation Analysis (CCA) in R:</span>
<span id="cb9-990"><a href="#cb9-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-991"><a href="#cb9-991" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb9-992"><a href="#cb9-992" aria-hidden="true" tabindex="-1"></a><span class="co"># CCA implementation using BigDataStatMeth functions</span></span>
<span id="cb9-993"><a href="#cb9-993" aria-hidden="true" tabindex="-1"></a>bdCCA_hdf5 <span class="ot">&lt;-</span> <span class="cf">function</span>(filename, X_dataset, Y_dataset, <span class="at">k =</span> <span class="dv">10</span>) {</span>
<span id="cb9-994"><a href="#cb9-994" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-995"><a href="#cb9-995" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1: Normalize both datasets</span></span>
<span id="cb9-996"><a href="#cb9-996" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bdNormalize_hdf5</span>(filename, X_dataset, <span class="at">bcenter =</span> <span class="cn">TRUE</span>, <span class="at">bscale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb9-997"><a href="#cb9-997" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bdNormalize_hdf5</span>(filename, Y_dataset, <span class="at">bcenter =</span> <span class="cn">TRUE</span>, <span class="at">bscale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb9-998"><a href="#cb9-998" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-999"><a href="#cb9-999" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 2: Compute QR decomposition for each</span></span>
<span id="cb9-1000"><a href="#cb9-1000" aria-hidden="true" tabindex="-1"></a>  qr_x <span class="ot">&lt;-</span> <span class="fu">bdQR_hdf5</span>(filename, X_dataset)</span>
<span id="cb9-1001"><a href="#cb9-1001" aria-hidden="true" tabindex="-1"></a>  qr_y <span class="ot">&lt;-</span> <span class="fu">bdQR_hdf5</span>(filename, Y_dataset)</span>
<span id="cb9-1002"><a href="#cb9-1002" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1003"><a href="#cb9-1003" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 3: Compute cross-product of Q matrices</span></span>
<span id="cb9-1004"><a href="#cb9-1004" aria-hidden="true" tabindex="-1"></a>  cross <span class="ot">&lt;-</span> <span class="fu">bdCrossprod_hdf5</span>(</span>
<span id="cb9-1005"><a href="#cb9-1005" aria-hidden="true" tabindex="-1"></a>    filename, </span>
<span id="cb9-1006"><a href="#cb9-1006" aria-hidden="true" tabindex="-1"></a>    <span class="at">A =</span> qr_x<span class="sc">$</span>Q_dataset,</span>
<span id="cb9-1007"><a href="#cb9-1007" aria-hidden="true" tabindex="-1"></a>    <span class="at">B =</span> qr_y<span class="sc">$</span>Q_dataset</span>
<span id="cb9-1008"><a href="#cb9-1008" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-1009"><a href="#cb9-1009" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1010"><a href="#cb9-1010" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 4: SVD of cross-product</span></span>
<span id="cb9-1011"><a href="#cb9-1011" aria-hidden="true" tabindex="-1"></a>  svd_result <span class="ot">&lt;-</span> <span class="fu">bdSVD_hdf5</span>(filename, cross<span class="sc">$</span>dataset, <span class="at">k =</span> k)</span>
<span id="cb9-1012"><a href="#cb9-1012" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1013"><a href="#cb9-1013" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 5: Back-transform to get canonical variates</span></span>
<span id="cb9-1014"><a href="#cb9-1014" aria-hidden="true" tabindex="-1"></a>  <span class="co"># ... (using bdblockmult_hdf5 to multiply through)</span></span>
<span id="cb9-1015"><a href="#cb9-1015" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1016"><a href="#cb9-1016" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">correlations =</span> svd_result<span class="sc">$</span>d, ...))</span>
<span id="cb9-1017"><a href="#cb9-1017" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-1018"><a href="#cb9-1018" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-1019"><a href="#cb9-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1020"><a href="#cb9-1020" aria-hidden="true" tabindex="-1"></a>This approach leverages existing optimized functions without writing C++ code.</span>
<span id="cb9-1021"><a href="#cb9-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1022"><a href="#cb9-1022" aria-hidden="true" tabindex="-1"></a>**Approach 2: Implement in C++ (For developers)**</span>
<span id="cb9-1023"><a href="#cb9-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1024"><a href="#cb9-1024" aria-hidden="true" tabindex="-1"></a>For maximum performance or novel algorithms, implement directly in C++. You'll work with:</span>
<span id="cb9-1025"><a href="#cb9-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1026"><a href="#cb9-1026" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`hdf5Dataset`</span> class for file access</span>
<span id="cb9-1027"><a href="#cb9-1027" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Eigen library for linear algebra</span>
<span id="cb9-1028"><a href="#cb9-1028" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>OpenMP for parallelization</span>
<span id="cb9-1029"><a href="#cb9-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1030"><a href="#cb9-1030" aria-hidden="true" tabindex="-1"></a>See the CCA implementation examples in the package source (<span class="in">`Example_bdCCA.cpp`</span>, <span class="in">`Example_bdCCA.h`</span>) which show both R-based and C++-based approaches to the same algorithm.</span>
<span id="cb9-1031"><a href="#cb9-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1032"><a href="#cb9-1032" aria-hidden="true" tabindex="-1"></a>**Key consideration:** The C++ approach requires understanding:</span>
<span id="cb9-1033"><a href="#cb9-1033" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Memory management in C++</span>
<span id="cb9-1034"><a href="#cb9-1034" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>HDF5 C API through <span class="in">`hdf5Dataset`</span> wrapper  </span>
<span id="cb9-1035"><a href="#cb9-1035" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Eigen matrix operations</span>
<span id="cb9-1036"><a href="#cb9-1036" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Thread safety for parallel operations</span>
<span id="cb9-1037"><a href="#cb9-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1038"><a href="#cb9-1038" aria-hidden="true" tabindex="-1"></a>Most users will find composing from existing functions sufficient. The C++ API is there for those developing new core algorithms or requiring maximum performance.</span>
<span id="cb9-1039"><a href="#cb9-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1040"><a href="#cb9-1040" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learning from Examples</span></span>
<span id="cb9-1041"><a href="#cb9-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1042"><a href="#cb9-1042" aria-hidden="true" tabindex="-1"></a>The package includes several complete examples showing different implementation strategies:</span>
<span id="cb9-1043"><a href="#cb9-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1044"><a href="#cb9-1044" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**`Example_bdCCA_hdf5_R.R`** - CCA implemented purely in R using BigDataStatMeth functions</span>
<span id="cb9-1045"><a href="#cb9-1045" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**`Example_bdCCA.cpp/.h`** - CCA implemented in C++ for comparison</span>
<span id="cb9-1046"><a href="#cb9-1046" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**`Example_getQRbyBlocks.R`** - Hierarchical QR showing block partitioning strategies</span>
<span id="cb9-1047"><a href="#cb9-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1048"><a href="#cb9-1048" aria-hidden="true" tabindex="-1"></a>These examples demonstrate how to think through:</span>
<span id="cb9-1049"><a href="#cb9-1049" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>What can be computed block-by-block?</span>
<span id="cb9-1050"><a href="#cb9-1050" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>What intermediate results need to be merged?</span>
<span id="cb9-1051"><a href="#cb9-1051" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>What's the memory footprint at each step?</span>
<span id="cb9-1052"><a href="#cb9-1052" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>When to write intermediate results to HDF5 vs. keep in memory?</span>
<span id="cb9-1053"><a href="#cb9-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1054"><a href="#cb9-1054" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interactive Exercise {.exercise}</span></span>
<span id="cb9-1055"><a href="#cb9-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1056"><a href="#cb9-1056" aria-hidden="true" tabindex="-1"></a><span class="fu">### Practice: Analyzing Block-Wise Efficiency</span></span>
<span id="cb9-1057"><a href="#cb9-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1058"><a href="#cb9-1058" aria-hidden="true" tabindex="-1"></a>Understanding which operations work well with block-wise processing and which present challenges helps you design efficient analysis pipelines. This exercise develops that intuition.</span>
<span id="cb9-1059"><a href="#cb9-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1062"><a href="#cb9-1062" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-1063"><a href="#cb9-1063" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb9-1064"><a href="#cb9-1064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1065"><a href="#cb9-1065" aria-hidden="true" tabindex="-1"></a><span class="co"># Consider this analysis workflow</span></span>
<span id="cb9-1066"><a href="#cb9-1066" aria-hidden="true" tabindex="-1"></a>analyze_workflow <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb9-1067"><a href="#cb9-1067" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 1: Compute column means</span></span>
<span id="cb9-1068"><a href="#cb9-1068" aria-hidden="true" tabindex="-1"></a>  means <span class="ot">&lt;-</span> <span class="fu">bdColMeans_hdf5</span>(file, dataset)</span>
<span id="cb9-1069"><a href="#cb9-1069" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1070"><a href="#cb9-1070" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 2: Center the data  </span></span>
<span id="cb9-1071"><a href="#cb9-1071" aria-hidden="true" tabindex="-1"></a>  centered <span class="ot">&lt;-</span> <span class="fu">bdNormalize_hdf5</span>(file, dataset, <span class="at">bcenter =</span> <span class="cn">TRUE</span>, <span class="at">bscale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb9-1072"><a href="#cb9-1072" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1073"><a href="#cb9-1073" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 3: Compute t(X) %*% X</span></span>
<span id="cb9-1074"><a href="#cb9-1074" aria-hidden="true" tabindex="-1"></a>  crossprod <span class="ot">&lt;-</span> <span class="fu">bdCrossprod_hdf5</span>(file, centered)</span>
<span id="cb9-1075"><a href="#cb9-1075" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1076"><a href="#cb9-1076" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Operation 4: Eigen-decomposition for PCA</span></span>
<span id="cb9-1077"><a href="#cb9-1077" aria-hidden="true" tabindex="-1"></a>  pca <span class="ot">&lt;-</span> <span class="fu">bdSVD_hdf5</span>(file, crossprod)</span>
<span id="cb9-1078"><a href="#cb9-1078" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-1079"><a href="#cb9-1079" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Question: Which operations are most/least block-amenable?</span></span>
<span id="cb9-1080"><a href="#cb9-1080" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-1081"><a href="#cb9-1081" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-1082"><a href="#cb9-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1083"><a href="#cb9-1083" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb9-1084"><a href="#cb9-1084" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reflection Questions</span></span>
<span id="cb9-1085"><a href="#cb9-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1086"><a href="#cb9-1086" aria-hidden="true" tabindex="-1"></a>Think through these scenarios - understanding the principles matters more than having "correct" answers:</span>
<span id="cb9-1087"><a href="#cb9-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1088"><a href="#cb9-1088" aria-hidden="true" tabindex="-1"></a>**1. Operation Efficiency Analysis:**</span>
<span id="cb9-1089"><a href="#cb9-1089" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Which operation above is most naturally block-wise? Why?</span>
<span id="cb9-1090"><a href="#cb9-1090" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Which operation requires the most inter-block coordination?</span>
<span id="cb9-1091"><a href="#cb9-1091" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>If you had to do this with limited memory, which step would be the bottleneck?</span>
<span id="cb9-1092"><a href="#cb9-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1093"><a href="#cb9-1093" aria-hidden="true" tabindex="-1"></a>**2. Block Size Decisions:**</span>
<span id="cb9-1094"><a href="#cb9-1094" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>For a 100,000 × 50,000 matrix with 32 GB RAM available, what block size would you choose?</span>
<span id="cb9-1095"><a href="#cb9-1095" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>What if you had 128 GB RAM? Would you still use blocks?</span>
<span id="cb9-1096"><a href="#cb9-1096" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>How would block size affect the accuracy of the results?</span>
<span id="cb9-1097"><a href="#cb9-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1098"><a href="#cb9-1098" aria-hidden="true" tabindex="-1"></a>**3. Algorithm Adaptation:**</span>
<span id="cb9-1099"><a href="#cb9-1099" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Consider k-means clustering. Can you decompose it block-wise?</span>
<span id="cb9-1100"><a href="#cb9-1100" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>What about hierarchical clustering?</span>
<span id="cb9-1101"><a href="#cb9-1101" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Which machine learning algorithms would be easy vs. hard to adapt?</span>
<span id="cb9-1102"><a href="#cb9-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1103"><a href="#cb9-1103" aria-hidden="true" tabindex="-1"></a>**4. Designing Your Pipeline:**</span>
<span id="cb9-1104"><a href="#cb9-1104" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Your analysis needs: QC filtering, normalization, PCA, then regression</span>
<span id="cb9-1105"><a href="#cb9-1105" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Which steps can process data block-by-block independently?</span>
<span id="cb9-1106"><a href="#cb9-1106" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Which steps need access to summary statistics from all data?</span>
<span id="cb9-1107"><a href="#cb9-1107" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Where would you store intermediate results?</span>
<span id="cb9-1108"><a href="#cb9-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1109"><a href="#cb9-1109" aria-hidden="true" tabindex="-1"></a>**5. Trade-offs:**</span>
<span id="cb9-1110"><a href="#cb9-1110" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Smaller blocks = less memory but more disk I/O</span>
<span id="cb9-1111"><a href="#cb9-1111" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Larger blocks = more memory but fewer I/O operations  </span>
<span id="cb9-1112"><a href="#cb9-1112" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>For your system, where's the sweet spot?</span>
<span id="cb9-1113"><a href="#cb9-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1114"><a href="#cb9-1114" aria-hidden="true" tabindex="-1"></a>Try sketching out a block-wise version of your actual analysis pipeline. Which parts translate easily? Which require creative rethinking? This mental exercise builds intuition for designing efficient big data workflows.</span>
<span id="cb9-1115"><a href="#cb9-1115" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-1116"><a href="#cb9-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1117"><a href="#cb9-1117" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key Takeaways {.key-concept}</span></span>
<span id="cb9-1118"><a href="#cb9-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1119"><a href="#cb9-1119" aria-hidden="true" tabindex="-1"></a>Let's consolidate what you've learned about adapting algorithms for block-wise processing with disk-based data.</span>
<span id="cb9-1120"><a href="#cb9-1120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1121"><a href="#cb9-1121" aria-hidden="true" tabindex="-1"></a><span class="fu">### Essential Concepts</span></span>
<span id="cb9-1122"><a href="#cb9-1122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1123"><a href="#cb9-1123" aria-hidden="true" tabindex="-1"></a>**The divide-process-combine paradigm** underlies all block-wise computing. You partition data into manageable pieces, process each piece (often independently), then combine results to get the final answer. This simple pattern adapts to operations from simple means to complex matrix factorizations. The challenge lies in figuring out *what* to process and *how* to combine results validly.</span>
<span id="cb9-1124"><a href="#cb9-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1125"><a href="#cb9-1125" aria-hidden="true" tabindex="-1"></a>**Block-amenable operations** share common mathematical properties that make them decompose naturally. Operations that can be expressed as sums, products, or aggregations across independent portions of data work well. Computing means, sums, element-wise operations, and many matrix products fall into this category. The mathematical structure of these operations allows valid decomposition.</span>
<span id="cb9-1126"><a href="#cb9-1126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1127"><a href="#cb9-1127" aria-hidden="true" tabindex="-1"></a>**Block-resistant operations** require information flow between all parts of the data or produce outputs that scale problematically. Anything requiring global sorting, finding specific quantiles, or creating O(n²) outputs challenges block-wise approaches. These operations don't decompose cleanly - they need special algorithmic tricks or fundamentally different approaches.</span>
<span id="cb9-1128"><a href="#cb9-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1129"><a href="#cb9-1129" aria-hidden="true" tabindex="-1"></a>**Block size creates a memory-accuracy-speed trade-off** with no universally optimal choice. Smaller blocks use less memory but require more disk I/O and potentially more approximation error in hierarchical algorithms. Larger blocks use more memory but require fewer I/O operations and may be more accurate. The optimal choice depends on your available RAM, disk speed, and accuracy requirements.</span>
<span id="cb9-1130"><a href="#cb9-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1131"><a href="#cb9-1131" aria-hidden="true" tabindex="-1"></a>**Hierarchical processing** enables algorithms that don't naturally decompose to single-pass block operations. By creating multiple levels of computation - process blocks, merge results into smaller intermediate blocks, repeat until small enough - you can handle very large matrices while controlling memory usage at each level. This is how BigDataStatMeth implements complex operations like SVD/PCA.</span>
<span id="cb9-1132"><a href="#cb9-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1133"><a href="#cb9-1133" aria-hidden="true" tabindex="-1"></a>**Composability is power.** You can build complex analyses by composing simple block-wise operations. Rather than implementing every possible analysis from scratch in C++, combine existing functions: normalize, compute crossproduct, perform SVD, multiply back through. This compositional approach lets you implement new methods at the R level, leveraging optimized core operations.</span>
<span id="cb9-1134"><a href="#cb9-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1135"><a href="#cb9-1135" aria-hidden="true" tabindex="-1"></a><span class="fu">### When Block-Wise Processing Works Well</span></span>
<span id="cb9-1136"><a href="#cb9-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1137"><a href="#cb9-1137" aria-hidden="true" tabindex="-1"></a>Understanding which problems benefit from block-wise approaches helps you make good architectural decisions for your analyses.</span>
<span id="cb9-1138"><a href="#cb9-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1139"><a href="#cb9-1139" aria-hidden="true" tabindex="-1"></a>✅ **Highly effective for:**</span>
<span id="cb9-1140"><a href="#cb9-1140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1141"><a href="#cb9-1141" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Matrix multiplication and products** - These decompose naturally into block-block operations. BigDataStatMeth's implementations are highly optimized and scale well.</span>
<span id="cb9-1142"><a href="#cb9-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1143"><a href="#cb9-1143" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Element-wise operations** - Operations like adding, subtracting, multiplying by scalars process each element independently. Perfect for block-wise processing with no communication overhead.</span>
<span id="cb9-1144"><a href="#cb9-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1145"><a href="#cb9-1145" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Row or column operations** - Computing means, sums, normalizations by rows or columns work naturally with blocks containing complete rows or columns.</span>
<span id="cb9-1146"><a href="#cb9-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1147"><a href="#cb9-1147" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Many factorizations** - SVD, QR, and Cholesky decompositions have hierarchical block-wise algorithms that maintain numerical accuracy while limiting memory usage.</span>
<span id="cb9-1148"><a href="#cb9-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1149"><a href="#cb9-1149" aria-hidden="true" tabindex="-1"></a>❌ **Challenging for:**</span>
<span id="cb9-1150"><a href="#cb9-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1151"><a href="#cb9-1151" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Global operations** - Finding the median, computing percentiles, or operations that require knowing the full data distribution don't decompose easily.</span>
<span id="cb9-1152"><a href="#cb9-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1153"><a href="#cb9-1153" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Fine-grained dependencies** - Algorithms where each element depends on many others (like some iterative optimization methods) resist block decomposition.</span>
<span id="cb9-1154"><a href="#cb9-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1155"><a href="#cb9-1155" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Operations creating large outputs** - Computing all pairwise distances or correlations creates O(n²) results. Even block-wise approaches struggle when output size explodes.</span>
<span id="cb9-1156"><a href="#cb9-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1157"><a href="#cb9-1157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Highly iterative methods** - Algorithms requiring many passes through data with convergence checks add overhead when each pass means disk I/O.</span>
<span id="cb9-1158"><a href="#cb9-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1159"><a href="#cb9-1159" aria-hidden="true" tabindex="-1"></a>For most statistical analyses in genomics and similar fields - PCA, regression, association tests, basic machine learning - block-wise approaches work very well. The operations these methods need decompose naturally. More specialized algorithms may require case-by-case evaluation of whether block-wise processing provides benefits.</span>
<span id="cb9-1160"><a href="#cb9-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1161"><a href="#cb9-1161" aria-hidden="true" tabindex="-1"></a><span class="fu">## Next Steps</span></span>
<span id="cb9-1162"><a href="#cb9-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1163"><a href="#cb9-1163" aria-hidden="true" tabindex="-1"></a>You now understand how standard statistical algorithms adapt for disk-based data processing. This conceptual foundation prepares you to:</span>
<span id="cb9-1164"><a href="#cb9-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1165"><a href="#cb9-1165" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">**Understand Linear Algebra Foundations →**</span><span class="co">](linear-algebra.qmd)</span> Review the mathematical operations BigDataStatMeth implements</span>
<span id="cb9-1166"><a href="#cb9-1166" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">**Getting Started Tutorial →**</span><span class="co">](../tutorials/getting-started.qmd)</span> Apply these concepts to your own data</span>
<span id="cb9-1167"><a href="#cb9-1167" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">**CCA Implementation Example →**</span><span class="co">](../workflows/canonical-correlation.qmd)</span> See a complete complex method implemented block-wise</span>
<span id="cb9-1168"><a href="#cb9-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1169"><a href="#cb9-1169" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb9-1170"><a href="#cb9-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1171"><a href="#cb9-1171" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb9-1172"><a href="#cb9-1172" aria-hidden="true" tabindex="-1"></a><span class="fu">### Want to Learn More?</span></span>
<span id="cb9-1173"><a href="#cb9-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-1174"><a href="#cb9-1174" aria-hidden="true" tabindex="-1"></a>The BigDataStatMeth paper provides mathematical details and proofs for the hierarchical algorithms. The <span class="co">[</span><span class="ot">C++ API documentation</span><span class="co">](../api-reference/cpp-api.qmd)</span> shows lower-level implementation details if you want to understand exactly how operations are executed.</span>
<span id="cb9-1175"><a href="#cb9-1175" aria-hidden="true" tabindex="-1"></a>:::</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025 BigDataStatMeth - ISGlobal BRGE</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/isglobal-brge/BigDataStatMeth/edit/main/fundamentals/blockwise-computing.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/isglobal-brge/BigDataStatMeth/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/isglobal-brge/BigDataStatMeth">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item">
 License: GPL-3
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>