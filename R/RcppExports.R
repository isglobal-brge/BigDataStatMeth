# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Cholesky Decomposition for HDF5-Stored Matrices
#'
#' @description
#' Computes the Cholesky decomposition of a symmetric positive-definite matrix stored
#' in an HDF5 file. The Cholesky decomposition factors a matrix A into the product
#' A = LL' where L is a lower triangular matrix.
#' 
#' @details 
#' The Cholesky decomposition is a specialized factorization for symmetric 
#' positive-definite matrices that provides several advantages:
#' * More efficient than LU decomposition for symmetric positive-definite matrices
#' * Numerically stable
#' * Useful for solving linear systems and computing matrix inverses
#' * Important in statistical computing (e.g., for sampling from multivariate normal distributions)
#'
#' This implementation features:
#' * Block-based computation for large matrices
#' * Optional storage formats (full or triangular)
#' * Parallel processing support
#' * Memory-efficient block algorithm
#'
#' Mathematical Details:
#' For a symmetric positive-definite matrix A, the decomposition A = LL' has the following properties:
#' * L is lower triangular
#' * L has positive diagonal elements
#' * L is unique
#'
#' The elements of L are computed using:
#' \deqn{l_{ii} = \sqrt{a_{ii} - \sum_{k=1}^{i-1} l_{ik}^2}}
#' \deqn{l_{ji} = \frac{1}{l_{ii}}(a_{ji} - \sum_{k=1}^{i-1} l_{ik}l_{jk})}
#'
#' @param filename Character string. Path to the HDF5 file containing the input matrix.
#' @param group Character string. Path to the group containing the input dataset.
#' @param dataset Character string. Name of the input dataset to decompose.
#' @param outdataset Character string. Name for the output dataset.
#' @param outgroup Character string. Optional output group path. If not provided,
#'   results are stored in the input group.
#' @param fullMatrix Logical. If TRUE, stores the complete matrix. If FALSE (default),
#'   stores only the lower triangular part to save space.
#' @param overwrite Logical. If TRUE, allows overwriting existing results.
#' @param threads Integer. Number of threads for parallel computation.
#' @param elementsBlock Integer. Maximum number of elements to process in each block
#'   (default = 100,000). For matrices larger than 5000x5000, automatically adjusted
#'   to number of rows or columns * 2.
#'
#' @return No direct return value. Results are written to the HDF5 file in the
#' specified location with the following structure:
#' \describe{
#'   \item{L}{The lower triangular Cholesky factor}
#' }
#' 
#' @examples
#' \dontrun{
#' library(rhdf5)
#' 
#' # Create a symmetric positive-definite matrix
#' set.seed(1234)
#' X <- matrix(rnorm(100), 10, 10)
#' A <- crossprod(X)  # A = X'X is symmetric positive-definite
#'     
#' # Save to HDF5
#' h5createFile("matrix.h5")
#' h5write(A, "matrix.h5", "data/matrix")
#'         
#' # Compute Cholesky decomposition
#' bdCholesky_hdf5("matrix.h5", "data", "matrix",
#'                 outdataset = "chol",
#'                 outgroup = "decompositions",
#'                 fullMatrix = FALSE)
#'        
#' # Verify the decomposition
#' L <- h5read("matrix.h5", "decompositions/chol")
#' max(abs(A - L %*% t(L)))  # Should be very small
#' }
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Higham, N. J. (2009). Cholesky factorization.
#'   Wiley Interdisciplinary Reviews: Computational Statistics, 1(2), 251-254.
#'        
#' @seealso
#' * \code{\link{bdInvCholesky_hdf5}} for computing inverse using Cholesky decomposition
#' * \code{\link{bdSolve_hdf5}} for solving linear systems
#' 
#' @export
bdCholesky_hdf5 <- function(filename, group, dataset, outdataset, outgroup = NULL, fullMatrix = NULL, overwrite = NULL, threads = NULL, elementsBlock = 1000000L) {
    .Call('_BigDataStatMeth_bdCholesky_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outdataset, outgroup, fullMatrix, overwrite, threads, elementsBlock)
}

#' QR Decomposition for In-Memory Matrices
#' 
#' @description
#' Computes the QR decomposition (also called QR factorization) of a matrix A into 
#' a product A = QR where Q is an orthogonal matrix and R is an upper triangular matrix.
#' This function operates on in-memory matrices.
#' 
#' @details
#' The QR decomposition is a fundamental matrix factorization that decomposes a matrix 
#' into an orthogonal matrix Q and an upper triangular matrix R. This implementation:
#' * Supports both thin and full QR decomposition
#' * Can utilize parallel computation for better performance
#' * Handles both matrix and vector inputs
#' 
#' @param X A real matrix or vector to be decomposed
#' @param thin Logical. If TRUE, returns the reduced (thin) Q matrix. If FALSE (default),
#'   returns the full Q matrix. The thin decomposition is more memory efficient.
#' @param block_size Integer. Optional block size for blocked computation. Larger blocks
#'   may improve performance but require more memory.
#' @param threads Integer. Optional number of threads for parallel computation. If NULL,
#'   uses all available threads.
#'
#' @return A list containing:
#'   * Q: The orthogonal matrix Q
#'   * R: The upper triangular matrix R
#'
#' @examples
#' \dontrun{
#' # Create a random 100x50 matrix
#' X <- matrix(rnorm(5000), 100, 50)
#' 
#' # Compute thin QR decomposition
#' result <- bdQR(X, thin = TRUE)
#' 
#' # Verify the decomposition
#' # Should be approximately zero
#' max(abs(X - result$Q %*% result$R))
#' }
#'
#' @seealso
#' \code{\link{bdQR_hdf5}} for QR decomposition of HDF5-stored matrices
#'
#' @export
bdQR <- function(X, thin = NULL, block_size = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdQR', PACKAGE = 'BigDataStatMeth', X, thin, block_size, threads)
}

#' QR Decomposition for HDF5-Stored Matrices
#' 
#' @description
#' Computes the QR decomposition of a matrix stored in an HDF5 file, factoring it into 
#' a product A = QR where Q is an orthogonal matrix and R is an upper triangular matrix.
#' Results are stored back in the HDF5 file.
#' 
#' @details
#' This function performs QR decomposition on large matrices stored in HDF5 format,
#' which is particularly useful for matrices too large to fit in memory. Features include:
#' * Support for both thin and full QR decomposition
#' * Blocked computation for improved performance
#' * Parallel processing capabilities
#' * Flexible output location specification
#' * Optional overwriting of existing datasets
#'
#' @param filename Character string. Path to the HDF5 file containing the input matrix.
#' @param group Character string. Path to the group containing the input dataset.
#' @param dataset Character string. Name of the input dataset to decompose.
#' @param outgroup Character string. Optional output group path where results will be stored.
#'   If not provided, results are stored in `<input_group>/QRDec`.
#' @param outdataset Character string. Optional base name for output datasets. Results
#'   will be stored as `Q.<outdataset>` and `R.<outdataset>`.
#' @param thin Logical. If TRUE, computes the reduced (thin) QR decomposition.
#'   If FALSE (default), computes the full decomposition.
#' @param block_size Integer. Optional block size for blocked computation.
#' @param overwrite Logical. If TRUE, allows overwriting existing datasets.
#'   Default is FALSE.
#' @param threads Integer. Optional number of threads for parallel computation.
#'   If NULL, uses all available threads.
#'
#' @return No return value. Results are written to the HDF5 file as:
#'   * Q.outdataset: The orthogonal matrix Q
#'   * R.outdataset: The upper triangular matrix R
#'
#' @examples
#' \dontrun{
#' # Create a sample HDF5 file with a matrix
#' library(rhdf5)
#' A <- matrix(rnorm(1000), 100, 10)
#' h5createFile("example.h5")
#' h5write(A, "example.h5", "mygroup/mymatrix")
#'
#' # Compute QR decomposition
#' bdQR_hdf5("example.h5", "mygroup", "mymatrix",
#'           outgroup = "mygroup/results",
#'           outdataset = "qr_result",
#'           thin = TRUE)
#' }
#'
#' @seealso
#' \code{\link{bdQR}} for QR decomposition of in-memory matrices
#'
#' @export
bdQR_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, thin = NULL, block_size = NULL, overwrite = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdQR_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, thin, block_size, overwrite, threads)
}

#' Singular Value Decomposition for HDF5-Stored Matrices
#'
#' @description
#' Computes the Singular Value Decomposition (SVD) of a large matrix stored in an HDF5 file.
#' The SVD decomposes a matrix A into a product A = UDV' where U and V are orthogonal
#' matrices and D is a diagonal matrix containing the singular values.
#' 
#' @details
#' This function implements a block-based SVD algorithm suitable for large matrices
#' that may not fit in memory. Key features include:
#' * Automatic method selection based on matrix size
#' * Block-based computation for large matrices
#' * Data centering and scaling options
#' * Parallel processing support
#' * Rank approximation through threshold
#' * Memory-efficient incremental algorithm
#'
#' The implementation uses an incremental algorithm with two key parameters:
#' * k: number of local SVDs to concatenate at each level
#' * q: number of levels in the computation
#'
#' @param filename Character string. Path to the HDF5 file containing the input matrix.
#' @param group Character string. Path to the group containing the input dataset.
#' @param dataset Character string. Name of the input dataset to decompose.
#' @param k Integer. Number of local SVDs to concatenate at each level (default = 2).
#'   Controls the trade-off between memory usage and computation speed.
#' @param q Integer. Number of levels for SVD computation (default = 1).
#'   Higher values can improve accuracy but increase computation time.
#' @param bcenter Logical. If TRUE (default), centers the data by subtracting column means.
#' @param bscale Logical. If TRUE (default), scales the centered columns by their
#'   standard deviations or root mean square.
#' @param rankthreshold Numeric. Threshold for determining matrix rank (default = 0).
#'   Must be between 0 and 0.1. Used to approximate rank for nearly singular matrices.
#' @param overwrite Logical. If TRUE, allows overwriting existing results.
#' @param method Character string. Computation method:
#'   * "auto": Automatically selects between "full" and "blocks" based on matrix size
#'   * "blocks": Uses block-based computation (recommended for large matrices)
#'   * "full": Performs direct computation without partitioning
#' @param threads Integer. Number of threads for parallel computation.
#'
#' @return A list with the following elements:
#' \describe{
#'   \item{fn}{Path to the HDF5 file}
#'   \item{ds_d}{Path to the dataset containing singular values}
#'   \item{ds_u}{Path to the dataset containing left singular vectors}
#'   \item{ds_v}{Path to the dataset containing right singular vectors}
#' }
#'
#' @examples
#' \dontrun{
#' # Create a sample large matrix in HDF5
#'
#' library(BigDataStatMeth)
#' library(rhdf5)
#' 
#' # Create a sample large matrix in HDF5
#' A <- matrix(rnorm(10000), 1000, 10)
#' 
#' fn <- "test_temp.hdf5"
#' bdCreate_hdf5_matrix(filename = fn, object = A, group = "data", dataset = "matrix")
#'
#' # Compute SVD with default parameters
#' res <- bdSVD_hdf5(fn, "data", "matrix")
#'
#' # Compute SVD with custom parameters
#' res <- bdSVD_hdf5(fn, "data", "matrix",
#'            k = 4, q = 2,
#'            bcenter = TRUE, bscale = TRUE,
#'            method = "blocks",
#'            threads = 4)
#' 
#' # list contents
#' h5ls(res$fn)
#' 
#' # Extract the result from HDF5 (d)
#' result_d_hdf5 <- h5read(res$fn, res$ds_d)
#' result_d_hdf5
#' 
#' # Compute the same SVD in R
#' result_d_r <- svd(A)$d
#' result_d_r
#' 
#' # Compare both results (should be TRUE)
#' all.equal(result_d_hdf5, result_d_r)
#' 
#' # Remove file
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' 
#' }
#'
#' @references
#' * Halko, N., Martinsson, P. G., & Tropp, J. A. (2011). Finding structure with randomness:
#'   Probabilistic algorithms for constructing approximate matrix decompositions.
#'   SIAM Review, 53(2), 217-288.
#'
#' @seealso
#' * \code{\link{bdPCA_hdf5}} for Principal Component Analysis
#' * \code{\link{bdQR_hdf5}} for QR decomposition
#'
#' @export
bdSVD_hdf5 <- function(filename, group = NULL, dataset = NULL, k = 2L, q = 1L, bcenter = TRUE, bscale = TRUE, rankthreshold = 0.0, overwrite = NULL, method = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdSVD_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, k, q, bcenter, bscale, rankthreshold, overwrite, method, threads)
}

#' Solve Linear System AX = B (In-Memory)
#'
#' @description
#' Solves the linear system AX = B where A is an N-by-N matrix and X and B are
#' N-by-NRHS matrices. The function automatically detects if A is symmetric and
#' uses the appropriate solver.
#'
#' @details
#' This function provides an efficient implementation for solving linear systems
#' using LAPACK routines. Key features:
#' 
#' * Automatic detection of matrix properties:
#'   - Checks for matrix symmetry
#'   - Selects optimal solver based on matrix structure
#' 
#' * Solver selection:
#'   - Symmetric systems: Uses LAPACK's dsysv routine
#'   - Non-symmetric systems: Uses LAPACK's dgesv routine
#' 
#' * Performance optimizations:
#'   - Automatic workspace sizing
#'   - Efficient memory management
#'   - Support for multiple right-hand sides
#'
#' The implementation ensures:
#' * Robust error handling
#' * Efficient memory usage
#' * Numerical stability
#' * Support for various matrix sizes
#'
#' @param A Numeric matrix. The coefficient matrix (must be square).
#' @param B Numeric matrix. The right-hand side matrix (must have same number of
#'   rows as A).
#'
#' @return Numeric matrix X, the solution to AX = B.
#'
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' n <- 500
#' m <- 500
#' 
#' A <- matrix(runif(n*m), nrow = n, ncol = m)
#' B <- matrix(runif(n), nrow = n)
#' AS <- A %*% t(A)  # Create symmetric matrix
#' 
#' # Solve using bdSolve
#' X <- bdSolve(A, B)
#' 
#' # Compare with R's solve
#' XR <- solve(A, B)
#' all.equal(X, XR, check.attributes=FALSE)
#'
#' @references
#' * Anderson, E. et al. (1999). LAPACK Users' Guide, 3rd Edition.
#'   SIAM, Philadelphia.
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#'
#' @seealso
#' * \code{\link{bdSolve_hdf5}} for solving systems with HDF5-stored matrices
#' * \code{\link{solve}} for R's built-in solver
#'
#' @export
bdSolve <- function(A, B) {
    .Call('_BigDataStatMeth_bdSolve', PACKAGE = 'BigDataStatMeth', A, B)
}

#' Solve Linear System AX = B (HDF5-Stored)
#'
#' @description
#' Solves the linear system AX = B where matrices A and B are stored in HDF5
#' format. The solution X is written back to the HDF5 file.
#'
#' @details
#' This function provides an HDF5-based implementation for solving large linear
#' systems. Key features:
#' 
#' * HDF5 Integration:
#'   - Efficient reading of input matrices
#'   - Memory-efficient processing
#'   - Direct output to HDF5 format
#' 
#' * Implementation Features:
#'   - Automatic solver selection
#'   - Support for large matrices
#'   - Flexible output options
#'   - Memory-efficient processing
#'
#' The function handles:
#' * Data validation
#' * Memory management
#' * Error handling
#' * HDF5 file operations
#'
#' @param filename String. Path to the HDF5 file.
#' @param groupA String. Group containing matrix A.
#' @param datasetA String. Dataset name for matrix A.
#' @param groupB String. Group containing matrix B.
#' @param datasetB String. Dataset name for matrix B.
#' @param outgroup Optional string. Output group name (defaults to "Solved").
#' @param outdataset Optional string. Output dataset name (defaults to "A_B").
#' @param overwrite Logical. Whether to overwrite existing results.
#'
#' @return No direct return value. Results are written to the HDF5 file.
#'
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' N <- 1000
#' M <- 1000
#' fn <- "test_temp.hdf5"
#' 
#' set.seed(555)
#' Y <- matrix(rnorm(N*M), N, M)
#' X <- matrix(rnorm(N), N, 1)
#' Ycp <- crossprod(Y)
#' 
#' # Compare with in-memory solution
#' resm <- bdSolve(Ycp, X)
#' resr <- solve(Ycp, X)
#' all.equal(resm, resr)
#' 
#' # Save matrices to HDF5
#' bdCreate_hdf5_matrix(filename = fn,
#'                      object = Ycp,
#'                      group = "data",
#'                      dataset = "A",
#'                      transp = FALSE,
#'                      overwriteFile = TRUE,
#'                      overwriteDataset = TRUE,
#'                      unlimited = FALSE)
#' 
#' bdCreate_hdf5_matrix(filename = fn,
#'                      object = X,
#'                      group = "data",
#'                      dataset = "B",
#'                      transp = FALSE,
#'                      overwriteFile = FALSE,
#'                      overwriteDataset = TRUE,
#'                      unlimited = FALSE)
#' 
#' # Solve using HDF5-stored matrices
#' bdSolve_hdf5(filename = fn,
#'              groupA = "data",
#'              datasetA = "A",
#'              groupB = "data",
#'              datasetB = "B",
#'              outgroup = "Solved",
#'              outdataset = "A_B",
#'              overwrite = TRUE)
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'     file.remove(fn)
#' }
#'
#' @references
#' * Anderson, E. et al. (1999). LAPACK Users' Guide, 3rd Edition.
#'   SIAM, Philadelphia.
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdSolve}} for in-memory matrix solving
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdSolve_hdf5 <- function(filename, groupA, datasetA, groupB, datasetB, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdSolve_hdf5', PACKAGE = 'BigDataStatMeth', filename, groupA, datasetA, groupB, datasetB, outgroup, outdataset, overwrite))
}

#' Apply function to different datasets inside a group
#'
#' This function provides a unified interface for applying various mathematical
#' operations to HDF5 datasets. It supports both single-dataset operations and
#' operations between multiple datasets.
#' 
#' @param filename Character array, indicating the name of the file to create
#' @param group Character array, indicating the input group where the data set
#'        to be imputed is
#' @param datasets Character array, indicating the input datasets to be used
#' @param outgroup Character array, indicating group where the data set will 
#'        be saved after imputation. If NULL, output dataset is stored 
#'        in the same input group
#' @param func Character array, function to be applied:
#'        - "QR": QR decomposition via bdQR()
#'        - "CrossProd": Cross product via bdCrossprod()
#'        - "tCrossProd": Transposed cross product via bdtCrossprod()
#'        - "invChol": Inverse via Cholesky decomposition
#'        - "blockmult": Matrix multiplication 
#'        - "CrossProd_double": Cross product with two matrices
#'        - "tCrossProd_double": Transposed cross product with two matrices
#'        - "solve": Matrix equation solving
#'        - "sdmean": Standard deviation and mean computation
#' @param b_group Optional character array indicating the input group for
#'        secondary datasets (used in two-matrix operations)
#' @param b_datasets Optional character array indicating the secondary datasets
#'        for two-matrix operations
#' @param overwrite Optional boolean. If true, overwrites existing results
#' @param transp_dataset Optional boolean. If true, transposes first dataset
#' @param transp_bdataset Optional boolean. If true, transposes second dataset
#' @param fullMatrix Optional boolean for Cholesky operations. If true, stores
#'        complete matrix; if false, stores only lower triangular
#' @param byrows Optional boolean for statistical operations. If true, computes
#'        by rows; if false, by columns
#' @param threads Optional integer specifying number of threads for parallel processing
#' 
#' @return Modifies the HDF5 file in place, adding computed results
#' 
#' @details
#' //' For matrix multiplication operations (`blockmult`, `CrossProd_double`, `tCrossProd_double`),
#' the `datasets` and `b_datasets` vectors must have the same length. Each operation is performed
#' element-wise between the corresponding pairs of datasets. Specifically, the `b_datasets` vector
#' defines the second operand for each matrix multiplication. For example, if
#' `datasets = {"A1", "A2", "A3"}` and `b_datasets = {"B1", "B2", "B3"}`, the operations
#' executed are: `A1 %*% B1`, `A2 %*% B2`, and `A3 %*% B3`.
#' 
#' Example: If `datasets = {"A1", "A2", "A3"}` and `b_datasets = {"B1", "B2", "B3"}`,
#' the function computes: `A1 %*% B1`, `A2 %*% B2`, and `A3 %*% B3`
#' 
#' @examples
#' \dontrun{
#' # Create a sample large matrix in HDF5
#' # Create hdf5 datasets
#' bdCreate_hdf5_matrix(filename = "test_temp.hdf5", 
#'                     object = Y, group = "data", dataset = "Y",
#'                     transp = FALSE,
#'                     overwriteFile = TRUE, overwriteDataset = TRUE, 
#'                     unlimited = FALSE)
#' 
#' bdCreate_hdf5_matrix(filename = "test_temp.hdf5", 
#'                     object = X,  group = "data",  dataset = "X",
#'                     transp = FALSE,
#'                     overwriteFile = FALSE, overwriteDataset = TRUE, 
#'                     unlimited = FALSE)
#' 
#' bdCreate_hdf5_matrix(filename = "test_temp.hdf5",
#'                     object = Z,  group = "data",  dataset = "Z",
#'                     transp = FALSE,
#'                     overwriteFile = FALSE, overwriteDataset = TRUE,
#'                     unlimited = FALSE)
#' 
#' dsets <- bdgetDatasetsList_hdf5("test_temp.hdf5", group = "data")
#' dsets
#' 
#' # Apply function :  QR Decomposition
#' bdapply_Function_hdf5(filename = "test_temp.hdf5",
#'                      group = "data",datasets = dsets,
#'                      outgroup = "QR",func = "QR",
#'                      overwrite = TRUE)
#' }
#' 
#' @note Performance is optimized through:
#'       - Block-wise processing for large datasets
#'       - Parallel computation where applicable
#'       - Memory-efficient matrix operations
#' 
#' @export
bdapply_Function_hdf5 <- function(filename, group, datasets, outgroup, func, b_group = NULL, b_datasets = NULL, overwrite = FALSE, transp_dataset = FALSE, transp_bdataset = FALSE, fullMatrix = FALSE, byrows = FALSE, threads = 2L) {
    invisible(.Call('_BigDataStatMeth_bdapply_Function_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, datasets, outgroup, func, b_group, b_datasets, overwrite, transp_dataset, transp_bdataset, fullMatrix, byrows, threads))
}

#' Principal Component Analysis for HDF5-Stored Matrices
#'
#' @description
#' Performs Principal Component Analysis (PCA) on a large matrix stored in an HDF5 file.
#' PCA reduces the dimensionality of the data while preserving as much variance as
#' possible. The implementation uses SVD internally for efficient and numerically
#' stable computation.
#' 
#' @details
#' This function implements a scalable PCA algorithm suitable for large matrices
#' that may not fit in memory. Key features include:
#' * Automatic method selection based on matrix size
#' * Block-based computation for large matrices
#' * Optional data preprocessing (centering and scaling)
#' * Parallel processing support
#' * Memory-efficient incremental algorithm
#' * Reuse of existing SVD results
#'
#' The implementation uses SVD internally and supports two computation methods:
#' * Full decomposition: Suitable for matrices that fit in memory
#' * Block-based decomposition: For large matrices, uses an incremental algorithm
#'
#' @param filename Character string. Path to the HDF5 file containing the input matrix.
#' @param group Character string. Path to the group containing the input dataset.
#' @param dataset Character string. Name of the input dataset to analyze.
#' @param ncomponents Integer. Number of principal components to compute (default = 0,
#'   which computes all components).
#' @param bcenter Logical. If TRUE, centers the data by subtracting column means.
#'   Default is FALSE.
#' @param bscale Logical. If TRUE, scales the centered columns by their standard
#'   deviations (if centered) or root mean square. Default is FALSE.
#' @param k Integer. Number of local SVDs to concatenate at each level (default = 2).
#'   Controls memory usage in block computation.
#' @param q Integer. Number of levels for SVD computation (default = 1).
#'   Higher values can improve accuracy but increase computation time.
#' @param rankthreshold Numeric. Threshold for determining matrix rank (default = 0).
#'   Must be between 0 and 0.1.
#' @param SVDgroup Character string. Group name where intermediate SVD results are
#'   stored. If SVD was previously computed, results will be reused from this group.
#' @param overwrite Logical. If TRUE, forces recomputation of SVD even if results exist.
#' @param method Character string. Computation method:
#'   * "auto": Automatically selects method based on matrix size
#'   * "blocks": Uses block-based computation (for large matrices)
#'   * "full": Performs direct computation (for smaller matrices)
#' @param threads Integer. Number of threads for parallel computation.
#'
#' @return No direct return value. Results are written to the HDF5 file in the
#' group 'PCA/`dataset`' with the following components:
#'   * sdev: Standard deviations of the principal components
#'   * rotation: Matrix of variable loadings (eigenvectors)
#'   * x: Matrix containing the rotated data (principal components)
#'   * center: Column means (if center = TRUE)
#'   * scale: Column standard deviations (if scale = TRUE)
#'
#' @examples
#' \dontrun{
#' # Create a sample large matrix in HDF5
#' library(rhdf5)
#' X <- matrix(rnorm(10000), 1000, 10)
#' h5createFile("data.h5")
#' h5write(X, "data.h5", "data/matrix")
#'
#' # Basic PCA with default parameters
#' bdPCA_hdf5("data.h5", "data", "matrix")
#'
#' # PCA with preprocessing and specific number of components
#' bdPCA_hdf5("data.h5", "data", "matrix",
#'            ncomponents = 3,
#'            bcenter = TRUE, bscale = TRUE,
#'            method = "blocks",
#'            threads = 4)
#' }
#'
#' @references
#' * Halko, N., Martinsson, P. G., & Tropp, J. A. (2011). Finding structure with randomness:
#'   Probabilistic algorithms for constructing approximate matrix decompositions.
#'   SIAM Review, 53(2), 217-288.
#' * Jolliffe, I. T. (2002). Principal Component Analysis, Second Edition.
#'   Springer Series in Statistics.
#'
#' @seealso
#' * \code{\link{bdSVD_hdf5}} for the underlying SVD computation
#' * \code{\link{bdNormalize_hdf5}} for data preprocessing options
#'
#' @export
bdPCA_hdf5 <- function(filename, group, dataset, ncomponents = 0L, bcenter = FALSE, bscale = FALSE, k = 2L, q = 1L, rankthreshold = 0.0, SVDgroup = NULL, overwrite = FALSE, method = NULL, threads = NULL) {
    invisible(.Call('_BigDataStatMeth_bdPCA_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, ncomponents, bcenter, bscale, k, q, rankthreshold, SVDgroup, overwrite, method, threads))
}

#' Bind matrices by rows or columns
#'
#' This function merges existing matrices within an HDF5 data file either by
#' combining their rows (stacking vertically) or columns (joining horizontally).
#' It provides functionality similar to R's rbind and cbind operations.
#' 
#' @param filename Character array indicating the name of the file to create
#' @param group Character array indicating the input group containing the datasets
#' @param datasets Character array specifying the input datasets to bind
#' @param outgroup Character array indicating the output group for the merged dataset.
#'        If NULL, output is stored in the same input group
#' @param outdataset Character array specifying the name for the new merged dataset
#' @param func Character array specifying the binding operation:
#'        - "bindRows": Merge datasets by rows (vertical stacking)
#'        - "bindCols": Merge datasets by columns (horizontal joining)
#'        - "bindRowsbyIndex": Merge datasets by rows using an index
#' @param overwrite Boolean indicating whether to overwrite existing datasets.
#'        Defaults to false
#' 
#' @return Modifies the HDF5 file in place, adding the merged dataset
#' 
#' @details
#' The function performs dimension validation before binding:
#' - For row binding: All datasets must have the same number of columns
#' - For column binding: All datasets must have the same number of rows
#' 
#' Memory efficiency is achieved through:
#' - Block-wise reading and writing
#' - Minimal data copying
#' - Proper resource cleanup
#' 
#' @note When binding by rows with an index, the index determines the
#'       order of combination
#' 
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' a <- matrix(1:12, 4, 3)
#' b <- matrix(13:24, 4, 3)
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", a, "data", "A")
#' bdCreate_hdf5_matrix("test.hdf5", b, "data", "B")
#' 
#' # Bind by rows
#' bdBind_hdf5_datasets("test.hdf5", "data", 
#'                      c("A", "B"),
#'                      "results", "combined",
#'                      "bindRows")
#' }
#' 
#' @export
bdBind_hdf5_datasets <- function(filename, group, datasets, outgroup, outdataset, func, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdBind_hdf5_datasets', PACKAGE = 'BigDataStatMeth', filename, group, datasets, outgroup, outdataset, func, overwrite))
}

#' Crossprod with hdf5 matrix
#' 
#' Performs optimized cross product operations on matrices stored in HDF5 format.
#' For a single matrix A, computes A^t * A. For two matrices A and B, computes
#' A^t * B. Uses block-wise processing for memory efficiency.
#' 
#' @param filename String indicating the HDF5 file path
#' @param group String indicating the input group containing matrix A
#' @param A String specifying the dataset name for matrix A
#' @param B Optional string specifying dataset name for matrix B.
#'        If NULL, performs A^t * A
#' @param groupB Optional string indicating group containing matrix B.
#'        If NULL, uses same group as A
#' @param block_size Optional integer specifying the block size for processing.
#'        Default is automatically determined based on matrix dimensions
#' @param mixblock_size Optional integer for memory block size in parallel processing
#' @param paral Optional boolean indicating whether to use parallel processing.
#'        Default is false
#' @param threads Optional integer specifying number of threads for parallel processing.
#'        If NULL, uses maximum available threads
#' @param outgroup Optional string specifying output group.
#'        Default is "OUTPUT"
#' @param outdataset Optional string specifying output dataset name.
#'        Default is "CrossProd_A_x_B"
#' @param overwrite Optional boolean indicating whether to overwrite existing datasets.
#'        Default is false
#' 
#' @return Modifies the HDF5 file in place, adding the cross product result
#' 
#' @details
#' The function implements block-wise matrix multiplication to handle large matrices
#' efficiently. Block size is automatically optimized based on:
#' - Available memory
#' - Matrix dimensions
#' - Whether parallel processing is enabled
#' 
#' For parallel processing:
#' - Uses OpenMP for thread management
#' - Implements cache-friendly block operations
#' - Provides automatic thread count optimization
#' 
#' Memory efficiency is achieved through:
#' - Block-wise reading and writing
#' - Minimal temporary storage
#' - Proper resource cleanup
#' 
#' @examples
#' \dontrun{
#'   library(BigDataStatMeth)
#'   library(rhdf5)
#'   
#'   # Create test matrix
#'   N = 1000
#'   M = 1000
#'   set.seed(555)
#'   a <- matrix(rnorm(N*M), N, M)
#'   
#'   # Save to HDF5
#'   bdCreate_hdf5_matrix("test.hdf5", a, "INPUT", "A", overwriteFile = TRUE)
#'   
#'   # Compute cross product
#'   bdCrossprod_hdf5("test.hdf5", "INPUT", "A", 
#'                    outgroup = "OUTPUT",
#'                    outdataset = "result",
#'                    block_size = 1024,
#'                    paral = TRUE,
#'                    threads = 4)
#' }
#' 
#' @export
bdCrossprod_hdf5 <- function(filename, group, A, B = NULL, groupB = NULL, block_size = NULL, mixblock_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    .Call('_BigDataStatMeth_bdCrossprod_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, mixblock_size, paral, threads, outgroup, outdataset, overwrite)
}

#' Normalize dataset in HDF5 file
#' 
#' Performs block-wise normalization of datasets stored in HDF5 format through
#' centering and/or scaling operations. Supports both row-wise and column-wise
#' normalization with memory-efficient block processing.
#' 
#' @param filename String indicating the HDF5 file path
#' @param group String specifying the group containing the dataset
#' @param dataset String specifying the dataset name to normalize
#' @param bcenter Optional boolean indicating whether to center the data.
#'        If TRUE (default), subtracts mean from each column/row
#' @param bscale Optional boolean indicating whether to scale the data.
#'        If TRUE (default), divides by standard deviation
#' @param byrows Optional boolean indicating whether to operate by rows.
#'        If TRUE, processes row-wise; if FALSE (default), column-wise
#' @param wsize Optional integer specifying the block size for processing.
#'        Default is 1000
#' @param overwrite Optional boolean indicating whether to overwrite existing datasets.
#'        Default is false
#' 
#' @return Modifies the HDF5 file in place, adding:
#'         - Normalized data under "NORMALIZED/\[group\]/\[dataset\]"
#'         - Mean values under "NORMALIZED/\[group\]/mean.\[dataset\]"
#'         - Standard deviations under "NORMALIZED/\[group\]/sd.\[dataset\]"
#' 
#' @details
#' The function implements block-wise normalization through:
#' 
#' Statistical computations:
#' - Mean calculation (for centering)
#' - Standard deviation calculation (for scaling)
#' - Efficient block-wise updates
#' 
#' Memory efficiency:
#' - Block-wise data processing
#' - Minimal temporary storage
#' - Proper resource cleanup
#' 
#' Processing options:
#' - Row-wise or column-wise operations
#' - Flexible block size selection
#' - Optional centering and scaling
#' 
#' Error handling:
#' - Input validation
#' - Resource management
#' - Exception handling
#' 
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test data
#' data <- matrix(rnorm(1000*100), 1000, 100)
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", data, "data", "matrix",
#'                      overwriteFile = TRUE)
#' 
#' # Normalize data
#' bdNormalize_hdf5("test.hdf5", "data", "matrix",
#'                  bcenter = TRUE,
#'                  bscale = TRUE,
#'                  wsize = 1000)
#' }
#' 
#' @export
bdNormalize_hdf5 <- function(filename, group, dataset, bcenter = NULL, bscale = NULL, byrows = NULL, wsize = NULL, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdNormalize_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, bcenter, bscale, byrows, wsize, overwrite))
}

#' HDF5 dataset addition
#'
#' Performs optimized block-wise addition between two datasets stored in HDF5
#' format. Supports both matrix-matrix and matrix-vector operations with
#' memory-efficient block processing.
#' 
#' @param filename String indicating the HDF5 file path
#' @param group String indicating the group containing matrix A
#' @param A String specifying the dataset name for matrix A
#' @param B String specifying the dataset name for matrix B
#' @param groupB Optional string indicating group containing matrix B.
#'        If NULL, uses same group as A
#' @param block_size Optional integer specifying block size for processing.
#'        If NULL, automatically determined based on matrix dimensions
#' @param paral Optional boolean indicating whether to use parallel processing.
#'        Default is false
#' @param threads Optional integer specifying number of threads for parallel processing.
#'        If NULL, uses maximum available threads
#' @param outgroup Optional string specifying output group.
#'        Default is "OUTPUT"
#' @param outdataset Optional string specifying output dataset name.
#'        Default is "A_+_B"
#' @param overwrite Optional boolean indicating whether to overwrite existing datasets.
#'        Default is false
#' 
#' @return Modifies the HDF5 file in place, adding the addition result
#' 
#' @details
#' The function implements optimized addition through:
#' 
#' Operation modes:
#' - Matrix-matrix addition (A + B)
#' - Matrix-vector addition
#' - Vector-matrix addition
#' 
#' Block processing:
#' - Automatic block size selection
#' - Memory-efficient operations
#' - Parallel computation support
#' 
#' Block size optimization based on:
#' - Matrix dimensions
#' - Available memory
#' - Operation type (matrix/vector)
#' 
#' Error handling:
#' - Dimension validation
#' - Resource management
#' - Exception handling
#' 
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' N <- 1500
#' M <- 1500
#' set.seed(555)
#' a <- matrix(rnorm(N*M), N, M)
#' b <- matrix(rnorm(N*M), N, M)
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", a, "data", "A",
#'                      overwriteFile = TRUE)
#' bdCreate_hdf5_matrix("test.hdf5", b, "data", "B",
#'                      overwriteFile = FALSE)
#' 
#' # Perform addition
#' bdblockSum_hdf5("test.hdf5", "data", "A", "B",
#'                 outgroup = "results",
#'                 outdataset = "sum",
#'                 block_size = 1024,
#'                 paral = TRUE)
#' }
#' 
#' @export
bdblockSum_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    .Call('_BigDataStatMeth_bdblockSum_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, paral, threads, outgroup, outdataset, overwrite)
}

#' Hdf5 datasets multiplication
#'
#' The bdblockmult_hdf5 function performs block-wise matrix multiplication 
#' between two matrices stored in an HDF5 file. This approach is also efficient 
#' for large matrices that cannot be fully loaded into memory.
#' 
#' @param filename string specifying the path to the HDF5 file
#' @param group string specifying the group within the HDF5 file containing 
#' matrix A.
#' @param A string specifying the dataset name for matrix A.
#' the data matrix to be used in calculus
#' @param B string specifying the dataset name for matrix B.
#' @param groupB string, (optional), An optional string specifying the group 
#' for matrix B. Defaults to the value of `group` if not provided.
#' @param block_size integer (optional), an optional parameter specifying the 
#' block size for processing the matrices. If not provided, a default block 
#' size is used. The block size should be chosen based on the available memory 
#' and the size of the matrices
#' @param paral boolean (optional), an optional parameter to enable parallel 
#' computation. Defaults to FALSE. Set `paral = true` to force parallel execution
#' @param threads integer (optional), an optional parameter specifying the 
#' number of threads to use if paral = TRUE. Ignored if paral = FALSE.
#' @param outgroup string (optional), An optional parameger specifying the group 
#' where the output matrix will be stored. If NULL, the output will be stored 
#' in the default group "OUTPUT".
#' @param outdataset string (optional), An optional parameter specifying the 
#' dataset name for the output matrix. If NULL, the default name will be 
#' constructed as the name of dataset A concatenated with _x_ and the 
#' name of dataset B.
#' @param overwrite logical (optional), An optional parameter to indicate whether 
#' existing results in the HDF5 file should be overwritten. Defaults to FALSE. 
#' If FALSE and the dataset already exists, an error will be displayed, and 
#' no calculations will be performed. If TRUE and a dataset with the same 
#' name as specified in outdataset already exists, it will be overwritten.
#' @details
#' * The function `bdblockmult_hdf5()` is efficient for both matrices that cannot 
#' fit into memory (by processing in blocks) and matrices that can be fully 
#' loaded into memory, as it optimizes computations based on available resources.
#' * Ensure that the dimensions of `A` and `B` matrices are compatible for 
#' matrix multiplication.
#' * The `block size` should be chosen based on the available memory and 
#' the size of the matrices.
#' * If `bparal = true`, number of concurrent threads in parallelization. If 
#' `paral = TRUE` and `threads = NULL` then `threads` is set to a half of a 
#' maximum number of available threads 
#' @return a dataset inside the hdf5 data file with A*B 
#' @examples
#' library("BigDataStatMeth")
#' library("rhdf5")
#' 
#' N = 1500; M = 1500
#' 
#' set.seed(555)
#' a <- matrix( rnorm( N*M, mean=0, sd=1), N, M) 
#' b <- matrix( rnorm( N*M, mean=0, sd=1), M, N) 
#' 
#' fn <- "test_temp.hdf5"
#' bdCreate_hdf5_matrix(filename = fn, 
#'                      object = a, group = "groupA", 
#'                      dataset = "datasetA",
#'                      transp = FALSE,
#'                      overwriteFile = TRUE, 
#'                      overwriteDataset = FALSE, 
#'                      unlimited = FALSE)
#'                      
#' bdCreate_hdf5_matrix(filename = fn, 
#'                      object = t(b), 
#'                      group = "groupA", 
#'                      dataset = "datasetB",
#'                      transp = FALSE,
#'                      overwriteFile = FALSE, 
#'                      overwriteDataset = TRUE, 
#'                      unlimited = FALSE)
#'                      
#' # Multiply two matrix
#' res <- bdblockmult_hdf5(filename = fn, group = "groupA", 
#'     A = "datasetA", B = "datasetB", outgroup = "results", 
#'     outdataset = "res", overwrite = TRUE ) 
#'     
#' res <- bdblockmult_hdf5(filename = fn, group = "groupA", 
#'     A = "datasetA", B = "datasetB", outgroup = "results", 
#'     outdataset = "res", block_size = 1024, overwrite = TRUE ) 
#' 
#' # list contents
#' h5ls(fn)
#' 
#' # Extract the result from HDF5
#' result_hdf5 <- h5read(res$fn, res$ds)[1:3, 1:5]
#' result_hdf5
#' 
#' # Compute the same multiplication in R
#' result_r <- (a %*% b)[1:3, 1:5]
#' result_r
#' 
#' # Compare both results (should be TRUE)
#' all.equal(result_hdf5, result_r)
#' 
#' # Remove file
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' 
#' @export
bdblockmult_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    .Call('_BigDataStatMeth_bdblockmult_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, paral, threads, outgroup, outdataset, overwrite)
}

#' Block matrix multiplication for sparse matrices
#' 
#' Performs optimized block-wise matrix multiplication for sparse matrices stored
#' in HDF5 format. The implementation is specifically designed to handle large
#' sparse matrices efficiently through block operations and parallel processing.
#' 
#' @param filename String indicating the HDF5 file path
#' @param group String indicating the group path for matrix A
#' @param A String specifying the dataset name for matrix A
#' @param B String specifying the dataset name for matrix B
#' @param groupB Optional string indicating group path for matrix B.
#'        If NULL, uses same group as A
#' @param block_size Optional integer specifying block size for processing.
#'        If NULL, automatically determined based on matrix dimensions
#' @param mixblock_size Optional integer for memory block size in parallel processing
#' @param paral Optional boolean indicating whether to use parallel processing.
#'        Default is false
#' @param threads Optional integer specifying number of threads for parallel processing.
#'        If NULL, uses maximum available threads
#' @param outgroup Optional string specifying output group.
#'        Default is "OUTPUT"
#' @param outdataset Optional string specifying output dataset name.
#'        Default is "A_x_B"
#' @param overwrite Optional boolean indicating whether to overwrite existing datasets.
#'        Default is false
#' 
#' @return Modifies the HDF5 file in place, adding the multiplication result
#' 
#' @details
#' The function implements optimized sparse matrix multiplication through:
#' - Block-wise processing to manage memory usage
#' - Automatic block size optimization
#' - Parallel processing support
#' - Efficient sparse matrix storage
#' 
#' Block size optimization considers:
#' - Available system memory
#' - Matrix dimensions and sparsity
#' - Parallel processing requirements
#' 
#' Memory efficiency is achieved through:
#' - Sparse matrix storage format
#' - Block-wise processing
#' - Minimal temporary storage
#' - Proper resource cleanup
#' 
#' @examples
#' \dontrun{
#' library(Matrix)
#' library(BigDataStatMeth)
#' 
#' # Create sparse test matrices
#' k <- 1e3
#' set.seed(1)
#' x_sparse <- sparseMatrix(
#'     i = sample(x = k, size = k),
#'     j = sample(x = k, size = k),
#'     x = rnorm(n = k)
#' )
#' 
#' set.seed(2)
#' y_sparse <- sparseMatrix(
#'     i = sample(x = k, size = k),
#'     j = sample(x = k, size = k),
#'     x = rnorm(n = k)
#' )
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", as.matrix(x_sparse), "SPARSE", "x_sparse")
#' bdCreate_hdf5_matrix("test.hdf5", as.matrix(y_sparse), "SPARSE", "y_sparse")
#' 
#' # Perform multiplication
#' bdblockmult_sparse_hdf5("test.hdf5", "SPARSE", "x_sparse", "y_sparse",
#'                         block_size = 1024,
#'                         paral = TRUE,
#'                         threads = 4)
#' }
#' 
#' @export
bdblockmult_sparse_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, mixblock_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdblockmult_sparse_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, mixblock_size, paral, threads, outgroup, outdataset, overwrite))
}

#' HDF5 dataset subtraction
#'
#' Performs optimized block-wise subtraction between two datasets stored in HDF5
#' format. Supports both matrix-matrix and matrix-vector operations with
#' memory-efficient block processing.
#' 
#' @param filename String indicating the HDF5 file path
#' @param group String indicating the group containing matrix A
#' @param A String specifying the dataset name for matrix A
#' @param B String specifying the dataset name for matrix B
#' @param groupB Optional string indicating group containing matrix B.
#'        If NULL, uses same group as A
#' @param block_size Optional integer specifying block size for processing.
#'        If NULL, automatically determined based on matrix dimensions
#' @param paral Optional boolean indicating whether to use parallel processing.
#'        Default is false
#' @param threads Optional integer specifying number of threads for parallel processing.
#'        If NULL, uses maximum available threads
#' @param outgroup Optional string specifying output group.
#'        Default is "OUTPUT"
#' @param outdataset Optional string specifying output dataset name.
#'        Default is "A_-_B"
#' @param overwrite Optional boolean indicating whether to overwrite existing datasets.
#'        Default is false
#' 
#' @return Modifies the HDF5 file in place, adding the subtraction result
#' 
#' @details
#' The function implements optimized subtraction through:
#' 
#' Operation modes:
#' - Matrix-matrix subtraction (A - B)
#' - Matrix-vector subtraction
#' - Vector-matrix subtraction
#' 
#' Block processing:
#' - Automatic block size selection
#' - Memory-efficient operations
#' - Parallel computation support
#' 
#' Block size optimization based on:
#' - Matrix dimensions
#' - Available memory
#' - Operation type (matrix/vector)
#' 
#' Error handling:
#' - Dimension validation
#' - Resource management
#' - Exception handling
#' 
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' N <- 1500
#' M <- 1500
#' set.seed(555)
#' a <- matrix(rnorm(N*M), N, M)
#' b <- matrix(rnorm(N*M), N, M)
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", a, "data", "A",
#'                      overwriteFile = TRUE)
#' bdCreate_hdf5_matrix("test.hdf5", b, "data", "B",
#'                      overwriteFile = FALSE)
#' 
#' # Perform subtraction
#' bdblockSubstract_hdf5("test.hdf5", "data", "A", "B",
#'                       outgroup = "results",
#'                       outdataset = "diff",
#'                       block_size = 1024,
#'                       paral = TRUE)
#' }
#' 
#' @export
bdblockSubstract_hdf5 <- function(filename, group, A, B, groupB = NULL, block_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    .Call('_BigDataStatMeth_bdblockSubstract_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, paral, threads, outgroup, outdataset, overwrite)
}

#' Transposed cross product with HDF5 matrices
#' 
#' Performs optimized transposed cross product operations on matrices stored in
#' HDF5 format. For a single matrix A, computes A * A^t. For two matrices A and B,
#' computes A * B^t. Uses block-wise processing for memory efficiency.
#' 
#' @param filename String indicating the HDF5 file path
#' @param group String indicating the input group containing matrix A
#' @param A String specifying the dataset name for matrix A
#' @param B Optional string specifying dataset name for matrix B.
#'        If NULL, performs A * A^t
#' @param groupB Optional string indicating group containing matrix B.
#'        If NULL, uses same group as A
#' @param block_size Optional integer specifying the block size for processing.
#'        Default is automatically determined based on matrix dimensions
#' @param mixblock_size Optional integer for memory block size in parallel processing
#' @param paral Optional boolean indicating whether to use parallel processing.
#'        Default is false
#' @param threads Optional integer specifying number of threads for parallel processing.
#'        If NULL, uses maximum available threads
#' @param outgroup Optional string specifying output group.
#'        Default is "OUTPUT"
#' @param outdataset Optional string specifying output dataset name.
#'        Default is "tCrossProd_A_x_B"
#' @param overwrite Optional boolean indicating whether to overwrite existing datasets.
#'        Default is false
#' 
#' @return Modifies the HDF5 file in place, adding the transposed cross product result
#' 
#' @details
#' The function implements block-wise matrix multiplication to handle large matrices
#' efficiently. Block size is automatically optimized based on:
#' - Available memory
#' - Matrix dimensions
#' - Whether parallel processing is enabled
#' 
#' For parallel processing:
#' - Uses OpenMP for thread management
#' - Implements cache-friendly block operations
#' - Provides automatic thread count optimization
#' 
#' Memory efficiency is achieved through:
#' - Block-wise reading and writing
#' - Minimal temporary storage
#' - Proper resource cleanup
#' 
#' Mathematical operations:
#' - For single matrix A: computes A * A^t
#' - For two matrices A, B: computes A * B^t
#' - Optimized for numerical stability
#' 
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' library(rhdf5)
#' 
#' # Create test matrix
#' N <- 1000
#' M <- 1000
#' set.seed(555)
#' a <- matrix(rnorm(N*M), N, M)
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", a, "INPUT", "A",
#'                      overwriteFile = TRUE)
#' 
#' # Compute transposed cross product
#' bdtCrossprod_hdf5("test.hdf5", "INPUT", "A",
#'                   outgroup = "OUTPUT",
#'                   outdataset = "result",
#'                   block_size = 1024,
#'                   paral = TRUE,
#'                   threads = 4)
#' }
#' 
#' @export
bdtCrossprod_hdf5 <- function(filename, group, A, B = NULL, groupB = NULL, block_size = NULL, mixblock_size = NULL, paral = NULL, threads = NULL, outgroup = NULL, outdataset = NULL, overwrite = NULL) {
    .Call('_BigDataStatMeth_bdtCrossprod_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, A, B, groupB, block_size, mixblock_size, paral, threads, outgroup, outdataset, overwrite)
}

#' Get HDF5 Dataset Dimensions
#'
#' @description
#' Retrieves the dimensions (number of rows and columns) of a dataset stored in
#' an HDF5 file.
#'
#' @details
#' This function provides efficient access to dataset dimensions in HDF5 files.
#' Key features:
#' 
#' * Dimension information:
#'   - Number of rows
#'   - Number of columns
#' 
#' * Implementation features:
#'   - Safe HDF5 file operations
#'   - Memory-efficient implementation
#'   - Comprehensive error handling
#'   - Read-only access to files
#'
#' The function opens the HDF5 file in read-only mode to ensure data safety.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param dataset Character string. Full path to the dataset within the HDF5 file
#'   (e.g., "group/subgroup/dataset").
#'
#' @return Integer vector of length 2 containing:
#'   - \[1\] Number of rows
#'   - \[2\] Number of columns
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create a test HDF5 file
#' fn <- "test.hdf5"
#' X <- matrix(rnorm(100), 10, 10)
#' 
#' # Save matrix to HDF5
#' bdCreate_hdf5_matrix(fn, X, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' 
#' # Get dimensions
#' dims <- bdgetDim_hdf5(fn, "data/matrix1")
#' print(paste("Rows:", dims[1]))
#' print(paste("Columns:", dims[2]))
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdgetDatasetsList_hdf5}} for listing available datasets
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdgetDim_hdf5 <- function(filename, dataset) {
    .Call('_BigDataStatMeth_bdgetDim_hdf5', PACKAGE = 'BigDataStatMeth', filename, dataset)
}

#' List Datasets in HDF5 Group
#'
#' @description
#' Retrieves a list of all datasets within a specified HDF5 group, with optional
#' filtering by prefix or suffix.
#'
#' @details
#' This function provides flexible dataset listing capabilities for HDF5 files.
#' Key features:
#' 
#' * Listing options:
#'   - All datasets in a group
#'   - Datasets matching a prefix
#'   - Datasets matching a suffix
#' 
#' * Implementation features:
#'   - Safe HDF5 file operations
#'   - Memory-efficient implementation
#'   - Comprehensive error handling
#'   - Read-only access to files
#'
#' The function opens the HDF5 file in read-only mode to ensure data safety.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group within the HDF5 file.
#' @param prefix Optional character string. If provided, only returns datasets
#'   starting with this prefix.
#'
#' @return Character vector containing dataset names.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create a test HDF5 file
#' fn <- "test.hdf5"
#' X <- matrix(rnorm(100), 10, 10)
#' Y <- matrix(rnorm(100), 10, 10)
#' 
#' # Save matrices to HDF5
#' bdCreate_hdf5_matrix(fn, X, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' bdCreate_hdf5_matrix(fn, Y, "data", "matrix2",
#'                      overwriteFile = FALSE)
#' 
#' # List all datasets in group
#' datasets <- bdgetDatasetsList_hdf5(fn, "data")
#' print(datasets)
#' 
#' # List datasets with prefix "matrix"
#' filtered <- bdgetDatasetsList_hdf5(fn, "data", prefix = "matrix")
#' print(filtered)
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdgetDatasetsList_hdf5 <- function(filename, group, prefix = NULL) {
    .Call('_BigDataStatMeth_bdgetDatasetsList_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, prefix)
}

#' Import Text File to HDF5
#'
#' @description
#' Converts a text file (e.g., CSV, TSV) to HDF5 format, providing efficient
#' storage and access capabilities.
#'
#' @details
#' This function provides flexible text file import capabilities with support for:
#' 
#' * Input format options:
#'   - Custom field separators
#'   - Header row handling
#'   - Row names handling
#' 
#' * Processing options:
#'   - Parallel processing
#'   - Memory-efficient import
#'   - Configurable thread count
#' 
#' * File handling:
#'   - Safe file operations
#'   - Overwrite protection
#'   - Comprehensive error handling
#'
#' The function supports parallel processing for large files and provides
#' memory-efficient import capabilities.
#'
#' @param filename Character string. Path to the input text file.
#' @param outputfile Character string. Path to the output HDF5 file.
#' @param outGroup Character string. Name of the group to create in HDF5 file.
#' @param outDataset Character string. Name of the dataset to create.
#' @param sep Character string (optional). Field separator, default is "\\t".
#' @param header Logical (optional). Whether first row contains column names.
#' @param rownames Logical (optional). Whether first column contains row names.
#' @param overwrite Logical (optional). Whether to overwrite existing dataset.
#' @param paral Logical (optional). Whether to use parallel processing.
#' @param threads Integer (optional). Number of threads for parallel processing.
#' @param overwriteFile Logical (optional). Whether to overwrite existing HDF5 file.
#'
#' @return No return value, called for side effects (file creation).
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create a test CSV file
#' data <- matrix(rnorm(100), 10, 10)
#' write.csv(data, "test.csv", row.names = FALSE)
#' 
#' # Import to HDF5
#' bdImportTextFile_hdf5(
#'   filename = "test.csv",
#'   outputfile = "output.hdf5",
#'   outGroup = "data",
#'   outDataset = "matrix1",
#'   sep = ",",
#'   header = TRUE,
#'   overwriteFile = TRUE
#' )
#' 
#' # Cleanup
#' unlink(c("test.csv", "output.hdf5"))
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices directly
#'
#' @export
bdImportTextFile_hdf5 <- function(filename, outputfile, outGroup, outDataset, sep = NULL, header = FALSE, rownames = FALSE, overwrite = FALSE, paral = NULL, threads = NULL, overwriteFile = NULL) {
    .Call('_BigDataStatMeth_bdImportTextFile_hdf5', PACKAGE = 'BigDataStatMeth', filename, outputfile, outGroup, outDataset, sep, header, rownames, overwrite, paral, threads, overwriteFile)
}

#' Impute Missing SNP Values in HDF5 Dataset
#'
#' @description
#' Performs imputation of missing values in SNP (Single Nucleotide Polymorphism)
#' data stored in HDF5 format.
#'
#' @details
#' This function provides efficient imputation capabilities for genomic data with
#' support for:
#' 
#' * Imputation options:
#'   - Row-wise or column-wise imputation
#'   - Parallel processing
#'   - Configurable thread count
#' 
#' * Output options:
#'   - Custom output location
#'   - In-place modification
#'   - Overwrite protection
#' 
#' * Implementation features:
#'   - Memory-efficient processing
#'   - Safe file operations
#'   - Error handling
#'
#' The function supports both in-place modification and creation of new datasets.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing input dataset.
#' @param dataset Character string. Name of the dataset to impute.
#' @param outgroup Character string (optional). Output group path. If NULL,
#'   uses input group.
#' @param outdataset Character string (optional). Output dataset name. If NULL,
#'   overwrites input dataset.
#' @param bycols Logical (optional). Whether to impute by columns (TRUE) or
#'   rows (FALSE). Default is TRUE.
#' @param paral Logical (optional). Whether to use parallel processing.
#' @param threads Integer (optional). Number of threads for parallel processing.
#' @param overwrite Logical (optional). Whether to overwrite existing dataset.
#'
#' @return No return value, called for side effects (data imputation).
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test data with missing values
#' data <- matrix(sample(c(0, 1, 2, NA), 100, replace = TRUE), 10, 10)
#' 
#' # Save to HDF5
#' fn <- "snp_data.hdf5"
#' bdCreate_hdf5_matrix(fn, data, "genotype", "snps",
#'                      overwriteFile = TRUE)
#' 
#' # Impute missing values
#' bdImputeSNPs_hdf5(
#'   filename = fn,
#'   group = "genotype",
#'   dataset = "snps",
#'   outgroup = "genotype_imputed",
#'   outdataset = "snps_complete",
#'   bycols = TRUE,
#'   paral = TRUE
#' )
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#' * Li, Y., et al. (2009). Genotype Imputation. Annual Review of Genomics
#'   and Human Genetics, 10, 387-406.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdImputeSNPs_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, bycols = TRUE, paral = NULL, threads = NULL, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdImputeSNPs_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, bycols, paral, threads, overwrite))
}

#' Matrix Inversion using Cholesky Decomposition for HDF5-Stored Matrices
#'
#' @description
#' Computes the inverse of a symmetric positive-definite matrix stored in an HDF5 file
#' using the Cholesky decomposition method. This approach is more efficient and
#' numerically stable than general matrix inversion methods for symmetric
#' positive-definite matrices.
#' 
#' @details
#' This function implements an efficient matrix inversion algorithm that leverages
#' the special properties of symmetric positive-definite matrices. Key features:
#' * Uses Cholesky decomposition for improved numerical stability
#' * Block-based computation for large matrices
#' * Optional storage formats (full or triangular)
#' * Parallel processing support
#' * Memory-efficient block algorithm
#'
#' The algorithm proceeds in two main steps:
#' 1. Compute the Cholesky decomposition A = LL'
#' 2. Solve the system LL'X = I for X = A^(-1)
#'
#' Advantages of this method:
#' * More efficient than general matrix inversion
#' * Better numerical stability
#' * Preserves matrix symmetry
#' * Exploits positive-definiteness for efficiency
#'
#' @param filename Character string. Path to the HDF5 file containing the input matrix.
#' @param group Character string. Path to the group containing the input dataset.
#' @param dataset Character string. Name of the input dataset to invert.
#' @param outdataset Character string. Name for the output dataset.
#' @param outgroup Character string. Optional output group path. If not provided,
#'   results are stored in the input group.
#' @param fullMatrix Logical. If TRUE, stores the complete inverse matrix.
#'   If FALSE (default), stores only the lower triangular part to save space.
#' @param overwrite Logical. If TRUE, allows overwriting existing results.
#' @param threads Integer. Number of threads for parallel computation (default = 2).
#' @param elementsBlock Integer. Maximum number of elements to process in each block
#'   (default = 1,000,000). For matrices larger than 5000x5000, automatically adjusted
#'   to number of rows or columns * 2.
#'
#' @return No direct return value. Results are written to the HDF5 file in the
#' specified location with the following structure:
#' \describe{
#'   \item{inverse}{The inverse matrix A^(-1)}
#' }
#'
#' @examples
#' \dontrun{
#' library(rhdf5)
#' 
#' # Create a symmetric positive-definite matrix
#' set.seed(1234)
#' X <- matrix(rnorm(100), 10, 10)
#' A <- crossprod(X)  # A = X'X is symmetric positive-definite
#' 
#' # Save to HDF5
#' h5createFile("matrix.h5")
#' h5write(A, "matrix.h5", "data/matrix")
#' 
#' # Compute inverse using Cholesky decomposition
#' bdInvCholesky_hdf5("matrix.h5", "data", "matrix",
#'                    outdataset = "inverse",
#'                    outgroup = "results",
#'                    fullMatrix = TRUE,
#'                    threads = 4)
#' 
#' # Verify the inverse
#' Ainv <- h5read("matrix.h5", "results/inverse")
#' max(abs(A %*% Ainv - diag(nrow(A))))  # Should be very small
#' }
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Higham, N. J. (2002). Accuracy and Stability of Numerical Algorithms,
#'   2nd Edition. SIAM.
#'
#' @seealso
#' * \code{\link{bdCholesky_hdf5}} for the underlying Cholesky decomposition
#' * \code{\link{bdSolve_hdf5}} for solving linear systems
#'
#' @export
bdInvCholesky_hdf5 <- function(filename, group, dataset, outdataset, outgroup = NULL, fullMatrix = NULL, overwrite = NULL, threads = 2L, elementsBlock = 1000000L) {
    .Call('_BigDataStatMeth_bdInvCholesky_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outdataset, outgroup, fullMatrix, overwrite, threads, elementsBlock)
}

#' Get Matrix Diagonal from HDF5
#'
#' @description
#' Retrieves the diagonal elements from a matrix stored in an HDF5 file.
#'
#' @details
#' This function provides efficient access to matrix diagonal elements with:
#' 
#' * Access features:
#'   - Direct diagonal access
#'   - Memory-efficient retrieval
#'   - Support for large matrices
#' 
#' * Implementation features:
#'   - Safe HDF5 file operations
#'   - Memory-efficient implementation
#'   - Comprehensive error handling
#'   - Read-only access to files
#'
#' The function opens the HDF5 file in read-only mode to ensure data safety.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing the dataset.
#' @param dataset Character string. Name of the dataset.
#'
#' @return Numeric vector containing diagonal elements.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrix
#' X <- matrix(rnorm(100), 10, 10)
#' diag(X) <- 0.5
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", X, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' 
#' # Get diagonal
#' diag_elements <- bdgetDiagonal_hdf5("test.hdf5", "data", "matrix1")
#' print(diag_elements)
#' 
#' # Cleanup
#' if (file.exists("test.hdf5")) {
#'   file.remove("test.hdf5")
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdWriteDiagonal_hdf5}} for writing diagonal elements
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdgetDiagonal_hdf5 <- function(filename, group, dataset) {
    .Call('_BigDataStatMeth_bdgetDiagonal_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset)
}

#' Write Matrix Diagonal to HDF5
#'
#' @description
#' Updates the diagonal elements of a matrix stored in an HDF5 file.
#'
#' @details
#' This function provides efficient diagonal modification capabilities with:
#' 
#' * Write features:
#'   - Direct diagonal access
#'   - Type checking and validation
#'   - Support for large matrices
#' 
#' * Implementation features:
#'   - Safe HDF5 file operations
#'   - Memory-efficient implementation
#'   - Comprehensive error handling
#'   - Type conversion support
#'
#' The function validates input types and dimensions before modification.
#'
#' @param diagonal Numeric vector. New diagonal elements to write.
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing the dataset.
#' @param dataset Character string. Name of the dataset to modify.
#'
#' @return No return value, called for side effects (diagonal modification).
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrix
#' X <- matrix(rnorm(100), 10, 10)
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", X, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' 
#' # Create new diagonal
#' new_diag <- seq(1, 10)
#' 
#' # Update diagonal
#' bdWriteDiagonal_hdf5(new_diag, "test.hdf5", "data", "matrix1")
#' 
#' # Verify
#' diag_elements <- bdgetDiagonal_hdf5("test.hdf5", "data", "matrix1")
#' print(diag_elements)
#' 
#' # Cleanup
#' if (file.exists("test.hdf5")) {
#'   file.remove("test.hdf5")
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdgetDiagonal_hdf5}} for reading diagonal elements
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdWriteDiagonal_hdf5 <- function(diagonal, filename, group, dataset) {
    invisible(.Call('_BigDataStatMeth_bdWriteDiagonal_hdf5', PACKAGE = 'BigDataStatMeth', diagonal, filename, group, dataset))
}

#' Compute Matrix Standard Deviation and Mean in HDF5
#'
#' @description
#' Computes standard deviation and/or mean statistics for a matrix stored in
#' HDF5 format, with support for row-wise or column-wise computations.
#'
#' @details
#' This function provides efficient statistical computation capabilities with:
#' 
#' * Computation options:
#'   - Standard deviation computation
#'   - Mean computation
#'   - Row-wise or column-wise processing
#' 
#' * Processing features:
#'   - Block-based computation
#'   - Memory-efficient processing
#'   - Configurable block size
#' 
#' * Implementation features:
#'   - Safe HDF5 file operations
#'   - Memory-efficient implementation
#'   - Comprehensive error handling
#'
#' Results are stored in a new group 'mean_sd' within the HDF5 file.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing the dataset.
#' @param dataset Character string. Name of the dataset to analyze.
#' @param sd Logical (optional). Whether to compute standard deviation.
#'   Default is TRUE.
#' @param mean Logical (optional). Whether to compute mean. Default is TRUE.
#' @param byrows Logical (optional). Whether to compute by rows (TRUE) or
#'   columns (FALSE). Default is FALSE.
#' @param wsize Integer (optional). Block size for processing. Default is 1000.
#' @param overwrite Logical (optional). Whether to overwrite existing results.
#'   Default is FALSE.
#'
#' @return No return value, called for side effects (statistics computation).
#'   Results are stored in the HDF5 file under the 'mean_sd' group with names:
#'   * 'sd.`dataset`' for standard deviation
#'   * 'mean.`dataset`' for mean
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' set.seed(123)
#' Y <- matrix(rnorm(100), 10, 10)
#' X <- matrix(rnorm(10), 10, 1)
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", Y, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' bdCreate_hdf5_matrix("test.hdf5", X, "data", "vector1",
#'                      overwriteFile = FALSE)
#' 
#' # Compute statistics
#' bdgetSDandMean_hdf5(
#'   filename = "test.hdf5",
#'   group = "data",
#'   dataset = "matrix1",
#'   sd = TRUE,
#'   mean = TRUE,
#'   byrows = TRUE,
#'   wsize = 500
#' )
#' 
#' # Cleanup
#' if (file.exists("test.hdf5")) {
#'   file.remove("test.hdf5")
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#' * Welford, B. P. (1962). Note on a method for calculating corrected
#'   sums of squares and products. Technometrics, 4(3), 419-420.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdgetSDandMean_hdf5 <- function(filename, group, dataset, sd = NULL, mean = NULL, byrows = NULL, wsize = NULL, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdgetSDandMean_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, sd, mean, byrows, wsize, overwrite))
}

#' Compute Matrix Pseudoinverse (In-Memory)
#'
#' @description
#' Computes the Moore-Penrose pseudoinverse of a matrix using SVD decomposition.
#' This implementation handles both square and rectangular matrices, and provides
#' numerically stable results even for singular or near-singular matrices.
#'
#' @details
#' The Moore-Penrose pseudoinverse A of a matrix A is computed using Singular
#' Value Decomposition (SVD). For a matrix A = UV*, the pseudoinverse is
#' A = VU* where  is obtained by reciprocating non-zero singular values.
#' 
#' Key features:
#' * Robust computation:
#'   - Handles singular and near-singular matrices
#'   - Automatic threshold for small singular values
#'   - Numerically stable implementation
#' 
#' * Implementation details:
#'   - Uses efficient SVD algorithms
#'   - Parallel processing support
#'   - Memory-efficient computation
#'   - Handles both dense and sparse inputs
#'
#' The pseudoinverse satisfies the Moore-Penrose conditions:
#' * AAA = A
#' * AAA = A
#' * (AA)* = AA
#' * (AA)* = AA
#'
#' @param X Numeric matrix or vector to be pseudoinverted.
#' @param threads Optional integer. Number of threads for parallel computation.
#'   If NULL, uses maximum available threads.
#'
#' @return The pseudoinverse matrix of X.
#'
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Create a singular matrix
#' X <- matrix(c(1,2,3,2,4,6), 2, 3)  # rank-deficient matrix
#' 
#' # Compute pseudoinverse
#' X_pinv <- bdpseudoinv(X)
#' 
#' # Verify Moore-Penrose conditions
#' # 1. X %*% X_pinv %*% X = X
#' all.equal(X %*% X_pinv %*% X, X)
#' 
#' # 2. X_pinv %*% X %*% X_pinv = X_pinv
#' all.equal(X_pinv %*% X %*% X_pinv, X_pinv)
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Ben-Israel, A., & Greville, T. N. E. (2003). Generalized Inverses:
#'   Theory and Applications, 2nd Edition. Springer.
#'
#' @seealso
#' * \code{\link{bdpseudoinv_hdf5}} for HDF5-stored matrices
#' * \code{\link{bdSVD_hdf5}} for singular value decomposition
#'
#' @export
bdpseudoinv <- function(X, threads = NULL) {
    .Call('_BigDataStatMeth_bdpseudoinv', PACKAGE = 'BigDataStatMeth', X, threads)
}

#' Compute Matrix Pseudoinverse (HDF5-Stored)
#'
#' @description
#' Computes the Moore-Penrose pseudoinverse of a matrix stored in HDF5 format.
#' The implementation is designed for large matrices, using block-based processing
#' and efficient I/O operations.
#'
#' @details
#' This function provides an HDF5-based implementation for computing pseudoinverses
#' of large matrices. Key features:
#' 
#' * HDF5 Integration:
#'   - Efficient reading of input matrix
#'   - Block-based processing for large matrices
#'   - Memory-efficient computation
#'   - Direct output to HDF5 format
#' 
#' * Implementation Features:
#'   - SVD-based computation
#'   - Parallel processing support
#'   - Automatic memory management
#'   - Flexible output options
#'
#' The function handles:
#' * Data validation
#' * Memory management
#' * Error handling
#' * HDF5 file operations
#'
#' @param filename String. Path to the HDF5 file.
#' @param group String. Group containing the input matrix.
#' @param dataset String. Dataset name for the input matrix.
#' @param outgroup Optional string. Output group name (defaults to "PseudoInverse").
#' @param outdataset Optional string. Output dataset name (defaults to input dataset name).
#' @param overwrite Logical. Whether to overwrite existing results.
#' @param threads Optional integer. Number of threads for parallel computation.
#'
#' @return No direct return value. Results are written to the HDF5 file.
#'
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Create a singular matrix
#' X <- matrix(c(1,2,3,2,4,6), 2, 3)
#' fn <- "test.hdf5"
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix(filename = fn,
#'                      object = X,
#'                      group = "data",
#'                      dataset = "X",
#'                      overwriteFile = TRUE)
#' 
#' # Compute pseudoinverse
#' bdpseudoinv_hdf5(filename = fn,
#'                  group = "data",
#'                  dataset = "X",
#'                  outgroup = "results",
#'                  outdataset = "X_pinv",
#'                  overwrite = TRUE)
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdpseudoinv}} for in-memory computation
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdpseudoinv_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, overwrite = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdpseudoinv_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, overwrite, threads)
}

#' Reduce Multiple HDF5 Datasets
#'
#' @description
#' Reduces multiple datasets within an HDF5 group using arithmetic operations
#' (addition or subtraction).
#'
#' @details
#' This function provides efficient dataset reduction capabilities with:
#' 
#' * Operation options:
#'   - Addition of datasets
#'   - Subtraction of datasets
#' 
#' * Output options:
#'   - Custom output location
#'   - Configurable dataset name
#'   - Overwrite protection
#' 
#' * Implementation features:
#'   - Memory-efficient processing
#'   - Safe file operations
#'   - Optional source cleanup
#'   - Comprehensive error handling
#'
#' The function processes datasets efficiently while maintaining data integrity.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing datasets.
#' @param reducefunction Character. Operation to apply, either "+" or "-".
#' @param outgroup Character string (optional). Output group path. If NULL,
#'   uses input group.
#' @param outdataset Character string (optional). Output dataset name. If NULL,
#'   uses input group name.
#' @param overwrite Logical (optional). Whether to overwrite existing dataset.
#'   Default is FALSE.
#' @param remove Logical (optional). Whether to remove source datasets after
#'   reduction. Default is FALSE.
#'
#' @return No return value, called for side effects (dataset reduction).
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' X1 <- matrix(1:100, 10, 10)
#' X2 <- matrix(101:200, 10, 10)
#' X3 <- matrix(201:300, 10, 10)
#' 
#' # Save to HDF5
#' fn <- "test.hdf5"
#' bdCreate_hdf5_matrix(fn, X1, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' bdCreate_hdf5_matrix(fn, X2, "data", "matrix2",
#'                      overwriteFile = FALSE)
#' bdCreate_hdf5_matrix(fn, X3, "data", "matrix3",
#'                      overwriteFile = FALSE)
#' 
#' # Reduce datasets by addition
#' bdReduce_hdf5_dataset(
#'   filename = fn,
#'   group = "data",
#'   reducefunction = "+",
#'   outgroup = "results",
#'   outdataset = "sum_matrix",
#'   overwrite = TRUE
#' )
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdReduce_hdf5_dataset <- function(filename, group, reducefunction, outgroup = NULL, outdataset = NULL, overwrite = FALSE, remove = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdReduce_hdf5_dataset', PACKAGE = 'BigDataStatMeth', filename, group, reducefunction, outgroup, outdataset, overwrite, remove))
}

#' Remove Elements from HDF5 File
#'
#' @description
#' Removes specified groups or datasets from an HDF5 file.
#'
#' @details
#' This function provides safe element removal capabilities with:
#' 
#' * Removal options:
#'   - Single element removal
#'   - Multiple element removal
#'   - Groups and datasets removal
#' 
#' * Implementation features:
#'   - Safe file operations
#'   - Memory-efficient implementation
#'   - Comprehensive error handling
#'   - Path validation
#'
#' The function validates paths and performs safe removal operations.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param elements Character vector. Full paths to elements to remove
#'   (e.g., "group/dataset" or "group/subgroup").
#'
#' @return No return value, called for side effects (element removal).
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test matrices
#' matA <- matrix(1:15, nrow = 3, byrow = TRUE)
#' matB <- matrix(15:1, nrow = 3, byrow = TRUE)
#' 
#' # Save to HDF5
#' fn <- "test.hdf5"
#' bdCreate_hdf5_matrix(fn, matA, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' bdCreate_hdf5_matrix(fn, matB, "data", "matrix2",
#'                      overwriteFile = FALSE)
#' 
#' # Remove elements
#' bdRemove_hdf5_element(fn, c("data/matrix1", "data/matrix2"))
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdRemove_hdf5_element <- function(filename, elements) {
    invisible(.Call('_BigDataStatMeth_bdRemove_hdf5_element', PACKAGE = 'BigDataStatMeth', filename, elements))
}

#' Remove Low-Representation SNPs from HDF5 Dataset
#'
#' @description
#' Removes SNPs (Single Nucleotide Polymorphisms) with low representation from
#' genomic data stored in HDF5 format.
#'
#' @details
#' This function provides efficient filtering capabilities for genomic data with
#' support for:
#' 
#' * Filtering options:
#'   - Row-wise or column-wise filtering
#'   - Configurable threshold percentage
#'   - Flexible output location
#' 
#' * Implementation features:
#'   - Memory-efficient processing
#'   - Safe file operations
#'   - Comprehensive error handling
#'   - Progress reporting
#'
#' The function supports both in-place modification and creation of new datasets.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing input dataset.
#' @param dataset Character string. Name of the dataset to filter.
#' @param outgroup Character string. Output group path for filtered data.
#' @param outdataset Character string. Output dataset name for filtered data.
#' @param pcent Numeric (optional). Threshold percentage for removal (0-1).
#'   Default is 0.5. SNPs with representation below this threshold are removed.
#' @param bycols Logical (optional). Whether to filter by columns (TRUE) or
#'   rows (FALSE). Default is TRUE.
#' @param overwrite Logical (optional). Whether to overwrite existing dataset.
#'   Default is FALSE.
#'
#' @return No return value, called for side effects (data filtering).
#'   Prints a warning message indicating the number of rows/columns removed.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test SNP data with missing values
#' snps <- matrix(sample(c(0, 1, 2, NA), 100, replace = TRUE,
#'                      prob = c(0.3, 0.3, 0.3, 0.1)), 10, 10)
#' 
#' # Save to HDF5
#' fn <- "snp_data.hdf5"
#' bdCreate_hdf5_matrix(fn, snps, "genotype", "raw_snps",
#'                      overwriteFile = TRUE)
#' 
#' # Remove SNPs with low representation
#' bdRemovelowdata_hdf5(
#'   filename = fn,
#'   group = "genotype",
#'   dataset = "raw_snps",
#'   outgroup = "genotype_filtered",
#'   outdataset = "filtered_snps",
#'   pcent = 0.3,
#'   bycols = TRUE
#' )
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#' * Marchini, J., & Howie, B. (2010). Genotype imputation for genome-wide
#'   association studies. Nature Reviews Genetics, 11(7), 499-511.
#'
#' @seealso
#' * \code{\link{bdImputeSNPs_hdf5}} for imputing missing SNP values
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdRemovelowdata_hdf5 <- function(filename, group, dataset, outgroup, outdataset, pcent, bycols, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdRemovelowdata_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, pcent, bycols, overwrite))
}

#' Remove SNPs Based on Minor Allele Frequency
#'
#' @description
#' Filters SNPs (Single Nucleotide Polymorphisms) based on Minor Allele
#' Frequency (MAF) in genomic data stored in HDF5 format.
#'
#' @details
#' This function provides efficient MAF-based filtering capabilities with:
#' 
#' * Filtering options:
#'   - MAF threshold-based filtering
#'   - Row-wise or column-wise processing
#'   - Block-based processing
#' 
#' * Implementation features:
#'   - Memory-efficient processing
#'   - Block-based operations
#'   - Safe file operations
#'   - Progress reporting
#'
#' The function supports both in-place modification and creation of new datasets.
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing input dataset.
#' @param dataset Character string. Name of the dataset to filter.
#' @param outgroup Character string. Output group path for filtered data.
#' @param outdataset Character string. Output dataset name for filtered data.
#' @param maf Numeric (optional). MAF threshold for filtering (0-1).
#'   Default is 0.05. SNPs with MAF above this threshold are removed.
#' @param bycols Logical (optional). Whether to process by columns (TRUE) or
#'   rows (FALSE). Default is FALSE.
#' @param blocksize Integer (optional). Block size for processing. Default is 100.
#'   Larger values use more memory but may be faster.
#' @param overwrite Logical (optional). Whether to overwrite existing dataset.
#'   Default is FALSE.
#'
#' @return No return value, called for side effects (data filtering).
#'   Prints a warning message indicating the number of rows/columns removed.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test SNP data
#' snps <- matrix(sample(c(0, 1, 2), 1000, replace = TRUE,
#'                      prob = c(0.7, 0.2, 0.1)), 100, 10)
#' 
#' # Save to HDF5
#' fn <- "snp_data.hdf5"
#' bdCreate_hdf5_matrix(fn, snps, "genotype", "raw_snps",
#'                      overwriteFile = TRUE)
#' 
#' # Remove SNPs with high MAF
#' bdRemoveMAF_hdf5(
#'   filename = fn,
#'   group = "genotype",
#'   dataset = "raw_snps",
#'   outgroup = "genotype_filtered",
#'   outdataset = "filtered_snps",
#'   maf = 0.1,
#'   bycols = TRUE,
#'   blocksize = 50
#' )
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#' * Marees, A. T., et al. (2018). A tutorial on conducting genomewide
#'   association studies: Quality control and statistical analysis. International
#'   Journal of Methods in Psychiatric Research, 27(2), e1608.
#'
#' @seealso
#' * \code{\link{bdRemovelowdata_hdf5}} for removing low-representation SNPs
#' * \code{\link{bdImputeSNPs_hdf5}} for imputing missing SNP values
#'
#' @export
bdRemoveMAF_hdf5 <- function(filename, group, dataset, outgroup, outdataset, maf, bycols, blocksize, overwrite = NULL) {
    invisible(.Call('_BigDataStatMeth_bdRemoveMAF_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, maf, bycols, blocksize, overwrite))
}

#' Sort HDF5 Dataset Using Predefined Order
#'
#' @description
#' Sorts a dataset in an HDF5 file based on a predefined ordering specified
#' through a list of sorting blocks.
#'
#' @details
#' This function provides efficient dataset sorting capabilities with:
#' 
#' * Sorting options:
#'   - Row-wise sorting
#'   - Column-wise sorting
#'   - Block-based processing
#' 
#' * Implementation features:
#'   - Memory-efficient processing
#'   - Block-based operations
#'   - Safe file operations
#'   - Progress reporting
#'
#' The sorting order is specified through a list of data frames, where each
#' data frame represents a block of elements to be sorted. Each data frame
#' must contain:
#' - Row names (current identifiers)
#' - chr (new identifiers)
#' - order (current positions)
#' - newOrder (target positions)
#'
#' Example sorting blocks structure:
#' 
#' Block 1 (maintaining order):
#'                       chr order newOrder Diagonal
#' TCGA-OR-A5J1 TCGA-OR-A5J1     1        1        1
#' TCGA-OR-A5J2 TCGA-OR-A5J2     2        2        1
#' TCGA-OR-A5J3 TCGA-OR-A5J3     3        3        1
#' TCGA-OR-A5J4 TCGA-OR-A5J4     4        4        1
#'
#' Block 2 (reordering with new identifiers):
#'                       chr order newOrder
#' TCGA-OR-A5J5 TCGA-OR-A5JA    10        5        1
#' TCGA-OR-A5J6 TCGA-OR-A5JB    11        6        1
#' TCGA-OR-A5J7 TCGA-OR-A5JC    12        7        0
#' TCGA-OR-A5J8 TCGA-OR-A5JD    13        8        1
#'
#' Block 3 (reordering with identifier swaps):
#'                       chr order newOrder
#' TCGA-OR-A5J9 TCGA-OR-A5J5     5        9        1
#' TCGA-OR-A5JA TCGA-OR-A5J6     6       10        1
#' TCGA-OR-A5JB TCGA-OR-A5J7     7       11        1
#' TCGA-OR-A5JC TCGA-OR-A5J8     8       12        1
#' TCGA-OR-A5JD TCGA-OR-A5J9     9       13        0
#'
#' In this example:
#' - Block 1 maintains the original order
#' - Block 2 assigns new identifiers (A5JA-D) to elements
#' - Block 3 swaps identifiers between elements
#' - The Diagonal column indicates whether the element is on the diagonal (1) or not (0)
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing input dataset.
#' @param dataset Character string. Name of the dataset to sort.
#' @param outdataset Character string. Name for the sorted dataset.
#' @param blockedSortlist List of data frames. Each data frame specifies the
#'   sorting order for a block of elements. See Details for structure.
#' @param func Character string. Function to apply:
#'   - "sortRows" for row-wise sorting
#'   - "sortCols" for column-wise sorting
#' @param outgroup Character string (optional). Output group path. If NULL,
#'   uses input group.
#' @param overwrite Logical (optional). Whether to overwrite existing dataset.
#'   Default is FALSE.
#'
#' @return No return value, called for side effects (dataset sorting).
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test data
#' data <- matrix(rnorm(100), 10, 10)
#' rownames(data) <- paste0("TCGA-OR-A5J", 1:10)
#' 
#' # Save to HDF5
#' fn <- "test.hdf5"
#' bdCreate_hdf5_matrix(fn, data, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' 
#' # Create sorting blocks
#' block1 <- data.frame(
#'   chr = paste0("TCGA-OR-A5J", c(2,1,3,4)),
#'   order = 1:4,
#'   newOrder = c(2,1,3,4),
#'   row.names = paste0("TCGA-OR-A5J", 1:4)
#' )
#' 
#' block2 <- data.frame(
#'   chr = paste0("TCGA-OR-A5J", c(6,5,8,7)),
#'   order = 5:8,
#'   newOrder = c(6,5,8,7),
#'   row.names = paste0("TCGA-OR-A5J", 5:8)
#' )
#' 
#' # Sort dataset
#' bdSort_hdf5_dataset(
#'   filename = fn,
#'   group = "data",
#'   dataset = "matrix1",
#'   outdataset = "matrix1_sorted",
#'   blockedSortlist = list(block1, block2),
#'   func = "sortRows"
#' )
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdSort_hdf5_dataset <- function(filename, group, dataset, outdataset, blockedSortlist, func, outgroup = NULL, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdSort_hdf5_dataset', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outdataset, blockedSortlist, func, outgroup, overwrite))
}

#' Split HDF5 Dataset into Submatrices
#'
#' @description
#' Splits a large dataset in an HDF5 file into smaller submatrices, with
#' support for both row-wise and column-wise splitting.
#'
#' @details
#' This function provides efficient dataset splitting capabilities with:
#' 
#' * Splitting options:
#'   - Row-wise or column-wise splitting
#'   - Fixed block size splitting
#'   - Fixed block count splitting
#' 
#' * Implementation features:
#'   - Memory-efficient processing
#'   - Block-based operations
#'   - Safe file operations
#'   - Progress reporting
#'
#' The function supports two splitting strategies:
#' 1. By number of blocks: Splits the dataset into a specified number of
#'    roughly equal-sized blocks
#' 2. By block size: Splits the dataset into blocks of a specified size
#'
#' @param filename Character string. Path to the HDF5 file.
#' @param group Character string. Path to the group containing input dataset.
#' @param dataset Character string. Name of the dataset to split.
#' @param outgroup Character string (optional). Output group path. If NULL,
#'   uses input group.
#' @param outdataset Character string (optional). Base name for output datasets.
#'   If NULL, uses input dataset name with block number suffix.
#' @param nblocks Integer (optional). Number of blocks to split into.
#'   Mutually exclusive with blocksize.
#' @param blocksize Integer (optional). Size of each block.
#'   Mutually exclusive with nblocks.
#' @param bycols Logical (optional). Whether to split by columns (TRUE) or
#'   rows (FALSE). Default is TRUE.
#' @param overwrite Logical (optional). Whether to overwrite existing datasets.
#'   Default is FALSE.
#'
#' @return No return value, called for side effects (dataset splitting).
#'   Creates multiple datasets in the HDF5 file named as
#'   "`outdataset`.1", "`outdataset`.2", etc.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Create test data
#' data <- matrix(rnorm(1000), 100, 10)
#' 
#' # Save to HDF5
#' fn <- "test.hdf5"
#' bdCreate_hdf5_matrix(fn, data, "data", "matrix1",
#'                      overwriteFile = TRUE)
#' 
#' # Split by number of blocks
#' bdSplit_matrix_hdf5(
#'   filename = fn,
#'   group = "data",
#'   dataset = "matrix1",
#'   outgroup = "data_split",
#'   outdataset = "block",
#'   nblocks = 4,
#'   bycols = TRUE
#' )
#' 
#' # Split by block size
#' bdSplit_matrix_hdf5(
#'   filename = fn,
#'   group = "data",
#'   dataset = "matrix1",
#'   outgroup = "data_split2",
#'   outdataset = "block",
#'   blocksize = 25,
#'   bycols = TRUE
#' )
#' 
#' # Cleanup
#' if (file.exists(fn)) {
#'   file.remove(fn)
#' }
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdSplit_matrix_hdf5 <- function(filename, group, dataset, outgroup = NULL, outdataset = NULL, nblocks = NULL, blocksize = NULL, bycols = TRUE, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdSplit_matrix_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, outgroup, outdataset, nblocks, blocksize, bycols, overwrite))
}

#' Write Upper/Lower Triangular Matrix
#'
#' @description
#' Creates a symmetric matrix by mirroring values from one triangular part to the other
#' in an HDF5-stored matrix. This function modifies the matrix in-place, either copying
#' the upper triangular values to the lower triangular part or vice versa.
#'
#' @details
#' This function provides an efficient way to create symmetric matrices from triangular
#' data. It operates directly on HDF5 datasets using block processing for memory
#' efficiency. The function:
#' 
#' * Validates that the input matrix is square
#' * Processes the matrix in blocks for memory efficiency
#' * Performs in-place modification of the dataset
#' * Preserves the original values in the source triangular part
#' * Supports both upper-to-lower and lower-to-upper mirroring
#'
#' The implementation uses block processing to handle large matrices efficiently,
#' making it suitable for big data applications. The block size can be adjusted
#' based on available memory and performance requirements.
#'
#' @param filename Character string specifying the path to an existing HDF5 file
#' @param group Character string indicating the input group containing the dataset
#' @param dataset Character string specifying the dataset to be modified
#' @param copytolower Logical. If TRUE, copies upper triangular to lower triangular.
#'   If FALSE (default), copies lower triangular to upper triangular.
#' @param elementsBlock Integer defining the maximum number of elements to process
#'   in each block. Default is 1,000,000. For matrices larger than 5000x5000,
#'   automatically adjusted to number of rows or columns * 2.
#'
#' @return No direct return value. The function modifies the HDF5 dataset in-place.
#'
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Create a matrix with upper triangular values
#' X <- matrix(rnorm(100), 10, 10)
#' X.1 <- X
#' X[lower.tri(X)] <- 0
#' 
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test_file.hdf5", X, "data", "X", 
#'                      overwriteFile = TRUE, 
#'                      overwriteDataset = FALSE, 
#'                      unlimited = FALSE)
#'                      
#' # Mirror upper triangular to lower
#' bdWriteOppsiteTriangularMatrix_hdf5(
#'   filename = "test_file.hdf5", 
#'   group = "data",
#'   dataset = "X",
#'   copytolower = TRUE,
#'   elementsBlock = 10
#' )
#'
#' # Create a matrix with lower triangular values
#' X <- X.1
#' X[upper.tri(X)] <- 0
#' 
#' # Add to HDF5 file
#' bdCreate_hdf5_matrix("test_file.hdf5", X, "data", "Y", 
#'                      overwriteFile = FALSE, 
#'                      overwriteDataset = FALSE, 
#'                      unlimited = FALSE)
#'                      
#' # Mirror lower triangular to upper
#' bdWriteOppsiteTriangularMatrix_hdf5(
#'   filename = "test_file.hdf5", 
#'   group = "data",
#'   dataset = "Y",
#'   copytolower = FALSE,
#'   elementsBlock = 10
#' )
#'
#' # Cleanup
#' if (file.exists("test_file.hdf5")) {
#'   file.remove("test_file.hdf5")
#' }
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdWriteOppsiteTriangularMatrix_hdf5 <- function(filename, group, dataset, copytolower = NULL, elementsBlock = 1000000L) {
    invisible(.Call('_BigDataStatMeth_bdWriteOppsiteTriangularMatrix_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, copytolower, elementsBlock))
}

#' Apply Vector Operations to HDF5 Matrix
#'
#' @description
#' Performs element-wise operations between a matrix and a vector stored in HDF5
#' format. The function supports addition, subtraction, multiplication, and division
#' operations, with options for row-wise or column-wise application and parallel
#' processing.
#'
#' @details
#' This function provides a flexible interface for performing element-wise operations
#' between matrices and vectors stored in HDF5 format. It supports:
#' 
#' * Four basic operations:
#'   - Addition (+): Adds vector elements to matrix rows/columns
#'   - Subtraction (-): Subtracts vector elements from matrix rows/columns
#'   - Multiplication (*): Multiplies matrix rows/columns by vector elements
#'   - Division (/): Divides matrix rows/columns by vector elements
#' 
#' * Processing options:
#'   - Row-wise or column-wise operations
#'   - Parallel processing for improved performance
#'   - Configurable thread count for parallel execution
#'   - Memory-efficient processing for large datasets
#'
#' The function performs extensive validation:
#' * Checks matrix and vector dimensions for compatibility
#' * Validates operation type
#' * Verifies HDF5 file and dataset accessibility
#' * Ensures proper data structures (matrix vs. vector)
#'
#' @param filename String. Path to the HDF5 file containing the datasets.
#' @param group String. Path to the group containing the matrix dataset.
#' @param dataset String. Name of the matrix dataset.
#' @param vectorgroup String. Path to the group containing the vector dataset.
#' @param vectordataset String. Name of the vector dataset.
#' @param outdataset String. Name for the output dataset.
#' @param func String. Operation to perform: "+", "-", "*", or "/".
#' @param outgroup Optional string. Output group path. If not provided,
#'   results are stored in the same group as the input matrix.
#' @param byrows Logical. If TRUE, applies operation by rows. If FALSE (default),
#'   applies operation by columns.
#' @param paral Logical. If TRUE, enables parallel processing.
#' @param threads Integer. Number of threads for parallel processing.
#'   Ignored if paral is FALSE.
#' @param overwrite Logical. If TRUE, allows overwriting existing datasets.
#'
#' @return No direct return value. Results are written to the HDF5 file in the
#' specified location.
#'
#' @examples
#' library(BigDataStatMeth)
#'     
#' # Create test data
#' set.seed(123)
#' Y <- matrix(rnorm(100), 10, 10)
#' X <- matrix(rnorm(10), 10, 1)
#'         
#' # Save to HDF5
#' bdCreate_hdf5_matrix("test.hdf5", Y, "data", "Y",
#'                      overwriteFile = TRUE,
#'                      overwriteDataset = FALSE,
#'                      unlimited = FALSE)
#' bdCreate_hdf5_matrix("test.hdf5", X, "data", "X",
#'                      overwriteFile = FALSE,
#'                      overwriteDataset = FALSE,
#'                      unlimited = FALSE)
#'             
#' # Multiply matrix rows by vector
#' bdcomputeMatrixVector_hdf5("test.hdf5",
#'                            group = "data",
#'                            dataset = "Y",
#'                            vectorgroup = "data",
#'                            vectordataset = "X",
#'                            outdataset = "ProdComputed",
#'                            func = "*",
#'                            byrows = TRUE,
#'                            overwrite = TRUE)
#'     
#' # Subtract vector from matrix rows
#' bdcomputeMatrixVector_hdf5("test.hdf5",
#'                            group = "data",
#'                            dataset = "Y",
#'                            vectorgroup = "data",
#'                            vectordataset = "X",
#'                            outdataset = "SubsComputed",
#'                            func = "-",
#'                            byrows = TRUE,
#'                            overwrite = TRUE)
#'     
#' # Subtract vector from matrix columns
#' bdcomputeMatrixVector_hdf5("test.hdf5",
#'                            group = "data",
#'                            dataset = "Y",
#'                            vectorgroup = "data",
#'                            vectordataset = "X",
#'                            outdataset = "SubsComputed",
#'                            func = "-",
#'                            byrows = FALSE,
#'                            overwrite = TRUE)
#'                            
#' # Cleanup
#' if (file.exists("test.hdf5")) {
#'   file.remove("test.hdf5")
#' }
#'
#' @references
#' * The HDF Group. (2000-2010). HDF5 User's Guide.
#' * Eddelbuettel, D., & Franois, R. (2011). Rcpp: Seamless R and C++
#'   Integration. Journal of Statistical Software, 40(8), 1-18.
#'
#' @seealso
#' * \code{\link{bdCreate_hdf5_matrix}} for creating HDF5 matrices
#'
#' @export
bdcomputeMatrixVector_hdf5 <- function(filename, group, dataset, vectorgroup, vectordataset, outdataset, func, outgroup = NULL, byrows = NULL, paral = NULL, threads = NULL, overwrite = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdcomputeMatrixVector_hdf5', PACKAGE = 'BigDataStatMeth', filename, group, dataset, vectorgroup, vectordataset, outdataset, func, outgroup, byrows, paral, threads, overwrite))
}

#' Diagnose I/O performance for BigDataStatMeth operations
#'
#' Analyzes your matrix size and operation to show the I/O-aware 
#' thread optimization strategy and expected performance impact.
#' This function provides detailed system analysis including storage
#' detection, I/O intensity calculation, and optimization reasoning.
#'
#' @param matrix_rows Number of rows in your matrix
#' @param matrix_cols Number of columns in your matrix
#' @param operation_type Type of BigDataStatMeth operation
#' @details
#' Supported operation types:
#' \itemize{
#'   \item "multiplication" - Matrix multiplication (A %*% B)
#'   \item "svd" - Singular Value Decomposition
#'   \item "crossprod" - Cross-product (t(A) %*% A)
#'   \item "tcrossprod" - Transpose cross-product (A %*% t(A))
#' }
#' 
#' The analysis includes:
#' \itemize{
#'   \item Storage type detection (HDD/SSD/NVMe/Network)
#'   \item I/O intensity ratio calculation
#'   \item System type identification (HPC/Server/Desktop)
#'   \item Thread recommendation with reasoning
#'   \item Expected performance improvement estimates
#' }
#' @examples
#' # Diagnose your specific workload
#' bdDiagnoseIO(5000, 5000, "multiplication")
#' 
#' # Check different operations
#' bdDiagnoseIO(10000, 8000, "svd")
#' bdDiagnoseIO(5000, 5000, "crossprod")
#' @export
bdDiagnoseIO <- function(matrix_rows, matrix_cols, operation_type = "multiplication") {
    invisible(.Call('_BigDataStatMeth_bdDiagnoseIO', PACKAGE = 'BigDataStatMeth', matrix_rows, matrix_cols, operation_type))
}

#' Get I/O-aware thread recommendation
#'
#' Returns the optimal number of threads for your specific matrix size
#' and operation, considering I/O bottlenecks, storage characteristics,
#' and system constraints. This function performs the same analysis as
#' the internal optimization but returns the result without applying it.
#'
#' @param matrix_rows Number of rows in your matrix
#' @param matrix_cols Number of columns in your matrix
#' @param operation_type Type of operation (default: "multiplication")
#' @param max_threads Maximum threads to consider (optional)
#' @return Integer with recommended thread count
#' @details
#' The recommendation considers:
#' \itemize{
#'   \item Storage I/O capacity (1 for HDD, 4 for SSD, 8 for NVMe)
#'   \item I/O to computation ratio for the specific operation
#'   \item System type (HPC cluster, server, desktop)
#'   \item Memory constraints on large systems (>64 cores)
#'   \item Job scheduler allocations (SLURM_CPUS_PER_TASK, PBS_NCPUS)
#'   \item CRAN compliance requirements
#' }
#' @note This function does not modify any OpenMP settings,
#'       use bdConfigureIO() to apply the recommendations
#' @examples
#' # Get recommendation for your workload
#' threads <- bdGetOptimalThreads(5000, 5000, "multiplication")
#' cat("Recommended threads:", threads, "\n")
#' 
#' # Limit maximum threads
#' threads <- bdGetOptimalThreads(10000, 10000, "svd", max_threads = 16)
#' 
#' # Use recommendation in manual configuration
#' # omp_set_num_threads(threads)
#' @export
bdGetOptimalThreads <- function(matrix_rows, matrix_cols, operation_type = "multiplication", max_threads = NULL) {
    .Call('_BigDataStatMeth_bdGetOptimalThreads', PACKAGE = 'BigDataStatMeth', matrix_rows, matrix_cols, operation_type, max_threads)
}

#' Configure BigDataStatMeth with I/O-aware optimization
#'
#' Applies optimal OpenMP configuration for your typical workload.
#' This sets the thread count and OpenMP parameters for the current R session
#' based on intelligent analysis of your matrix size, operation type,
#' storage characteristics, and system capabilities.
#'
#' @param matrix_rows Typical number of rows in your matrices
#' @param matrix_cols Typical number of columns in your matrices  
#' @param operation_type Primary operation type you'll be using (default: "multiplication")
#' @details
#' This function:
#' \itemize{
#'   \item Calculates optimal thread count using I/O-aware analysis
#'   \item Applies OpenMP thread configuration (omp_set_num_threads)
#'   \item Sets appropriate OpenMP scheduling policy
#'   \item Disables dynamic thread adjustment for consistent performance
#'   \item Configures thread affinity settings when beneficial
#' }
#' 
#' The configuration persists for the current R session and affects
#' all subsequent BigDataStatMeth operations and other OpenMP code.
#' @note Call this function once at the beginning of your analysis session
#' @warning This modifies global OpenMP settings which may affect
#'          other packages using OpenMP in the same R session
#' @examples
#' # Configure for matrix multiplication workload
#' bdConfigureIO(5000, 5000, "multiplication")
#' 
#' # Configure for SVD operations
#' bdConfigureIO(10000, 8000, "svd")
#' 
#' # Now your BigDataStatMeth operations will use optimal settings
#' result <- bdblockmult_hdf5("data.h5", "matrices", "A", "B")
#' @export
bdConfigureIO <- function(matrix_rows, matrix_cols, operation_type = "multiplication") {
    invisible(.Call('_BigDataStatMeth_bdConfigureIO', PACKAGE = 'BigDataStatMeth', matrix_rows, matrix_cols, operation_type))
}

#' Check current BigDataStatMeth thread configuration
#'
#' Shows the current OpenMP thread configuration and system information.
#' Useful for verifying that optimization has been applied correctly,
#' understanding system characteristics, and debugging performance issues.
#'
#' @return List with current configuration details
#' @details
#' Returns a list containing:
#' \itemize{
#'   \item current_threads - Currently configured OpenMP threads
#'   \item available_cores - Total CPU cores available
#'   \item system_type - Detected system type (HPC/Server/Desktop/CRAN)
#'   \item is_hpc - Whether HPC environment was detected
#'   \item is_cran - Whether CRAN compliance mode is active
#'   \item optimization_active - Whether I/O-aware optimization appears active
#'   \item thread_efficiency - Ratio of current threads to available cores
#' }
#' @note This function only reads current settings and does not
#'       modify any configuration
#' @examples
#' # Check current configuration
#' config <- bdCheckConfig()
#' print(config)
#' 
#' # See if optimization is active
#' if (config$optimization_active) {
#'   message("I/O-aware optimization is active")
#' } else {
#'   message("Consider running bdConfigureIO() for optimization")
#' }
#' 
#' # Check thread efficiency
#' if (config$thread_efficiency < 0.5) {
#'   message("Conservative threading detected - likely I/O optimized")
#' }
#' @export
bdCheckConfig <- function() {
    .Call('_BigDataStatMeth_bdCheckConfig', PACKAGE = 'BigDataStatMeth')
}

#' Quick performance test for current thread configuration
#'
#' Performs a simple matrix operation to test the performance
#' of the current thread configuration. Useful for measuring
#' the impact of I/O-aware optimization and comparing different
#' configurations.
#'
#' @param test_size Size of test matrix (default: 2000)
#' @return Numeric vector with timing in milliseconds
#' @details
#' The test performs a matrix multiplication of two random matrices
#' of size test_size  test_size. This operation uses the current
#' OpenMP configuration and provides a benchmark for computational
#' performance under the current thread settings.
#' 
#' The test is CPU-intensive and may not reflect I/O-bound BigDataStatMeth
#' operations, but provides a baseline for thread configuration effectiveness.
#' @note 
#' - Larger test sizes provide more stable timing but take longer
#' - Results may vary between runs due to system load
#' - This test uses in-memory matrices, not HDF5 I/O
#' @examples
#' # Test current performance
#' time_ms <- bdTestPerformance()
#' cat("Test completed in", time_ms, "milliseconds\n")
#' 
#' # Compare different configurations
#' time_before <- bdTestPerformance()
#' bdConfigureIO(5000, 5000, "multiplication")
#' time_after <- bdTestPerformance()
#' 
#' # Compare results
#' improvement <- time_before / time_after
#' cat("Performance improvement:", improvement, "x\n")
#' 
#' # Test with larger matrices for more stable results
#' time_stable <- bdTestPerformance(test_size = 3000)
#' @export
bdTestPerformance <- function(test_size = 2000L) {
    .Call('_BigDataStatMeth_bdTestPerformance', PACKAGE = 'BigDataStatMeth', test_size)
}

#' Block-Based Matrix Multiplication
#'
#' @description
#' Performs efficient matrix multiplication using block-based algorithms. The function
#' supports various input combinations (matrix-matrix, matrix-vector, vector-vector)
#' and provides options for parallel processing and block-based computation.
#'
#' @details
#' This function implements block-based matrix multiplication algorithms optimized
#' for cache efficiency and memory usage. Key features:
#' 
#' * Input combinations supported:
#'   - Matrix-matrix multiplication
#'   - Matrix-vector multiplication (both left and right)
#'   - Vector-vector multiplication
#' 
#' * Performance optimizations:
#'   - Block-based computation for cache efficiency
#'   - Parallel processing for large matrices
#'   - Automatic block size selection
#'   - Memory-efficient implementation
#'
#' The function automatically selects the appropriate multiplication method based
#' on input types and sizes. For large matrices (>2.25e+08 elements), block-based
#' computation is used by default.
#'
#' @param A Matrix or vector. First input operand.
#' @param B Matrix or vector. Second input operand.
#' @param block_size Integer. Block size for computation. If NULL, uses maximum
#'   allowed block size.
#' @param paral Logical. If TRUE, enables parallel computation. Default is FALSE.
#' @param byBlocks Logical. If TRUE (default), forces block-based computation for
#'   large matrices. Can be set to FALSE to disable blocking.
#' @param threads Integer. Number of threads for parallel computation. If NULL,
#'   uses half of available threads or maximum allowed threads.
#'
#' @return Matrix or vector containing the result of A * B.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Matrix-matrix multiplication
#' N <- 2500
#' M <- 400
#' nc <- 4
#' 
#' set.seed(555)
#' mat <- matrix(rnorm(N*M, mean=0, sd=10), N, M)
#' 
#' # Parallel block multiplication
#' result <- bdblockMult(mat, mat,
#'                       paral = TRUE,
#'                       threads = nc)
#' 
#' # Matrix-vector multiplication
#' vec <- rnorm(M)
#' result_mv <- bdblockMult(mat, vec,
#'                          paral = TRUE,
#'                          threads = nc)
#' }
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Kumar, V. et al. (1994). Introduction to Parallel Computing: Design and
#'   Analysis of Algorithms. Benjamin/Cummings Publishing Company.
#'
#' @seealso
#' * \code{\link{bdblockSum}} for block-based matrix addition
#' * \code{\link{bdblockSubstract}} for block-based matrix subtraction
#'
#' @export
bdblockMult <- function(A, B, block_size = NULL, paral = NULL, byBlocks = TRUE, threads = NULL) {
    .Call('_BigDataStatMeth_bdblockMult', PACKAGE = 'BigDataStatMeth', A, B, block_size, paral, byBlocks, threads)
}

#' Block-Based Matrix Subtraction
#'
#' @description
#' Performs efficient matrix subtraction using block-based algorithms. The function
#' supports various input combinations (matrix-matrix, matrix-vector, vector-vector)
#' and provides options for parallel processing and block-based computation.
#'
#' @details
#' This function implements block-based matrix subtraction algorithms optimized
#' for cache efficiency and memory usage. Key features:
#' 
#' * Input combinations supported:
#'   - Matrix-matrix subtraction
#'   - Matrix-vector subtraction (both left and right)
#'   - Vector-vector subtraction
#' 
#' * Performance optimizations:
#'   - Block-based computation for cache efficiency
#'   - Parallel processing for large matrices
#'   - Automatic method selection based on input size
#'   - Memory-efficient implementation
#'
#' The function automatically selects the appropriate subtraction method based
#' on input types and sizes. For large matrices (>2.25e+08 elements), block-based
#' computation is used by default.
#'
#' @param A Matrix or vector. First input operand.
#' @param B Matrix or vector. Second input operand.
#' @param block_size Integer. Block size for computation. If NULL, uses maximum
#'   allowed block size.
#' @param paral Logical. If TRUE, enables parallel computation. Default is FALSE.
#' @param byBlocks Logical. If TRUE (default), forces block-based computation for
#'   large matrices. Can be set to FALSE to disable blocking.
#' @param threads Integer. Number of threads for parallel computation. If NULL,
#'   uses half of available threads.
#'
#' @return Matrix or vector containing the result of A - B.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Matrix-matrix subtraction
#' N <- 2500
#' M <- 400
#' nc <- 4
#' 
#' set.seed(555)
#' mat1 <- matrix(rnorm(N*M, mean=0, sd=10), N, M)
#' mat2 <- matrix(rnorm(N*M, mean=0, sd=10), N, M)
#' 
#' # Parallel block subtraction
#' result <- bdblockSubstract(mat1, mat2,
#'                           paral = TRUE,
#'                           threads = nc)
#' 
#' # Matrix-vector subtraction
#' vec <- rnorm(M)
#' result_mv <- bdblockSubstract(mat1, vec,
#'                              paral = TRUE,
#'                              threads = nc)
#' }
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Kumar, V. et al. (1994). Introduction to Parallel Computing: Design and
#'   Analysis of Algorithms. Benjamin/Cummings Publishing Company.
#'
#' @seealso
#' * \code{\link{bdblockSum}} for block-based matrix addition
#' * \code{\link{bdblockMult}} for block-based matrix multiplication
#'
#' @export
bdblockSubstract <- function(A, B, block_size = NULL, paral = NULL, byBlocks = TRUE, threads = NULL) {
    .Call('_BigDataStatMeth_bdblockSubstract', PACKAGE = 'BigDataStatMeth', A, B, block_size, paral, byBlocks, threads)
}

#' Block-Based Matrix Addition
#'
#' @description
#' Performs efficient matrix addition using block-based algorithms. The function
#' supports various input combinations (matrix-matrix, matrix-vector, vector-vector)
#' and provides options for parallel processing and block-based computation.
#'
#' @details
#' This function implements block-based matrix addition algorithms optimized
#' for cache efficiency and memory usage. Key features:
#' 
#' * Input combinations supported:
#'   - Matrix-matrix addition
#'   - Matrix-vector addition (both left and right)
#'   - Vector-vector addition
#' 
#' * Performance optimizations:
#'   - Block-based computation for cache efficiency
#'   - Parallel processing for large matrices
#'   - Automatic method selection based on input size
#'   - Memory-efficient implementation
#'
#' The function automatically selects the appropriate addition method based
#' on input types and sizes. For large matrices (>2.25e+08 elements), block-based
#' computation is used by default.
#'
#' @param A Matrix or vector. First input operand.
#' @param B Matrix or vector. Second input operand.
#' @param block_size Integer. Block size for computation. If NULL, uses maximum
#'   allowed block size.
#' @param paral Logical. If TRUE, enables parallel computation. Default is FALSE.
#' @param byBlocks Logical. If TRUE (default), forces block-based computation for
#'   large matrices. Can be set to FALSE to disable blocking.
#' @param threads Integer. Number of threads for parallel computation. If NULL,
#'   uses half of available threads.
#'
#' @return Matrix or vector containing the result of A + B.
#'
#' @examples
#' \dontrun{
#' library(BigDataStatMeth)
#' 
#' # Matrix-matrix addition
#' N <- 2500
#' M <- 400
#' nc <- 4
#' 
#' set.seed(555)
#' mat1 <- matrix(rnorm(N*M, mean=0, sd=10), N, M)
#' mat2 <- matrix(rnorm(N*M, mean=0, sd=10), N, M)
#' 
#' # Parallel block addition
#' result <- bdblockSum(mat1, mat2,
#'                      paral = TRUE,
#'                      threads = nc)
#' 
#' # Matrix-vector addition
#' vec <- rnorm(M)
#' result_mv <- bdblockSum(mat1, vec,
#'                         paral = TRUE,
#'                         threads = nc)
#' }
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Kumar, V. et al. (1994). Introduction to Parallel Computing: Design and
#'   Analysis of Algorithms. Benjamin/Cummings Publishing Company.
#'
#' @seealso
#' * \code{\link{bdblockSubstract}} for block-based matrix subtraction
#' * \code{\link{bdblockMult}} for block-based matrix multiplication
#'
#' @export
bdblockSum <- function(A, B, block_size = NULL, paral = NULL, byBlocks = TRUE, threads = NULL) {
    .Call('_BigDataStatMeth_bdblockSum', PACKAGE = 'BigDataStatMeth', A, B, block_size, paral, byBlocks, threads)
}

#' Efficient Matrix Cross-Product Computation
#'
#' @description
#' Computes matrix cross-products efficiently using block-based algorithms and
#' optional parallel processing. Supports both single-matrix (X'X) and two-matrix
#' (X'Y) cross-products.
#'
#' @details
#' This function implements efficient cross-product computation using block-based
#' algorithms optimized for cache efficiency and memory usage. Key features:
#' 
#' * Operation modes:
#'   - Single matrix: Computes X'X
#'   - Two matrices: Computes X'Y
#' 
#' * Performance optimizations:
#'   - Block-based computation for cache efficiency
#'   - Parallel processing for large matrices
#'   - Automatic block size selection
#'   - Memory-efficient implementation
#'
#' The function automatically selects optimal computation strategies based on
#' input size and available resources. For large matrices, block-based computation
#' is used to improve cache utilization.
#'
#' @param A Numeric matrix. First input matrix.
#' @param B Optional numeric matrix. If provided, computes A'B instead of A'A.
#' @param transposed Logical. If TRUE, uses transposed input matrix.
#' @param block_size Integer. Block size for computation. If NULL, uses optimal
#'   block size based on matrix dimensions and cache size.
#' @param paral Logical. If TRUE, enables parallel computation.
#' @param threads Integer. Number of threads for parallel computation. If NULL,
#'   uses all available threads.
#'
#' @return Numeric matrix containing the cross-product result.
#'
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Single matrix cross-product
#' n <- 100
#' p <- 60
#' X <- matrix(rnorm(n*p), nrow=n, ncol=p)
#' res <- bdCrossprod(X)
#' 
#' # Verify against base R
#' all.equal(crossprod(X), res)
#' 
#' # Two-matrix cross-product
#' n <- 100
#' p <- 100
#' Y <- matrix(rnorm(n*p), nrow=n)
#' res <- bdCrossprod(X, Y)
#' 
#' # Parallel computation
#' res_par <- bdCrossprod(X, Y,
#'                        paral = TRUE,
#'                        threads = 4)
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Kumar, V. et al. (1994). Introduction to Parallel Computing: Design and
#'   Analysis of Algorithms. Benjamin/Cummings Publishing Company.
#'
#' @seealso
#' * \code{\link{bdtCrossprod}} for transposed cross-product
#' * \code{\link{bdblockMult}} for block-based matrix multiplication
#'
#' @export
bdCrossprod <- function(A, B = NULL, transposed = NULL, block_size = NULL, paral = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdCrossprod', PACKAGE = 'BigDataStatMeth', A, B, transposed, block_size, paral, threads)
}

#' Efficient Matrix Transposed Cross-Product Computation
#'
#' @description
#' Computes matrix transposed cross-products efficiently using block-based
#' algorithms and optional parallel processing. Supports both single-matrix (XX')
#' and two-matrix (XY') transposed cross-products.
#'
#' @details
#' This function implements efficient transposed cross-product computation using
#' block-based algorithms optimized for cache efficiency and memory usage.
#' Key features:
#' 
#' * Operation modes:
#'   - Single matrix: Computes XX'
#'   - Two matrices: Computes XY'
#' 
#' * Performance optimizations:
#'   - Block-based computation for cache efficiency
#'   - Parallel processing for large matrices
#'   - Automatic block size selection
#'   - Memory-efficient implementation
#'
#' The function automatically selects optimal computation strategies based on
#' input size and available resources. For large matrices, block-based computation
#' is used to improve cache utilization.
#'
#' @param A Numeric matrix. First input matrix.
#' @param B Optional numeric matrix. If provided, computes XY' instead of XX'.
#' @param transposed Logical. If TRUE, uses transposed input matrix.
#' @param block_size Integer. Block size for computation. If NULL, uses optimal
#'   block size based on matrix dimensions and cache size.
#' @param paral Logical. If TRUE, enables parallel computation.
#' @param threads Integer. Number of threads for parallel computation. If NULL,
#'   uses all available threads.
#'
#' @return Numeric matrix containing the transposed cross-product result.
#'
#' @examples
#' library(BigDataStatMeth)
#' 
#' # Single matrix transposed cross-product
#' n <- 100
#' p <- 60
#' X <- matrix(rnorm(n*p), nrow=n, ncol=p)
#' res <- bdtCrossprod(X)
#' 
#' # Verify against base R
#' all.equal(tcrossprod(X), res)
#' 
#' # Two-matrix transposed cross-product
#' n <- 100
#' p <- 100
#' Y <- matrix(rnorm(n*p), nrow=n)
#' res <- bdtCrossprod(X, Y)
#' 
#' # Parallel computation
#' res_par <- bdtCrossprod(X, Y,
#'                         paral = TRUE,
#'                         threads = 4)
#'
#' @references
#' * Golub, G. H., & Van Loan, C. F. (2013). Matrix Computations, 4th Edition.
#'   Johns Hopkins University Press.
#' * Kumar, V. et al. (1994). Introduction to Parallel Computing: Design and
#'   Analysis of Algorithms. Benjamin/Cummings Publishing Company.
#'
#' @seealso
#' * \code{\link{bdCrossprod}} for standard cross-product
#' * \code{\link{bdblockMult}} for block-based matrix multiplication
#'
#' @export
bdtCrossprod <- function(A, B = NULL, transposed = NULL, block_size = NULL, paral = NULL, threads = NULL) {
    .Call('_BigDataStatMeth_bdtCrossprod', PACKAGE = 'BigDataStatMeth', A, B, transposed, block_size, paral, threads)
}

#' Get BigDataStatMeth system information and OpenMP configuration
#'
#' This function provides detailed information about the current system
#' and OpenMP configuration, including automatic detection of HPC clusters,
#' Linux servers, and other system types.
#'
#' @return List containing system information:
#' \itemize{
#'   \item system_type - Type of system detected
#'   \item os_name - Operating system name
#'   \item num_cores - Number of CPU cores
#'   \item recommended_threads - Recommended number of threads
#'   \item current_threads - Currently configured threads
#'   \item is_hpc - Whether HPC environment was detected
#'   \item is_linux_server - Whether Linux server was detected
#'   \item is_conservative_mode - Whether conservative mode is active
#'   \item detection_method - Method used for system detection
#'   \item openmp_schedule - Recommended OpenMP schedule
#' }
#' @examples
#' # Get system information
#' info <- bdGetSystemInfo()
#' print(info)
#' 
#' # Check if we're on an HPC system
#' if (info$is_hpc) {
#'   message("HPC environment detected - using smart optimization")
#' }
#' @export
bdGetSystemInfo <- function() {
    .Call('_BigDataStatMeth_bdGetSystemInfo', PACKAGE = 'BigDataStatMeth')
}

#' Configure OpenMP threads with intelligent optimization
#'
#' Allows users to specify the exact number of threads while applying
#' system-specific optimizations for best performance.
#'
#' @param threads Number of threads to use (required)
#' @param apply_optimizations Whether to apply system-specific optimizations (default: TRUE)
#' @examples
#' # On a 128-core server, use only 32 threads with optimizations
#' bdConfigureOpenMP(32)
#' 
#' # Use 48 threads without system optimizations
#' bdConfigureOpenMP(48, apply_optimizations = FALSE)
#' 
#' # Check what was configured
#' bdGetSystemInfo()
#' @export
bdConfigureOpenMP <- function(threads, apply_optimizations = TRUE) {
    invisible(.Call('_BigDataStatMeth_bdConfigureOpenMP', PACKAGE = 'BigDataStatMeth', threads, apply_optimizations))
}

#' Apply intelligent HPC optimizations
#'
#' Optimizes OpenMP settings for HPC environments while respecting
#' the resources allocated by job schedulers (SLURM, PBS, etc.).
#' Uses ALL allocated threads with optimized configuration.
#'
#' @examples
#' # Apply HPC optimizations (respects allocated resources)
#' bdOptimizeForHPC()
#' 
#' # Check what was configured
#' bdGetSystemInfo()
#' @export
bdOptimizeForHPC <- function() {
    invisible(.Call('_BigDataStatMeth_bdOptimizeForHPC', PACKAGE = 'BigDataStatMeth'))
}

#' Print comprehensive system diagnostics
#'
#' Prints detailed diagnostic information about the current system,
#' OpenMP configuration, and performance settings. Useful for
#' troubleshooting and optimization.
#'
#' @examples
#' # Print full diagnostics
#' bdPrintDiagnostics()
#' @export
bdPrintDiagnostics <- function() {
    invisible(.Call('_BigDataStatMeth_bdPrintDiagnostics', PACKAGE = 'BigDataStatMeth'))
}

#' Test OpenMP performance
#'
#' Performs a simple OpenMP performance test to measure the effectiveness
#' of current thread settings. Returns the execution time in milliseconds.
#'
#' @return Numeric value representing execution time in milliseconds
#' @examples
#' # Test current performance
#' time_ms <- bdTestOpenMPPerformance()
#' cat("OpenMP test completed in", time_ms, "milliseconds\n")
#' 
#' # Compare different configurations
#' bdConfigureOpenMP(32)
#' time_32 <- bdTestOpenMPPerformance()
#' 
#' bdConfigureOpenMP(64)
#' time_64 <- bdTestOpenMPPerformance()
#' 
#' cat("32 threads:", time_32, "ms\n")
#' cat("64 threads:", time_64, "ms\n")
#' @export
bdTestOpenMPPerformance <- function() {
    .Call('_BigDataStatMeth_bdTestOpenMPPerformance', PACKAGE = 'BigDataStatMeth')
}

#' Benchmark different thread configurations on current system
#'
#' Tests performance with different thread counts to find the optimal
#' configuration for the current workload and system.
#'
#' @param thread_counts Vector of thread counts to test (optional)
#' @param iterations Number of iterations per test (default: 3)
#' @examples
#' # Test common configurations
#' results <- bdBenchmarkThreads()
#' 
#' # Test specific thread counts
#' results <- bdBenchmarkThreads(c(16, 32, 48, 64))
#' print(results)
#' @export
bdBenchmarkThreads <- function(thread_counts = NULL, iterations = 3L) {
    .Call('_BigDataStatMeth_bdBenchmarkThreads', PACKAGE = 'BigDataStatMeth', thread_counts, iterations)
}

#' Get recommended thread configuration for current system
#'
#' Analyzes the current system and provides intelligent recommendations
#' for optimal thread configuration based on available resources.
#'
#' @param max_threads Maximum threads user wants to consider (optional)
#' @return List with recommendations
#' @examples
#' # Get recommendations for current system
#' rec <- bdGetRecommendations()
#' print(rec)
#' 
#' # Get recommendations limiting to 48 threads
#' rec <- bdGetRecommendations(max_threads = 48)
#' @export
bdGetRecommendations <- function(max_threads = NULL) {
    .Call('_BigDataStatMeth_bdGetRecommendations', PACKAGE = 'BigDataStatMeth', max_threads)
}

#' Check CRAN compliance and thread limitations
#'
#' This function checks if the current environment has CRAN-like restrictions
#' and shows how threading is being limited for compliance.
#'
#' @return List with CRAN compliance information
#' @examples
#' # Check CRAN compliance status
#' cran_info <- bdCheckCRANCompliance()
#' print(cran_info)
#' 
#' # See if threads are being limited
#' if (cran_info$is_cran_environment) {
#'   message("Running in CRAN-like environment - threads limited to 2")
#' }
#' @export
bdCheckCRANCompliance <- function() {
    .Call('_BigDataStatMeth_bdCheckCRANCompliance', PACKAGE = 'BigDataStatMeth')
}

#' Override CRAN limitations (for user environments only)
#'
#' This function allows users to override CRAN limitations in their own
#' environments while maintaining compliance during package checking.
#' 
#' @param force_threads Number of threads to force (optional)
#' @param ignore_cran_limits Whether to ignore CRAN-like limitations (default: FALSE)
#' @examples
#' # Check current limitations
#' bdCheckCRANCompliance()
#' 
#' # In user environment, override for full performance
#' # (This should NOT be used during package checking)
#' bdOverrideCRANLimits(ignore_cran_limits = TRUE)
#' 
#' # Force specific number of threads
#' bdOverrideCRANLimits(force_threads = 64, ignore_cran_limits = TRUE)
#' @export
bdOverrideCRANLimits <- function(force_threads = NULL, ignore_cran_limits = FALSE) {
    invisible(.Call('_BigDataStatMeth_bdOverrideCRANLimits', PACKAGE = 'BigDataStatMeth', force_threads, ignore_cran_limits))
}

#' Create hdf5 data file and write data to it
#'
#' Creates a hdf5 file with numerical data matrix,
#' 
#' @param filename, character array indicating the name of the file to create
#' @param object numerical data matrix
#' @param group, character array indicating folder name to put the matrix in hdf5 file
#' @param dataset, character array indicating the dataset name to store the matix data
#' @param transp boolean, if trans=true matrix is stored transposed in hdf5 file
#' @param overwriteFile, optional boolean by default overwriteFile = false, if true and file exists, removes old file and creates a new file with de dataset data.
#' @param overwriteDataset, optional boolean by default overwriteDataset = false,  if true and dataset exists, removes old dataset and creates a new dataset.
#' @param unlimited, optional boolean by default unlimited = false, if true creates a dataset that can growth.
#' @return none
#' 
#' @examples
#' 
#' matA <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15), nrow = 3, byrow = TRUE)
#' bdCreate_hdf5_matrix(filename = "test_temp.hdf5", 
#'                     object = matA, group = "datasets", 
#'                     dataset = "datasetA", transp = FALSE, 
#'                     overwriteFile = TRUE, 
#'                     overwriteDataset = TRUE,
#'                     unlimited = FALSE)
#' 
#' # Remove file (used as example)
#'   if (file.exists("test_temp.hdf5")) {
#'     # Delete file if it exist
#'     file.remove("test_temp.hdf5")
#'   }
#' 
#' @export
bdCreate_hdf5_matrix <- function(filename, object, group = NULL, dataset = NULL, transp = NULL, overwriteFile = NULL, overwriteDataset = NULL, unlimited = NULL) {
    invisible(.Call('_BigDataStatMeth_bdCreate_hdf5_matrix', PACKAGE = 'BigDataStatMeth', filename, object, group, dataset, transp, overwriteFile, overwriteDataset, unlimited))
}

